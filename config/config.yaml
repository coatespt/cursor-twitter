# Sample configuration for the Twitter subject detection pipeline

# So far the only input mode is RabbitMQ
mode: mqj
mq_host: localhost
mq_port: 5672
mq_queue: tweet_in

# The number of tweets to keep in memory
# Also the set of tweets over which global frequency classes are computed
window: 300000

# The number of tweets to process in each batch
batch: 5000

# Whether to log to the console
verbose: true 

# The directory to log to
log_dir: ../logs

# The minimum Z score for a 3pk element to be considered anomalous
z_score: 7

# The number of frequency classes to create
freq_classes: 7

# The length of the busy word processor counter arrays
bw_array_len: 1000

# List of frequency classes (1-based) to skip for busy word detection. E.g., [1, 2] skips the most frequent and second most frequent classes.
skip_frequency_classes: []

# Word filtering configuration
filter:
  # Enable word filtering
  enabled: true
  # Path to file containing words to filter out
  filter_file: "./config/filter_lists/test_filters.txt"

# Persistence configuration
persistence:
  # Directory for storing state files (counts, filters, 3pk mappings)
  state_dir: "../data/state"

# Sender status tracking
sender:
  # File to track the last processed CSV file
  status_file: "../data/sender/sender_status.txt"



