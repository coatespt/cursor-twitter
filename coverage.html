
<!DOCTYPE html>
<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<title>filter: Go Coverage Report</title>
		<style>
			body {
				background: black;
				color: rgb(80, 80, 80);
			}
			body, pre, #legend span {
				font-family: Menlo, monospace;
				font-weight: bold;
			}
			#topbar {
				background: black;
				position: fixed;
				top: 0; left: 0; right: 0;
				height: 42px;
				border-bottom: 1px solid rgb(80, 80, 80);
			}
			#content {
				margin-top: 50px;
			}
			#nav, #legend {
				float: left;
				margin-left: 10px;
			}
			#legend {
				margin-top: 12px;
			}
			#nav {
				margin-top: 10px;
			}
			#legend span {
				margin: 0 5px;
			}
			.cov0 { color: rgb(192, 0, 0) }
.cov1 { color: rgb(128, 128, 128) }
.cov2 { color: rgb(116, 140, 131) }
.cov3 { color: rgb(104, 152, 134) }
.cov4 { color: rgb(92, 164, 137) }
.cov5 { color: rgb(80, 176, 140) }
.cov6 { color: rgb(68, 188, 143) }
.cov7 { color: rgb(56, 200, 146) }
.cov8 { color: rgb(44, 212, 149) }
.cov9 { color: rgb(32, 224, 152) }
.cov10 { color: rgb(20, 236, 155) }

		</style>
	</head>
	<body>
		<div id="topbar">
			<div id="nav">
				<select id="files">
				
				<option value="file0">cursor-twitter/src/filter/word_filter.go (97.1%)</option>
				
				<option value="file1">cursor-twitter/src/pipeline/busy_word_processors.go (0.0%)</option>
				
				<option value="file2">cursor-twitter/src/pipeline/frequency_classes.go (54.5%)</option>
				
				<option value="file3">cursor-twitter/src/pipeline/frequency_computation_thread.go (80.6%)</option>
				
				<option value="file4">cursor-twitter/src/pipeline/queues.go (82.4%)</option>
				
				<option value="file5">cursor-twitter/src/pipeline/threepartkey.go (0.0%)</option>
				
				<option value="file6">cursor-twitter/src/pipeline/tokencounter.go (94.3%)</option>
				
				</select>
			</div>
			<div id="legend">
				<span>not tracked</span>
			
				<span class="cov0">not covered</span>
				<span class="cov8">covered</span>
			
			</div>
		</div>
		<div id="content">
		
		<pre class="file" id="file0" style="display: none">package filter

import (
        "bufio"
        "fmt"
        "os"
        "strings"
        "sync"
)

// WordFilter holds a set of words to filter out
type WordFilter struct {
        filteredWords map[string]bool
        mu            sync.RWMutex
}

// NewWordFilter creates a new empty WordFilter
func NewWordFilter() *WordFilter <span class="cov8" title="1">{
        return &amp;WordFilter{
                filteredWords: make(map[string]bool),
        }
}</span>

// LoadFromFile loads filtered words from a file
// Each line should contain one word, lines starting with # are comments
func (wf *WordFilter) LoadFromFile(filename string) error <span class="cov8" title="1">{
        file, err := os.Open(filename)
        if err != nil </span><span class="cov8" title="1">{
                return fmt.Errorf("failed to open filter file %s: %v", filename, err)
        }</span>
        <span class="cov8" title="1">defer file.Close()

        wf.mu.Lock()
        defer wf.mu.Unlock()

        scanner := bufio.NewScanner(file)
        lineNum := 0
        loadedCount := 0

        for scanner.Scan() </span><span class="cov8" title="1">{
                lineNum++
                line := strings.TrimSpace(scanner.Text())

                // Skip empty lines and comments
                if line == "" || strings.HasPrefix(line, "#") </span><span class="cov8" title="1">{
                        continue</span>
                }

                // Convert to lowercase for case-insensitive matching
                <span class="cov8" title="1">word := strings.ToLower(line)
                wf.filteredWords[word] = true
                loadedCount++</span>
        }

        <span class="cov8" title="1">if err := scanner.Err(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("error reading filter file %s at line %d: %v", filename, lineNum, err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// IsFiltered checks if a token should be filtered out
func (wf *WordFilter) IsFiltered(token string) bool <span class="cov8" title="1">{
        wf.mu.RLock()
        defer wf.mu.RUnlock()

        // Convert token to lowercase for case-insensitive matching
        token = strings.ToLower(token)
        return wf.filteredWords[token]
}</span>

// GetFilteredCount returns the number of words in the filter
func (wf *WordFilter) GetFilteredCount() int <span class="cov8" title="1">{
        wf.mu.RLock()
        defer wf.mu.RUnlock()
        return len(wf.filteredWords)
}</span>

// AddWord adds a single word to the filter
func (wf *WordFilter) AddWord(word string) <span class="cov8" title="1">{
        wf.mu.Lock()
        defer wf.mu.Unlock()
        wf.filteredWords[strings.ToLower(word)] = true
}</span>

// RemoveWord removes a word from the filter
func (wf *WordFilter) RemoveWord(word string) <span class="cov8" title="1">{
        wf.mu.Lock()
        defer wf.mu.Unlock()
        delete(wf.filteredWords, strings.ToLower(word))
}</span>
</pre>
		
		<pre class="file" id="file1" style="display: none">package pipeline

import (
        "fmt"
        "math"
        "strings"
        "sync"
        "time"

        "cursor-twitter/src/tweets"
        "log/slog"
)

// ThreePartKeyQueue is a thread-safe queue for ThreePartKeys
type ThreePartKeyQueue struct {
        items []tweets.ThreePartKey
        mu    sync.Mutex
}

// NewThreePartKeyQueue creates a new ThreePartKeyQueue
func NewThreePartKeyQueue() *ThreePartKeyQueue <span class="cov0" title="0">{
        return &amp;ThreePartKeyQueue{
                items: make([]tweets.ThreePartKey, 0),
        }
}</span>

// Enqueue adds ThreePartKeys to the queue
func (q *ThreePartKeyQueue) Enqueue(keys []tweets.ThreePartKey) <span class="cov0" title="0">{
        q.mu.Lock()
        defer q.mu.Unlock()
        q.items = append(q.items, keys...)
}</span>

// Dequeue removes and returns ThreePartKeys from the queue
func (q *ThreePartKeyQueue) Dequeue() []tweets.ThreePartKey <span class="cov0" title="0">{
        q.mu.Lock()
        defer q.mu.Unlock()

        if len(q.items) == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>

        // Return up to 100 keys at a time
        <span class="cov0" title="0">batchSize := 100
        if len(q.items) &lt; batchSize </span><span class="cov0" title="0">{
                batchSize = len(q.items)
        }</span>

        <span class="cov0" title="0">result := q.items[:batchSize]
        q.items = q.items[batchSize:]
        return result</span>
}

// Len returns the number of items in the queue
func (q *ThreePartKeyQueue) Len() int <span class="cov0" title="0">{
        q.mu.Lock()
        defer q.mu.Unlock()
        return len(q.items)
}</span>

// BatchResult holds the busy words found by a processor in one batch
type BatchResult struct {
        ClassIndex int
        BusyWords  []tweets.ThreePartKey
        WordCount  int
        Error      error
        Timestamp  time.Time
}

// BatchSummary holds the complete results from all frequency classes
type BatchSummary struct {
        BatchNumber    int
        TotalBusyWords int
        ClassResults   map[int][]string // class index -&gt; list of busy words
        Timestamp      time.Time
}

// FrequencyClassProcessor manages queues and processors for each frequency class
type FrequencyClassProcessor struct {
        queues     []*ThreePartKeyQueue
        processors []*BusyWordProcessor
        numClasses int
        stopChan   chan struct{}
        wg         sync.WaitGroup

        // Batch coordination
        batchResults chan BatchResult
        batchBarrier *Barrier
        batchMutex   sync.Mutex
        batchActive  bool
        batchNumber  int

        // Global token mapping reference (set from main.go)
        globalTokenMapping map[tweets.ThreePartKey]string
        globalMappingMutex *sync.RWMutex
}

// Barrier implements thread coordination barrier pattern
type Barrier struct {
        mu      sync.Mutex
        count   int
        waiting int
        cond    *sync.Cond
}

// NewBarrier creates a new barrier for N threads
func NewBarrier(count int) *Barrier <span class="cov0" title="0">{
        b := &amp;Barrier{count: count}
        b.cond = sync.NewCond(&amp;b.mu)
        return b
}</span>

// Wait blocks until all N threads have called Wait()
func (b *Barrier) Wait() <span class="cov0" title="0">{
        b.mu.Lock()
        b.waiting++

        if b.waiting &lt; b.count </span><span class="cov0" title="0">{
                // Not all threads have reached the barrier yet
                b.cond.Wait()
        }</span> else<span class="cov0" title="0"> {
                // All threads have reached the barrier, wake everyone up
                b.cond.Broadcast()
        }</span>

        <span class="cov0" title="0">b.mu.Unlock()</span>
}

// Reset resets the barrier for the next cycle
func (b *Barrier) Reset() <span class="cov0" title="0">{
        b.mu.Lock()
        b.waiting = 0
        b.mu.Unlock()
}</span>

// IsComplete returns true if all threads have reached the barrier
func (b *Barrier) IsComplete() bool <span class="cov0" title="0">{
        b.mu.Lock()
        defer b.mu.Unlock()
        return b.waiting == b.count
}</span>

// BusyWordProcessor processes ThreePartKeys for a specific frequency class
type BusyWordProcessor struct {
        classIndex int
        queue      *ThreePartKeyQueue
        stopChan   chan struct{}
        wg         sync.WaitGroup
        tokenCount int
        mutex      sync.Mutex

        // Counter arrays for the three parts of 3PK
        part1Counters []int
        part2Counters []int
        part3Counters []int
        arrayLen      int

        // Configuration
        zScoreThreshold float64

        // Global token mapping reference (set from main.go)
        globalTokenMapping map[tweets.ThreePartKey]string
        globalMappingMutex *sync.RWMutex

        // Batch coordination
        freqClassProcessor *FrequencyClassProcessor
}

// NewFrequencyClassProcessor creates a new processor with the specified number of classes
func NewFrequencyClassProcessor(numClasses int, arrayLen int, zScoreThreshold float64) *FrequencyClassProcessor <span class="cov0" title="0">{
        queues := make([]*ThreePartKeyQueue, numClasses)
        processors := make([]*BusyWordProcessor, numClasses)

        fcp := &amp;FrequencyClassProcessor{
                queues:       queues,
                processors:   processors,
                numClasses:   numClasses,
                stopChan:     make(chan struct{}),
                batchResults: make(chan BatchResult, numClasses), // Buffer for all processors
                batchBarrier: NewBarrier(numClasses),
        }

        for i := 0; i &lt; numClasses; i++ </span><span class="cov0" title="0">{
                queues[i] = NewThreePartKeyQueue()
                processors[i] = NewBusyWordProcessor(i, queues[i], arrayLen, zScoreThreshold, fcp)
        }</span>

        <span class="cov0" title="0">return fcp</span>
}

// NewBusyWordProcessor creates a new busy word processor for a specific class
func NewBusyWordProcessor(classIndex int, queue *ThreePartKeyQueue, arrayLen int, zScoreThreshold float64, fcp *FrequencyClassProcessor) *BusyWordProcessor <span class="cov0" title="0">{
        // Initialize counter arrays to zero
        part1Counters := make([]int, arrayLen)
        part2Counters := make([]int, arrayLen)
        part3Counters := make([]int, arrayLen)

        return &amp;BusyWordProcessor{
                classIndex:         classIndex,
                queue:              queue,
                stopChan:           make(chan struct{}),
                tokenCount:         0,
                part1Counters:      part1Counters,
                part2Counters:      part2Counters,
                part3Counters:      part3Counters,
                arrayLen:           arrayLen,
                zScoreThreshold:    zScoreThreshold,
                freqClassProcessor: fcp,
        }
}</span>

// Start begins all the busy word processors
func (fcp *FrequencyClassProcessor) Start() <span class="cov0" title="0">{
        slog.Info("Starting FrequencyClassProcessor", "num_classes", fcp.numClasses)

        for i, processor := range fcp.processors </span><span class="cov0" title="0">{
                fcp.wg.Add(1)
                go func(p *BusyWordProcessor, classIdx int) </span><span class="cov0" title="0">{
                        defer fcp.wg.Done()
                        p.run()
                }</span>(processor, i)
                <span class="cov0" title="0">slog.Info("Started BusyWordProcessor", "class_index", i)</span>
        }

        // Start the batch result collector
        <span class="cov0" title="0">go fcp.collectBatchResults()</span>
}

// Stop gracefully stops all processors
func (fcp *FrequencyClassProcessor) Stop() <span class="cov0" title="0">{
        close(fcp.stopChan)
        fcp.wg.Wait()
        slog.Info("FrequencyClassProcessor stopped")
}</span>

// collectBatchResults collects and merges results from all processors
func (fcp *FrequencyClassProcessor) collectBatchResults() <span class="cov0" title="0">{
        // Track results for current batch
        currentBatch := make(map[int][]string)
        resultsReceived := 0

        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-fcp.stopChan:<span class="cov0" title="0">
                        return</span>
                case result := &lt;-fcp.batchResults:<span class="cov0" title="0">
                        if result.Error != nil </span><span class="cov0" title="0">{
                                slog.Error("Busy word processor error",
                                        "class_index", result.ClassIndex,
                                        "error", result.Error)
                                continue</span>
                        }

                        // Convert 3PKs to actual words
                        <span class="cov0" title="0">busyWords := fcp.convert3PKsToWords(result.BusyWords)

                        // Store results for this class
                        currentBatch[result.ClassIndex] = busyWords
                        resultsReceived++

                        // Immediate feedback for this class (simplified)
                        fmt.Printf("Class %d: %d busy words\n", result.ClassIndex, len(busyWords))

                        // Check if all classes have reported
                        if resultsReceived == fcp.numClasses </span><span class="cov0" title="0">{
                                // Print batch summary
                                fcp.printBatchSummary(currentBatch)

                                // Reset for next batch
                                currentBatch = make(map[int][]string)
                                resultsReceived = 0
                                fcp.batchNumber++
                        }</span>
                }
        }
}

// printBatchSummary prints a summary of all busy words found in this batch
func (fcp *FrequencyClassProcessor) printBatchSummary(classResults map[int][]string) <span class="cov0" title="0">{
        fmt.Printf("\n" + strings.Repeat("=", 60) + "\n")
        fmt.Printf("BATCH %d SUMMARY: %d frequency classes completed\n",
                fcp.batchNumber, fcp.numClasses)

        totalBusyWords := 0
        for classIndex, words := range classResults </span><span class="cov0" title="0">{
                totalBusyWords += len(words)
                fmt.Printf("Class %d: %d busy words\n", classIndex, len(words))
        }</span>

        <span class="cov0" title="0">fmt.Printf("TOTAL: %d busy words\n", totalBusyWords)

        // Print busy words by class (only if there are any)
        for classIndex, words := range classResults </span><span class="cov0" title="0">{
                if len(words) &gt; 0 </span><span class="cov0" title="0">{
                        fmt.Printf("\nClass %d busy words:\n", classIndex)
                        for i, word := range words </span><span class="cov0" title="0">{
                                fmt.Printf("  %d. %s\n", i+1, word)
                        }</span>
                }
        }

        <span class="cov0" title="0">fmt.Printf(strings.Repeat("=", 60) + "\n\n")</span>
}

// convert3PKsToWords converts ThreePartKeys back to actual word strings
func (fcp *FrequencyClassProcessor) convert3PKsToWords(threePKs []tweets.ThreePartKey) []string <span class="cov0" title="0">{
        words := make([]string, 0, len(threePKs))

        for _, threePK := range threePKs </span><span class="cov0" title="0">{
                // Get the word from the global token mapping
                if word, exists := fcp.getWordFrom3PK(threePK); exists </span><span class="cov0" title="0">{
                        words = append(words, word)
                }</span>
        }

        <span class="cov0" title="0">return words</span>
}

// getWordFrom3PK safely retrieves a word from the global token mapping
func (fcp *FrequencyClassProcessor) getWordFrom3PK(threePK tweets.ThreePartKey) (string, bool) <span class="cov0" title="0">{
        if fcp.globalMappingMutex == nil || fcp.globalTokenMapping == nil </span><span class="cov0" title="0">{
                // Fallback to placeholder if mapping not available
                return fmt.Sprintf("word_%d_%d_%d", threePK.Part1, threePK.Part2, threePK.Part3), true
        }</span>

        <span class="cov0" title="0">fcp.globalMappingMutex.RLock()
        defer fcp.globalMappingMutex.RUnlock()

        word, exists := fcp.globalTokenMapping[threePK]
        return word, exists</span>
}

// EnqueueToFrequencyClass routes a ThreePartKey to the appropriate frequency class queue
func (fcp *FrequencyClassProcessor) EnqueueToFrequencyClass(classIndex int, key tweets.ThreePartKey) <span class="cov0" title="0">{
        if classIndex &lt; 0 || classIndex &gt;= fcp.numClasses </span><span class="cov0" title="0">{
                slog.Warn("Invalid frequency class index", "class_index", classIndex, "num_classes", fcp.numClasses)
                return
        }</span>
        <span class="cov0" title="0">fcp.queues[classIndex].Enqueue([]tweets.ThreePartKey{key})

        // Debug: Log enqueuing occasionally
        queueSize := fcp.queues[classIndex].Len()
        if queueSize%1000 == 0 &amp;&amp; queueSize &gt; 0 </span><span class="cov0" title="0">{
                slog.Info("3pk enqueued to frequency class",
                        "class_index", classIndex,
                        "queue_size", queueSize,
                        "three_pk", key)
        }</span>
}

// EnqueueKeysToFrequencyClass routes multiple ThreePartKeys to a frequency class queue
func (fcp *FrequencyClassProcessor) EnqueueKeysToFrequencyClass(classIndex int, keys []tweets.ThreePartKey) <span class="cov0" title="0">{
        if classIndex &lt; 0 || classIndex &gt;= fcp.numClasses </span><span class="cov0" title="0">{
                slog.Warn("Invalid frequency class index", "class_index", classIndex, "num_classes", fcp.numClasses)
                return
        }</span>
        <span class="cov0" title="0">fcp.queues[classIndex].Enqueue(keys)</span>
}

// GetQueueStats returns statistics about all frequency class queues
func (fcp *FrequencyClassProcessor) GetQueueStats() map[string]int <span class="cov0" title="0">{
        stats := make(map[string]int)
        for i, queue := range fcp.queues </span><span class="cov0" title="0">{
                stats[fmt.Sprintf("freq_class_%d_queue_size", i)] = queue.Len()
        }</span>
        <span class="cov0" title="0">return stats</span>
}

// GetProcessorStats returns statistics about all busy word processors
func (fcp *FrequencyClassProcessor) GetProcessorStats() map[string]int <span class="cov0" title="0">{
        stats := make(map[string]int)
        for i, processor := range fcp.processors </span><span class="cov0" title="0">{
                stats[fmt.Sprintf("freq_class_%d_tokens_processed", i)] = processor.GetTokenCount()
        }</span>
        <span class="cov0" title="0">return stats</span>
}

// run is the main loop for a busy word processor
func (bwp *BusyWordProcessor) run() <span class="cov0" title="0">{
        defer bwp.wg.Done()

        slog.Info("BusyWordProcessor started", "class_index", bwp.classIndex, "array_len", bwp.arrayLen)

        loopCount := 0
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-bwp.stopChan:<span class="cov0" title="0">
                        slog.Info("BusyWordProcessor stopping", "class_index", bwp.classIndex)
                        return</span>
                default:<span class="cov0" title="0">
                        loopCount++

                        // Try to get ThreePartKeys from the queue
                        keys := bwp.queue.Dequeue()
                        if keys == nil </span><span class="cov0" title="0">{
                                // No keys available, wait a bit
                                time.Sleep(1 * time.Millisecond)
                                continue</span>
                        }

                        // Process the ThreePartKeys
                        <span class="cov0" title="0">for _, key := range keys </span><span class="cov0" title="0">{
                                // Check for termination signal: (-1, -1, -1)
                                if key.Part1 == -1 &amp;&amp; key.Part2 == -1 &amp;&amp; key.Part3 == -1 </span><span class="cov0" title="0">{
                                        // Perform coordinated z-computation
                                        bwp.performCoordinatedZComputation()
                                        continue</span>
                                }

                                // Increment counters for each part of the 3PK
                                <span class="cov0" title="0">index1 := key.Part1
                                index2 := key.Part2
                                index3 := key.Part3

                                bwp.part1Counters[index1]++
                                bwp.part2Counters[index2]++
                                bwp.part3Counters[index3]++

                                bwp.mutex.Lock()
                                bwp.tokenCount++
                                bwp.mutex.Unlock()</span>
                        }
                }
        }
}

// performCoordinatedZComputation performs z-computation and reports results to coordinator
func (bwp *BusyWordProcessor) performCoordinatedZComputation() <span class="cov0" title="0">{
        // fmt.Printf("*** BusyWordProcessor-%d: COORDINATED Z-COMPUTATION STARTED ***\n", bwp.classIndex)

        // Calculate statistics for each array
        part1Stats := bwp.CalculateArrayStats(bwp.part1Counters)
        part2Stats := bwp.CalculateArrayStats(bwp.part2Counters)
        part3Stats := bwp.CalculateArrayStats(bwp.part3Counters)

        // Calculate z-scores and find high-scoring positions
        part1HighZScores := bwp.CalculateZScores(bwp.part1Counters, part1Stats, bwp.zScoreThreshold)
        part2HighZScores := bwp.CalculateZScores(bwp.part2Counters, part2Stats, bwp.zScoreThreshold)
        part3HighZScores := bwp.CalculateZScores(bwp.part3Counters, part3Stats, bwp.zScoreThreshold)

        // Find busy words
        busyWords := bwp.FindBusyWords(part1HighZScores, part2HighZScores, part3HighZScores)

        // Report results to coordinator
        result := BatchResult{
                ClassIndex: bwp.classIndex,
                BusyWords:  busyWords,
                WordCount:  len(busyWords),
                Error:      nil,
                Timestamp:  time.Now(),
        }

        bwp.freqClassProcessor.batchResults &lt;- result

        // fmt.Printf("*** BusyWordProcessor-%d: COORDINATED Z-COMPUTATION COMPLETED ***\n", bwp.classIndex)
        // fmt.Printf("*** BusyWordProcessor-%d: Array totals - Part1: %d, Part2: %d, Part3: %d ***\n",
        //         bwp.classIndex, part1Stats.total, part2Stats.total, part3Stats.total)
        // fmt.Printf("*** BusyWordProcessor-%d: Part1 stats - Mean: %.2f, StdDev: %.2f ***\n",
        //         bwp.classIndex, part1Stats.mean, part1Stats.stdDev)
        // fmt.Printf("*** BusyWordProcessor-%d: Part2 stats - Mean: %.2f, StdDev: %.2f ***\n",
        //         bwp.classIndex, part2Stats.mean, part2Stats.stdDev)
        // fmt.Printf("*** BusyWordProcessor-%d: Part3 stats - Mean: %.2f, StdDev: %.2f ***\n",
        //         bwp.classIndex, part3Stats.mean, part3Stats.stdDev)
        // fmt.Printf("*** BusyWordProcessor-%d: High Z-scores (&gt;=%.1f) - Part1: %d, Part2: %d, Part3: %d ***\n",
        //         bwp.classIndex, bwp.zScoreThreshold, len(part1HighZScores), len(part2HighZScores), len(part3HighZScores))
        // fmt.Printf("*** BusyWordProcessor-%d: Busy words found: %d ***\n", bwp.classIndex, len(busyWords))

        // Wipe all counter arrays to zero
        for i := 0; i &lt; bwp.arrayLen; i++ </span><span class="cov0" title="0">{
                bwp.part1Counters[i] = 0
                bwp.part2Counters[i] = 0
                bwp.part3Counters[i] = 0
        }</span>

        // fmt.Printf("*** BusyWordProcessor-%d: Arrays reset, waiting at barrier ***\n", bwp.classIndex)

        // Wait at barrier until all processors have completed
        <span class="cov0" title="0">bwp.freqClassProcessor.batchBarrier.Wait()

        // Reset barrier for next cycle (only the last processor to reach barrier does this)
        bwp.freqClassProcessor.batchMutex.Lock()
        if bwp.freqClassProcessor.batchBarrier.IsComplete() </span><span class="cov0" title="0">{
                bwp.freqClassProcessor.batchBarrier.Reset()
                fmt.Printf("*** BARRIER RESET: All %d processors synchronized, starting next cycle ***\n",
                        bwp.freqClassProcessor.numClasses)
        }</span>
        <span class="cov0" title="0">bwp.freqClassProcessor.batchMutex.Unlock()</span>

        // fmt.Printf("*** BusyWordProcessor-%d: Barrier cleared, starting next cycle ***\n", bwp.classIndex)

        // slog.Info("Coordinated z-computation completed and arrays reset",
        //         "class_index", bwp.classIndex,
        //         "array_len", bwp.arrayLen,
        //         "part1_total", part1Stats.total,
        //         "part2_total", part2Stats.total,
        //         "part3_total", part3Stats.total,
        //         "part1_mean", part1Stats.mean,
        //         "part1_stddev", part1Stats.stdDev,
        //         "part2_mean", part2Stats.mean,
        //         "part2_stddev", part2Stats.stdDev,
        //         "part3_mean", part3Stats.mean,
        //         "part3_stddev", part3Stats.stdDev,
        //         "z_score_threshold", bwp.zScoreThreshold,
        //         "part1_high_z_scores", len(part1HighZScores),
        //         "part2_high_z_scores", len(part2HighZScores),
        //         "part3_high_z_scores", len(part3HighZScores))
}

// GetTokenCount returns the number of tokens processed by this processor
func (bwp *BusyWordProcessor) GetTokenCount() int <span class="cov0" title="0">{
        bwp.mutex.Lock()
        defer bwp.mutex.Unlock()
        return bwp.tokenCount
}</span>

// performZComputation performs statistical analysis on the counter arrays
// Calculates z-scores using Gaussian statistics for each array position
func (bwp *BusyWordProcessor) performZComputation() <span class="cov0" title="0">{
        fmt.Printf("*** BusyWordProcessor-%d: Z-COMPUTATION STARTED ***\n", bwp.classIndex)

        // Calculate statistics for each array
        part1Stats := bwp.CalculateArrayStats(bwp.part1Counters)
        part2Stats := bwp.CalculateArrayStats(bwp.part2Counters)
        part3Stats := bwp.CalculateArrayStats(bwp.part3Counters)

        // Calculate z-scores and find high-scoring positions
        part1HighZScores := bwp.CalculateZScores(bwp.part1Counters, part1Stats, bwp.zScoreThreshold)
        part2HighZScores := bwp.CalculateZScores(bwp.part2Counters, part2Stats, bwp.zScoreThreshold)
        part3HighZScores := bwp.CalculateZScores(bwp.part3Counters, part3Stats, bwp.zScoreThreshold)

        // Take cartesian product of high z-score positions to generate candidate 3PKs
        // For each combination (pos1, pos2, pos3) where pos1 ∈ part1HighZScores, pos2 ∈ part2HighZScores, pos3 ∈ part3HighZScores
        // Generate 3PK and check if it exists in the global token mapping table
        // This will identify the "busy words" for this frequency class
        busyWords := bwp.FindBusyWords(part1HighZScores, part2HighZScores, part3HighZScores)

        fmt.Printf("*** BusyWordProcessor-%d: Z-COMPUTATION COMPLETED ***\n", bwp.classIndex)
        fmt.Printf("*** BusyWordProcessor-%d: Array totals - Part1: %d, Part2: %d, Part3: %d ***\n",
                bwp.classIndex, part1Stats.Total, part2Stats.Total, part3Stats.Total)
        fmt.Printf("*** BusyWordProcessor-%d: Part1 stats - Mean: %.2f, StdDev: %.2f ***\n",
                bwp.classIndex, part1Stats.Mean, part1Stats.StdDev)
        fmt.Printf("*** BusyWordProcessor-%d: Part2 stats - Mean: %.2f, StdDev: %.2f ***\n",
                bwp.classIndex, part2Stats.Mean, part2Stats.StdDev)
        fmt.Printf("*** BusyWordProcessor-%d: Part3 stats - Mean: %.2f, StdDev: %.2f ***\n",
                bwp.classIndex, part3Stats.Mean, part3Stats.StdDev)
        fmt.Printf("*** BusyWordProcessor-%d: High Z-scores (&gt;=%.1f) - Part1: %d, Part2: %d, Part3: %d ***\n",
                bwp.classIndex, bwp.zScoreThreshold, len(part1HighZScores), len(part2HighZScores), len(part3HighZScores))
        fmt.Printf("*** BusyWordProcessor-%d: Busy words found: %d ***\n", bwp.classIndex, len(busyWords))
        fmt.Printf("*** BusyWordProcessor-%d: Wiping counter arrays to zero ***\n", bwp.classIndex)

        // Wipe all counter arrays to zero
        for i := 0; i &lt; bwp.arrayLen; i++ </span><span class="cov0" title="0">{
                bwp.part1Counters[i] = 0
                bwp.part2Counters[i] = 0
                bwp.part3Counters[i] = 0
        }</span>

        <span class="cov0" title="0">fmt.Printf("*** BusyWordProcessor-%d: Arrays reset, ready for next batch ***\n", bwp.classIndex)

        slog.Info("Z-computation completed and arrays reset",
                "class_index", bwp.classIndex,
                "array_len", bwp.arrayLen,
                "part1_total", part1Stats.Total,
                "part2_total", part2Stats.Total,
                "part3_total", part3Stats.Total,
                "part1_mean", part1Stats.Mean,
                "part1_stddev", part1Stats.StdDev,
                "part2_mean", part2Stats.Mean,
                "part2_stddev", part2Stats.StdDev,
                "part3_mean", part3Stats.Mean,
                "part3_stddev", part3Stats.StdDev,
                "z_score_threshold", bwp.zScoreThreshold,
                "part1_high_z_scores", len(part1HighZScores),
                "part2_high_z_scores", len(part2HighZScores),
                "part3_high_z_scores", len(part3HighZScores))</span>
}

// CalculateZScores calculates z-scores for each position and returns set of high-scoring positions
// Also calculates min, max, and mean z-scores for threshold tuning
func (bwp *BusyWordProcessor) CalculateZScores(counts []int, stats ArrayStats, threshold float64) map[int]float64 <span class="cov0" title="0">{
        highZScores := make(map[int]float64)

        // Avoid division by zero
        if stats.StdDev == 0 </span><span class="cov0" title="0">{
                return highZScores
        }</span>

        // Calculate all z-scores and track statistics
        <span class="cov0" title="0">var allZScores []float64
        for i, count := range counts </span><span class="cov0" title="0">{
                zScore := (float64(count) - stats.Mean) / stats.StdDev
                allZScores = append(allZScores, zScore)
                if zScore &gt;= threshold </span><span class="cov0" title="0">{
                        highZScores[i] = zScore
                }</span>
        }

        // Calculate z-score statistics
        <span class="cov0" title="0">if len(allZScores) &gt; 0 </span><span class="cov0" title="0">{
                minZ := allZScores[0]
                maxZ := allZScores[0]
                sumZ := 0.0

                for _, z := range allZScores </span><span class="cov0" title="0">{
                        if z &lt; minZ </span><span class="cov0" title="0">{
                                minZ = z
                        }</span>
                        <span class="cov0" title="0">if z &gt; maxZ </span><span class="cov0" title="0">{
                                maxZ = z
                        }</span>
                        <span class="cov0" title="0">sumZ += z</span>
                }
                <span class="cov0" title="0">meanZ := sumZ / float64(len(allZScores))

                fmt.Printf("*** BusyWordProcessor-%d: Z-score stats - Min: %.2f, Max: %.2f, Mean: %.2f ***\n",
                        bwp.classIndex, minZ, maxZ, meanZ)</span>
        }

        <span class="cov0" title="0">return highZScores</span>
}

// ArrayStats holds statistical information about an array
type ArrayStats struct {
        Total  int
        Mean   float64
        StdDev float64
}

// CalculateArrayStats calculates mean, standard deviation, and z-scores for an array
func (bwp *BusyWordProcessor) CalculateArrayStats(counts []int) ArrayStats <span class="cov0" title="0">{
        // Calculate total and mean
        total := 0
        for _, count := range counts </span><span class="cov0" title="0">{
                total += count
        }</span>
        <span class="cov0" title="0">mean := float64(total) / float64(bwp.arrayLen)

        // Calculate variance (sum of squared differences from mean)
        variance := 0.0
        for _, count := range counts </span><span class="cov0" title="0">{
                diff := float64(count) - mean
                variance += diff * diff
        }</span>
        <span class="cov0" title="0">variance = variance / float64(bwp.arrayLen)

        // Calculate standard deviation
        stdDev := math.Sqrt(variance)

        return ArrayStats{
                Total:  total,
                Mean:   mean,
                StdDev: stdDev,
        }</span>
}

// FindBusyWords finds busy words from high z-score positions
func (bwp *BusyWordProcessor) FindBusyWords(part1HighZScores, part2HighZScores, part3HighZScores map[int]float64) []tweets.ThreePartKey <span class="cov0" title="0">{
        busyWords := []tweets.ThreePartKey{}

        // Iterate over all combinations of high z-score positions
        for pos1, _ := range part1HighZScores </span><span class="cov0" title="0">{
                for pos2, _ := range part2HighZScores </span><span class="cov0" title="0">{
                        for pos3, _ := range part3HighZScores </span><span class="cov0" title="0">{
                                // Generate 3PK from high z-score positions
                                key := tweets.ThreePartKey{
                                        Part1: pos1,
                                        Part2: pos2,
                                        Part3: pos3,
                                }

                                // Check if the generated 3PK exists in the global token mapping table
                                if bwp.existsInGlobalTokenMapping(key) </span><span class="cov0" title="0">{
                                        busyWords = append(busyWords, key)
                                }</span>
                        }
                }
        }

        <span class="cov0" title="0">return busyWords</span>
}

// SetGlobalTokenMapping sets the reference to the global token mapping
func (bwp *BusyWordProcessor) SetGlobalTokenMapping(mapping map[tweets.ThreePartKey]string, mutex *sync.RWMutex) <span class="cov0" title="0">{
        bwp.globalTokenMapping = mapping
        bwp.globalMappingMutex = mutex
}</span>

// existsInGlobalTokenMapping checks if a ThreePartKey exists in the global token mapping table
func (bwp *BusyWordProcessor) existsInGlobalTokenMapping(key tweets.ThreePartKey) bool <span class="cov0" title="0">{
        if bwp.globalMappingMutex == nil || bwp.globalTokenMapping == nil </span><span class="cov0" title="0">{
                return false
        }</span>

        <span class="cov0" title="0">bwp.globalMappingMutex.RLock()
        defer bwp.globalMappingMutex.RUnlock()

        _, exists := bwp.globalTokenMapping[key]
        return exists</span>
}

// SetGlobalTokenMappingForAll sets the global token mapping for all busy word processors
func (fcp *FrequencyClassProcessor) SetGlobalTokenMappingForAll(mapping map[tweets.ThreePartKey]string, mutex *sync.RWMutex) <span class="cov0" title="0">{
        // Set the mapping in the FrequencyClassProcessor itself
        fcp.globalTokenMapping = mapping
        fcp.globalMappingMutex = mutex

        // Also set it in all individual processors
        for _, processor := range fcp.processors </span><span class="cov0" title="0">{
                processor.SetGlobalTokenMapping(mapping, mutex)
        }</span>
}
</pre>
		
		<pre class="file" id="file2" style="display: none">package pipeline

import (
        "encoding/gob"
        "fmt"
        "os"
        "path/filepath"
        "sort"
        "sync"

        "github.com/bits-and-blooms/bloom/v3"
)

// TokenCount holds a token and its count.
type TokenCount struct {
        Token string
        Count int
}

// FreqClassFilter interface for both set and Bloom filter implementations
type FreqClassFilter interface {
        Contains(token string) bool
}

// SetFilter implements FreqClassFilter using a simple hash set
type SetFilter struct {
        tokens map[string]bool
}

// NewSetFilter creates a new SetFilter with the given tokens
func NewSetFilter(tokens []string) *SetFilter <span class="cov0" title="0">{
        sf := &amp;SetFilter{tokens: make(map[string]bool, len(tokens))}
        for _, token := range tokens </span><span class="cov0" title="0">{
                sf.tokens[token] = true
        }</span>
        <span class="cov0" title="0">return sf</span>
}

func (sf *SetFilter) Contains(token string) bool <span class="cov8" title="1">{
        return sf.tokens[token]
}</span>

// BloomFilterWrapper implements FreqClassFilter using a Bloom filter
type BloomFilterWrapper struct {
        filter *bloom.BloomFilter
}

func (bf *BloomFilterWrapper) Contains(token string) bool <span class="cov0" title="0">{
        return bf.filter.TestString(token)
}</span>

// SerializableFilter represents a filter that can be saved/loaded
type SerializableFilter struct {
        Type   string   // "set" or "bloom"
        Tokens []string // For SetFilter
        // Note: Bloom filters are not easily serializable, so we'll focus on SetFilter for now
}

// Add a struct to hold the result
type FreqClassResult struct {
        Filters   []FreqClassFilter
        TopTokens []TokenCount
}

// CRITICAL: ONLY the FCT (FrequencyComputationThread) should ever touch token counters or do frequency calculations.
// DO NOT create any other threads, managers, or background processes that access token counters.
// The FCT is the single source of truth for all token counting and frequency computation.

// BuildFrequencyClassBloomFiltersOptimized is an optimized version that doesn't require TokenCounter
func BuildFrequencyClassBloomFiltersOptimized(tokenCounts map[string]int, F int, bloomSizes []uint, hashCounts []uint) FreqClassResult <span class="cov8" title="1">{
        // Step 1: Build a slice of (token, count) pairs (pre-allocate for efficiency)
        tokenCountsSlice := make([]TokenCount, 0, len(tokenCounts))
        for token, count := range tokenCounts </span><span class="cov8" title="1">{
                tokenCountsSlice = append(tokenCountsSlice, TokenCount{Token: token, Count: count})
        }</span>

        // Step 2: Sort by count descending (most frequent first)
        <span class="cov8" title="1">sort.Slice(tokenCountsSlice, func(i, j int) bool </span><span class="cov8" title="1">{
                return tokenCountsSlice[i].Count &gt; tokenCountsSlice[j].Count
        }</span>)

        // Step 3: Calculate total count and class size
        <span class="cov8" title="1">total := 0
        for _, tc := range tokenCountsSlice </span><span class="cov8" title="1">{
                total += tc.Count
        }</span>
        <span class="cov8" title="1">if F &lt;= 0 </span><span class="cov0" title="0">{
                F = 1
        }</span>
        <span class="cov8" title="1">C := total / F

        // Step 4: Assign tokens to F classes (optimized)
        classes := make([][]string, F)
        classIdx := 0
        runningTotal := 0

        for _, pair := range tokenCountsSlice </span><span class="cov8" title="1">{
                if classIdx &lt; F-1 &amp;&amp; runningTotal &gt;= (classIdx+1)*C </span><span class="cov8" title="1">{
                        classIdx++
                }</span>
                <span class="cov8" title="1">classes[classIdx] = append(classes[classIdx], pair.Token)
                runningTotal += pair.Count</span>
        }

        // Step 5: Create F filters and insert tokens (parallel processing)
        <span class="cov8" title="1">filters := make([]FreqClassFilter, F)
        var wg sync.WaitGroup

        for i := 0; i &lt; F; i++ </span><span class="cov8" title="1">{
                wg.Add(1)
                go func(classIndex int) </span><span class="cov8" title="1">{
                        defer wg.Done()
                        tokenCount := len(classes[classIndex])

                        // Use hash set for small classes (threshold: 1000 tokens)
                        if tokenCount &lt; 1000 </span><span class="cov8" title="1">{
                                setFilter := &amp;SetFilter{tokens: make(map[string]bool, tokenCount)}
                                for _, token := range classes[classIndex] </span><span class="cov8" title="1">{
                                        setFilter.tokens[token] = true
                                }</span>
                                <span class="cov8" title="1">filters[classIndex] = setFilter</span>
                        } else<span class="cov0" title="0"> {
                                // Use Bloom filter for large classes
                                bloomSize := uint(tokenCount * 10) // Simple sizing
                                numHashes := uint(10)              // Simple hash count
                                if bloomSizes != nil &amp;&amp; classIndex &lt; len(bloomSizes) </span><span class="cov0" title="0">{
                                        bloomSize = bloomSizes[classIndex]
                                }</span>
                                <span class="cov0" title="0">if hashCounts != nil &amp;&amp; classIndex &lt; len(hashCounts) </span><span class="cov0" title="0">{
                                        numHashes = hashCounts[classIndex]
                                }</span>

                                <span class="cov0" title="0">bf := bloom.New(bloomSize, numHashes)
                                for _, token := range classes[classIndex] </span><span class="cov0" title="0">{
                                        bf.AddString(token)
                                }</span>
                                <span class="cov0" title="0">filters[classIndex] = &amp;BloomFilterWrapper{filter: bf}</span>
                        }
                }(i)
        }

        <span class="cov8" title="1">wg.Wait()

        // Log final class distribution
        for i := 0; i &lt; F; i++ </span><span class="cov8" title="1">{
                fmt.Printf("[AsyncFreqClass] Class %d assigned %d tokens\n", i+1, len(classes[i]))
        }</span>

        <span class="cov8" title="1">return FreqClassResult{
                Filters:   filters,
                TopTokens: tokenCountsSlice[:min(10, len(tokenCountsSlice))],
        }</span>
}

// min helper function
func min(a, b int) int <span class="cov8" title="1">{
        if a &lt; b </span><span class="cov8" title="1">{
                return a
        }</span>
        <span class="cov8" title="1">return b</span>
}

// BuildFrequencyClassHashSets divides tokens into F frequency classes and returns F hash set filters.
// Each class accounts for roughly the same number of token occurrences (not unique tokens).
func BuildFrequencyClassHashSets(tokenCounts map[string]int, F int, bloomSizes []uint, hashCounts []uint) FreqClassResult <span class="cov8" title="1">{
        // Step 1: Build a slice of (token, count) pairs
        tokenCountsSlice := make([]TokenCount, 0, len(tokenCounts))
        for token, count := range tokenCounts </span><span class="cov8" title="1">{
                tokenCountsSlice = append(tokenCountsSlice, TokenCount{Token: token, Count: count})
        }</span>

        // Step 2: Sort by count descending (most frequent first)
        <span class="cov8" title="1">sort.Slice(tokenCountsSlice, func(i, j int) bool </span><span class="cov8" title="1">{
                return tokenCountsSlice[i].Count &gt; tokenCountsSlice[j].Count
        }</span>)

        // Step 3: Calculate total count and class size
        <span class="cov8" title="1">total := 0
        for _, tc := range tokenCountsSlice </span><span class="cov8" title="1">{
                total += tc.Count
        }</span>
        <span class="cov8" title="1">if F &lt;= 0 </span><span class="cov0" title="0">{
                F = 1
        }</span>
        <span class="cov8" title="1">C := total / F

        // Step 4: Assign tokens to F classes
        classes := make([][]string, F)
        classIdx := 0
        runningTotal := 0

        fmt.Printf("*** DEBUG: Starting token distribution to %d classes ***\n", F)
        for _, pair := range tokenCountsSlice </span><span class="cov8" title="1">{
                if classIdx &lt; F-1 &amp;&amp; runningTotal &gt;= (classIdx+1)*C </span><span class="cov8" title="1">{
                        fmt.Printf("*** DEBUG: Advancing from class %d to class %d at running total %d (threshold: %d) ***\n",
                                classIdx+1, classIdx+2, runningTotal, (classIdx+1)*C)
                        classIdx++
                }</span>
                <span class="cov8" title="1">classes[classIdx] = append(classes[classIdx], pair.Token)
                runningTotal += pair.Count</span>
        }
        <span class="cov8" title="1">fmt.Printf("*** DEBUG: Token distribution complete. Final running total: %d ***\n", runningTotal)

        // Step 5: Create F hash set filters and insert tokens
        filters := make([]FreqClassFilter, F)
        for i := 0; i &lt; F; i++ </span><span class="cov8" title="1">{
                setFilter := &amp;SetFilter{tokens: make(map[string]bool, len(classes[i]))}
                for _, token := range classes[i] </span><span class="cov8" title="1">{
                        setFilter.tokens[token] = true
                }</span>
                <span class="cov8" title="1">filters[i] = setFilter</span>
        }

        // Log final class distribution with usage counts
        <span class="cov8" title="1">fmt.Printf("*** FREQUENCY CLASS REBUILD: Built %d classes ***\n", F)
        fmt.Printf("*** DEBUG: Total tokens to distribute: %d, Target per class: %d ***\n", total, C)
        for i := 0; i &lt; F; i++ </span><span class="cov8" title="1">{
                // Calculate total usage for this class
                classUsage := 0
                for _, token := range classes[i] </span><span class="cov8" title="1">{
                        for _, tc := range tokenCountsSlice </span><span class="cov8" title="1">{
                                if tc.Token == token </span><span class="cov8" title="1">{
                                        classUsage += tc.Count
                                        break</span>
                                }
                        }
                }
                <span class="cov8" title="1">fmt.Printf("  Class %d: %d distinct tokens, %d total usages\n", i+1, len(classes[i]), classUsage)
                if len(classes[i]) == 0 </span><span class="cov0" title="0">{
                        fmt.Printf("  *** WARNING: Class %d is empty! ***\n", i+1)
                }</span>
        }
        <span class="cov8" title="1">fmt.Printf("*** FREQUENCY CLASS REBUILD COMPLETE ***\n")

        return FreqClassResult{
                Filters:   filters,
                TopTokens: tokenCountsSlice[:min(10, len(tokenCountsSlice))],
        }</span>
}

var globalFiltersMutex sync.RWMutex
var globalFilters []FreqClassFilter

// SetGlobalFilters sets the global frequency class filters
func SetGlobalFilters(filters []FreqClassFilter) <span class="cov8" title="1">{
        globalFiltersMutex.Lock()
        defer globalFiltersMutex.Unlock()
        globalFilters = filters
        fmt.Printf("*** SetGlobalFilters called with %d filters ***\n", len(filters))
}</span>

// GetGlobalFilters returns the current global frequency class filters
func GetGlobalFilters() []FreqClassFilter <span class="cov0" title="0">{
        globalFiltersMutex.RLock()
        defer globalFiltersMutex.RUnlock()
        result := make([]FreqClassFilter, len(globalFilters))
        copy(result, globalFilters)
        //fmt.Printf("*** GetGlobalFilters called, returning %d filters ***\n", len(result))
        return result
}</span>

// SaveToFile saves the frequency class filters to a file
// Note: This only saves SetFilter types, not BloomFilterWrapper
func (fcr *FreqClassResult) SaveToFile(filename string) error <span class="cov8" title="1">{
        // Ensure the directory exists
        dir := filepath.Dir(filename)
        if err := os.MkdirAll(dir, 0755); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create directory %s: %v", dir, err)
        }</span>

        // Create the file
        <span class="cov8" title="1">file, err := os.Create(filename)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create file %s: %v", filename, err)
        }</span>
        <span class="cov8" title="1">defer file.Close()

        // Convert filters to serializable format
        serializableFilters := make([]SerializableFilter, len(fcr.Filters))
        for i, filter := range fcr.Filters </span><span class="cov8" title="1">{
                if setFilter, ok := filter.(*SetFilter); ok </span><span class="cov8" title="1">{
                        // Convert SetFilter to SerializableFilter
                        tokens := make([]string, 0, len(setFilter.tokens))
                        for token := range setFilter.tokens </span><span class="cov8" title="1">{
                                tokens = append(tokens, token)
                        }</span>
                        <span class="cov8" title="1">serializableFilters[i] = SerializableFilter{
                                Type:   "set",
                                Tokens: tokens,
                        }</span>
                } else<span class="cov0" title="0"> {
                        // Skip BloomFilterWrapper for now
                        serializableFilters[i] = SerializableFilter{
                                Type:   "bloom",
                                Tokens: []string{}, // Bloom filters not serialized
                        }
                }</span>
        }

        // Create serializable result
        <span class="cov8" title="1">serializableResult := struct {
                Filters   []SerializableFilter
                TopTokens []TokenCount
        }{
                Filters:   serializableFilters,
                TopTokens: fcr.TopTokens,
        }

        // Encode and write to file
        encoder := gob.NewEncoder(file)
        if err := encoder.Encode(serializableResult); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to encode filters to %s: %v", filename, err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// LoadFromFile loads frequency class filters from a file
func (fcr *FreqClassResult) LoadFromFile(filename string) error <span class="cov8" title="1">{
        // Open the file
        file, err := os.Open(filename)
        if err != nil </span><span class="cov8" title="1">{
                return fmt.Errorf("failed to open file %s: %v", filename, err)
        }</span>
        <span class="cov8" title="1">defer file.Close()

        // Decode the serializable result
        var serializableResult struct {
                Filters   []SerializableFilter
                TopTokens []TokenCount
        }
        decoder := gob.NewDecoder(file)
        if err := decoder.Decode(&amp;serializableResult); err != nil </span><span class="cov8" title="1">{
                return fmt.Errorf("failed to decode filters from %s: %v", filename, err)
        }</span>

        // Convert back to FreqClassFilter
        <span class="cov8" title="1">filters := make([]FreqClassFilter, len(serializableResult.Filters))
        for i, sf := range serializableResult.Filters </span><span class="cov8" title="1">{
                if sf.Type == "set" </span><span class="cov8" title="1">{
                        // Convert SerializableFilter back to SetFilter
                        setFilter := &amp;SetFilter{tokens: make(map[string]bool, len(sf.Tokens))}
                        for _, token := range sf.Tokens </span><span class="cov8" title="1">{
                                setFilter.tokens[token] = true
                        }</span>
                        <span class="cov8" title="1">filters[i] = setFilter</span>
                } else<span class="cov0" title="0"> {
                        // For bloom filters, create an empty SetFilter (placeholder)
                        filters[i] = &amp;SetFilter{tokens: make(map[string]bool)}
                }</span>
        }

        // Update the FreqClassResult
        <span class="cov8" title="1">fcr.Filters = filters
        fcr.TopTokens = serializableResult.TopTokens

        return nil</span>
}

// BuildFrequencyClassBloomFilters divides tokens into F frequency classes and returns F filters.
// Each class accounts for roughly the same number of token occurrences (not unique tokens).
// Small classes use hash sets, large classes use Bloom filters.
// bloomSizes and hashCounts are arrays of length F, one for each frequency class.
func BuildFrequencyClassBloomFilters(tc *TokenCounter, F int, bloomSizes []uint, hashCounts []uint) FreqClassResult <span class="cov0" title="0">{
        // Step 1: Build a slice of (token, count) pairs
        tokenCounts := make([]TokenCount, 0, len(tc.Counts()))
        for token, count := range tc.Counts() </span><span class="cov0" title="0">{
                tokenCounts = append(tokenCounts, TokenCount{Token: token, Count: count})
        }</span>

        // Step 2: Sort by count descending (most frequent first)
        <span class="cov0" title="0">sort.Slice(tokenCounts, func(i, j int) bool </span><span class="cov0" title="0">{
                return tokenCounts[i].Count &gt; tokenCounts[j].Count
        }</span>)

        // Log the top 10 most frequent tokens
        <span class="cov0" title="0">topN := 10
        if len(tokenCounts) &lt; topN </span><span class="cov0" title="0">{
                topN = len(tokenCounts)
        }</span>
        <span class="cov0" title="0">fmt.Printf("[FreqClass] Top %d tokens: ", topN)
        for i := 0; i &lt; topN; i++ </span><span class="cov0" title="0">{
                fmt.Printf("%s(%d) ", tokenCounts[i].Token, tokenCounts[i].Count)
        }</span>
        <span class="cov0" title="0">fmt.Println()

        // Step 3: Calculate total count and class size
        total := 0
        for _, tc := range tokenCounts </span><span class="cov0" title="0">{
                total += tc.Count
        }</span>
        <span class="cov0" title="0">if F &lt;= 0 </span><span class="cov0" title="0">{
                F = 1
        }</span>
        <span class="cov0" title="0">C := total / F
        fmt.Printf("[FreqClass] Total tokens: %d, Classes: %d, Target per class: %d\n", total, F, C)

        // Step 4: Assign tokens to F classes
        classes := make([][]string, F)
        classIdx := 0
        runningTotal := 0
        for _, pair := range tokenCounts </span><span class="cov0" title="0">{
                if classIdx &lt; F-1 &amp;&amp; runningTotal &gt;= (classIdx+1)*C </span><span class="cov0" title="0">{
                        fmt.Printf("[FreqClass] Advancing to class %d at running total %d\n", classIdx+1, runningTotal)
                        classIdx++
                }</span>
                <span class="cov0" title="0">classes[classIdx] = append(classes[classIdx], pair.Token)
                runningTotal += pair.Count</span>
        }

        // Log final class distribution
        <span class="cov0" title="0">for i := 0; i &lt; F; i++ </span><span class="cov0" title="0">{
                fmt.Printf("[FreqClass] Class %d assigned %d tokens\n", i+1, len(classes[i]))
        }</span>

        // Step 5: Create F filters and insert tokens
        <span class="cov0" title="0">filters := make([]FreqClassFilter, F)
        for i := 0; i &lt; F; i++ </span><span class="cov0" title="0">{
                tokenCount := len(classes[i])

                // Use hash set for small classes (threshold: 1000 tokens)
                if tokenCount &lt; 1000 </span><span class="cov0" title="0">{
                        setFilter := &amp;SetFilter{tokens: make(map[string]bool)}
                        for _, token := range classes[i] </span><span class="cov0" title="0">{
                                setFilter.tokens[token] = true
                        }</span>
                        <span class="cov0" title="0">filters[i] = setFilter

                        // Log the number of tokens and total occurrences in this class
                        totalClassCount := 0
                        for _, token := range classes[i] </span><span class="cov0" title="0">{
                                for _, tc := range tokenCounts </span><span class="cov0" title="0">{
                                        if tc.Token == token </span><span class="cov0" title="0">{
                                                totalClassCount += tc.Count
                                        }</span>
                                }
                        }
                        <span class="cov0" title="0">fmt.Printf("[FreqClass] Class %d: %d tokens, %d total occurrences, using HASH SET\n",
                                i+1, len(classes[i]), totalClassCount)</span>
                } else<span class="cov0" title="0"> {
                        // Use Bloom filter for large classes
                        bloomSize := bloomSizes[i]
                        numHashes := hashCounts[i]
                        bf := bloom.New(bloomSize, numHashes)
                        for _, token := range classes[i] </span><span class="cov0" title="0">{
                                bf.AddString(token)
                        }</span>
                        <span class="cov0" title="0">filters[i] = &amp;BloomFilterWrapper{filter: bf}

                        // Log the number of tokens and total occurrences in this class
                        totalClassCount := 0
                        for _, token := range classes[i] </span><span class="cov0" title="0">{
                                for _, tc := range tokenCounts </span><span class="cov0" title="0">{
                                        if tc.Token == token </span><span class="cov0" title="0">{
                                                totalClassCount += tc.Count
                                        }</span>
                                }
                        }
                        <span class="cov0" title="0">fmt.Printf("[FreqClass] Class %d: %d tokens, %d total occurrences, bloom_size=%d, hash_count=%d\n",
                                i+1, len(classes[i]), totalClassCount, bloomSize, numHashes)</span>
                }
        }

        <span class="cov0" title="0">return FreqClassResult{
                Filters:   filters,
                TopTokens: tokenCounts[:topN],
        }</span>
}

// GetTokenFrequencyClass returns the frequency class index for a token.
// Checks filters in order from most frequent to least frequent.
// If the token is not found in any class, returns the last index (least frequent class).
func GetTokenFrequencyClass(token string) int <span class="cov0" title="0">{
        filters := GetGlobalFilters() // Thread-safe getter
        if len(filters) == 0 </span><span class="cov0" title="0">{
                fmt.Printf("WARNING: No frequency class filters available, assigning token '%s' to class 0\n", token)
                return 0 // Defensive: if no filters, return 0
        }</span>

        // Debug: Log filter status occasionally (but not too often)
        // Note: This is a simple approach - in production you'd want a thread-safe counter
        // For now, we'll just log the first few calls to see what's happening
        <span class="cov0" title="0">if len(filters) &gt; 0 </span><span class="cov0" title="0">{
                // Check if this is a SetFilter and has tokens
                if setFilter, ok := filters[0].(*SetFilter); ok </span><span class="cov0" title="0">{
                        if len(setFilter.tokens) == 0 </span><span class="cov0" title="0">{
                                fmt.Printf("WARNING: Frequency class filter 0 is empty\n")
                        }</span>
                }
        }

        <span class="cov0" title="0">for i, filter := range filters </span><span class="cov0" title="0">{
                if filter.Contains(token) </span><span class="cov0" title="0">{
                        return i
                }</span>
        }
        // Not found: assign to least frequent class
        <span class="cov0" title="0">return len(filters) - 1</span>
}
</pre>
		
		<pre class="file" id="file3" style="display: none">package pipeline

import (
        "cursor-twitter/src/tweets"
        "encoding/gob"
        "fmt"
        "os"
        "path/filepath"
        "sync"
        "sync/atomic"
        "time"

        "log/slog"
)

// Global flag to track when persistence is in progress
var persistenceInProgress int32 // Atomic flag: 0 = not in progress, 1 = in progress

// FrequencyComputationThread (FCT) manages token counting and frequency calculations
// in a separate goroutine to avoid blocking the main tweet processing pipeline.
type FrequencyComputationThread struct {
        // Token processing
        tokenCounter      *TokenCounter
        inboundTokenQueue *TokenQueue
        oldTokenQueue     *TokenQueue

        // Frequency calculation control
        shouldRebuild int32 // Atomic boolean (0 = false, 1 = true)

        // Thread control
        stopChan chan struct{}
        wg       sync.WaitGroup

        // Configuration
        freqClassInterval time.Duration
        freqClasses       int

        // Current filters (thread-safe access)
        currentFilters []FreqClassFilter
        filtersMutex   sync.RWMutex

        // Debug: Track rebuild count
        rebuildCount      int
        rebuildCountMutex sync.Mutex
}

// NewFrequencyComputationThread creates a new FCT with the specified configuration
func NewFrequencyComputationThread(
        tokenCounter *TokenCounter,
        inboundTokenQueue *TokenQueue,
        oldTokenQueue *TokenQueue,
        freqClassIntervalTweets int,
        freqClasses int,
) *FrequencyComputationThread <span class="cov8" title="1">{
        return &amp;FrequencyComputationThread{
                tokenCounter:      tokenCounter,
                inboundTokenQueue: inboundTokenQueue,
                oldTokenQueue:     oldTokenQueue,
                stopChan:          make(chan struct{}),
                freqClassInterval: time.Duration(freqClassIntervalTweets) * time.Second, // Not used in current implementation
                freqClasses:       freqClasses,
        }
}</span>

// Start begins the FCT goroutine
func (fct *FrequencyComputationThread) Start() <span class="cov8" title="1">{
        slog.Info("FCT Start method called")
        fct.wg.Add(1)
        go fct.run()
        slog.Info("FCT goroutine launched")
        slog.Info("FrequencyComputationThread started",
                "freq_class_interval_tweets", fct.freqClassInterval.Seconds(),
                "freq_classes", fct.freqClasses)
}</span>

// Stop gracefully stops the FCT goroutine
func (fct *FrequencyComputationThread) Stop() <span class="cov8" title="1">{
        close(fct.stopChan)
        fct.wg.Wait()
        slog.Info("FrequencyComputationThread stopped")
}</span>

// TriggerRebuild signals that a frequency class rebuild is needed
// The FCT will handle the rebuild autonomously when it's ready
func (fct *FrequencyComputationThread) TriggerRebuild() <span class="cov8" title="1">{
        atomic.StoreInt32(&amp;fct.shouldRebuild, 1)
        slog.Info("FCT: Rebuild flag SET - frequency boundary crossed")
}</span>

// run is the main loop of the FCT goroutine
func (fct *FrequencyComputationThread) run() <span class="cov8" title="1">{
        defer fct.wg.Done()

        // Add panic recovery
        defer func() </span><span class="cov8" title="1">{
                if r := recover(); r != nil </span><span class="cov0" title="0">{
                        slog.Error("FCT run loop panicked", "panic", r)
                }</span>
                <span class="cov8" title="1">slog.Info("FCT run method exiting")</span>
        }()

        <span class="cov8" title="1">slog.Info("FCT run method entered")
        slog.Info("FCT run loop starting")

        loopCount := 0
        for </span><span class="cov8" title="1">{
                select </span>{
                case &lt;-fct.stopChan:<span class="cov8" title="1">
                        slog.Info("FCT run loop stopping")
                        return</span>
                default:<span class="cov8" title="1">
                        loopCount++
                        if loopCount%10000 == 0 </span><span class="cov0" title="0">{ // Log every 10,000 iterations
                                slog.Info("FCT loop iteration", "count", loopCount)
                        }</span>
                        <span class="cov8" title="1">if loopCount%100000 == 0 </span><span class="cov0" title="0">{ // Log every 100,000 iterations to confirm it's running
                                slog.Info("FCT: Loop is running, iteration", "count", loopCount)
                        }</span>

                        // Check if rebuild is needed first
                        <span class="cov8" title="1">shouldRebuild := atomic.LoadInt32(&amp;fct.shouldRebuild) == 1

                        // Debug: Log rebuild flag status more frequently
                        if loopCount%1000 == 0 </span><span class="cov0" title="0">{
                                slog.Info("FCT: Rebuild flag check",
                                        "loop_count", loopCount,
                                        "should_rebuild", shouldRebuild)
                        }</span>

                        // ALWAYS log when rebuild flag is true (this should be rare)
                        <span class="cov8" title="1">if shouldRebuild </span><span class="cov8" title="1">{
                                slog.Info("FCT: REBUILD FLAG DETECTED!",
                                        "loop_count", loopCount,
                                        "should_rebuild", shouldRebuild)
                        }</span>

                        // Debug: Log the branch we're taking more frequently
                        <span class="cov8" title="1">if loopCount%1000 == 0 </span><span class="cov0" title="0">{
                                if shouldRebuild </span><span class="cov0" title="0">{
                                        slog.Info("FCT: Taking rebuild branch", "loop_count", loopCount)
                                }</span> else<span class="cov0" title="0"> {
                                        slog.Debug("FCT: Taking token processing branch", "loop_count", loopCount)
                                }</span>
                        }

                        <span class="cov8" title="1">if shouldRebuild </span><span class="cov8" title="1">{
                                // Increment rebuild count
                                fct.rebuildCountMutex.Lock()
                                fct.rebuildCount++
                                currentRebuildCount := fct.rebuildCount
                                fct.rebuildCountMutex.Unlock()

                                // Consume all accumulated tokens before starting computation
                                slog.Info("FCT: Consuming accumulated tokens before rebuild", "rebuild_count", currentRebuildCount)
                                fct.consumeAllAccumulatedTokens()

                                rebuildStartTime := time.Now()
                                slog.Info("FCT: Starting rebuild", "rebuild_count", currentRebuildCount, "start_time", rebuildStartTime.Format("15:04:05"))
                                fmt.Printf("*** FCT REBUILD STARTED at %s ***\n", rebuildStartTime.Format("15:04:05"))
                                // Pause token processing and do rebuild
                                fct.performRebuild()

                                // Debug: Log queue sizes after rebuild
                                inboundSizeAfter := fct.inboundTokenQueue.Len()
                                oldSizeAfter := fct.oldTokenQueue.Len()
                                slog.Info("FCT: Queue sizes after rebuild",
                                        "rebuild_count", currentRebuildCount,
                                        "inbound_queue_size", inboundSizeAfter,
                                        "old_queue_size", oldSizeAfter)

                        }</span>

                        // Process a small amount of tokens (main loop body - always happens)
                        <span class="cov8" title="1">fct.processTokens()

                        // Add a small delay when no tokens are being processed to prevent CPU spinning
                        inboundSize := fct.inboundTokenQueue.Len()
                        oldSize := fct.oldTokenQueue.Len()
                        if inboundSize == 0 &amp;&amp; oldSize == 0 </span><span class="cov8" title="1">{
                                time.Sleep(1 * time.Millisecond)
                        }</span>

                        // Debug: Log when queues are empty
                        <span class="cov8" title="1">if loopCount%1000 == 0 &amp;&amp; inboundSize == 0 &amp;&amp; oldSize == 0 </span><span class="cov0" title="0">{
                                slog.Debug("FCT: No tokens to process, waiting...",
                                        "loop_count", loopCount,
                                        "inbound_queue_size", inboundSize,
                                        "old_queue_size", oldSize)
                        }</span>
                }
        }
}

// processTokens processes tokens from both queues
func (fct *FrequencyComputationThread) processTokens() <span class="cov8" title="1">{
        // Only log when we actually process tokens or when queues have significant backlog
        inboundProcessed := 0
        for </span><span class="cov8" title="1">{
                tokens := fct.inboundTokenQueue.Dequeue()
                if tokens == nil </span><span class="cov8" title="1">{
                        break</span> // Queue is empty
                }
                <span class="cov8" title="1">fct.tokenCounter.IncrementTokens(tokens)
                inboundProcessed += len(tokens)</span>
        }

        // Process old tokens (decrement counts)
        <span class="cov8" title="1">oldProcessed := 0
        for </span><span class="cov8" title="1">{
                tokens := fct.oldTokenQueue.Dequeue()
                if tokens == nil </span><span class="cov8" title="1">{
                        break</span> // Queue is empty
                }
                <span class="cov8" title="1">fct.tokenCounter.DecrementTokens(tokens)
                oldProcessed += len(tokens)</span>
        }

        // Only log if we processed tokens or if queues are getting backed up
        <span class="cov8" title="1">if inboundProcessed &gt; 0 || oldProcessed &gt; 0 </span><span class="cov8" title="1">{
                slog.Info("FCT processed tokens",
                        "inbound_processed", inboundProcessed,
                        "old_processed", oldProcessed,
                        "inbound_queue_size_after", fct.inboundTokenQueue.Len(),
                        "old_queue_size_after", fct.oldTokenQueue.Len())
        }</span> else<span class="cov8" title="1"> {
                // Check if queues are getting backed up but we didn't process anything
                currentInboundSize := fct.inboundTokenQueue.Len()
                currentOldSize := fct.oldTokenQueue.Len()
                if currentInboundSize &gt; 100 || currentOldSize &gt; 100 </span><span class="cov0" title="0">{
                        slog.Warn("FCT queues have backlog but processed no tokens",
                                "inbound_queue_size", currentInboundSize,
                                "old_queue_size", currentOldSize)
                }</span>
        }

        // Debug: Log every 1000 calls to processTokens to confirm it's being called
        // Note: This is a simple counter for debugging - in production this would be removed
        // or made thread-safe if needed
}

// checkForRebuild method removed - rebuild logic now integrated into main loop

// performRebuild performs the actual frequency class calculation and filter building
func (fct *FrequencyComputationThread) performRebuild() <span class="cov8" title="1">{
        // Reset the rebuild flag immediately so loop can detect new rebuild requests
        atomic.StoreInt32(&amp;fct.shouldRebuild, 0)
        slog.Info("FCT: Rebuild flag RESET at start of performRebuild")

        startTime := time.Now()
        slog.Info("Starting frequency class rebuild")

        // Get a snapshot of current token counts for frequency calculations
        tokenCounts := fct.tokenCounter.CountsSnapshot()

        // Perform the frequency class calculation
        slog.Info("FCT: About to call BuildFrequencyClassHashSets", "token_count", len(tokenCounts), "freq_classes", fct.freqClasses)
        result := BuildFrequencyClassHashSets(tokenCounts, fct.freqClasses, nil, nil)
        slog.Info("FCT: BuildFrequencyClassHashSets returned", "filters_built", len(result.Filters))

        // Clear the token counter after frequency calculation
        // This ensures each rebuild is based only on the current window's tokens
        fct.tokenCounter.Clear()

        // Store the filters for the main thread to access
        fct.filtersMutex.Lock()
        fct.currentFilters = result.Filters
        fct.filtersMutex.Unlock()

        // Also install globally for main thread
        fmt.Printf("*** ABOUT TO INSTALL FILTERS GLOBALLY ***\n")
        SetGlobalFilters(result.Filters)
        fmt.Printf("*** FILTERS INSTALLED GLOBALLY ***\n")

        // Save the data structures to files
        savePersistedState(result, tokenCounts)

        duration := time.Since(startTime)
        completionTime := time.Now()
        slog.Info("Frequency class rebuild completed",
                "duration", duration,
                "completion_time", completionTime.Format("15:04:05"),
                "token_count", len(tokenCounts),
                "filters_built", len(result.Filters))

        // Also print to stdout for immediate visibility
        fmt.Printf("*** FREQUENCY REBUILD COMPLETED at %s (duration: %v) ***\n",
                completionTime.Format("15:04:05"), duration)

        // Add diagnostic line to show filters are installed
        slog.Info("INSTALLED: frequency class filters are now active",
                "num_filters", len(result.Filters))

        // Print to stdout for immediate visibility
        fmt.Printf("*** FREQUENCY FILTERS INSTALLED: %d filters now active ***\n", len(result.Filters))

        // Log top tokens for debugging
        if len(result.TopTokens) &gt; 0 </span><span class="cov8" title="1">{
                slog.Debug("Top tokens after rebuild",
                        "top_token", result.TopTokens[0].Token,
                        "top_count", result.TopTokens[0].Count)
        }</span>
}

// GetQueueStats returns statistics about the current queue states
func (fct *FrequencyComputationThread) GetQueueStats() map[string]int <span class="cov8" title="1">{
        return map[string]int{
                "inbound_token_queue_size": fct.inboundTokenQueue.Len(),
                "old_token_queue_size":     fct.oldTokenQueue.Len(),
                "distinct_tokens":          len(fct.tokenCounter.Counts()),
        }
}</span>

// GetCurrentFilters returns the current frequency class filters (thread-safe)
func (fct *FrequencyComputationThread) GetCurrentFilters() []FreqClassFilter <span class="cov0" title="0">{
        fct.filtersMutex.RLock()
        defer fct.filtersMutex.RUnlock()
        return fct.currentFilters
}</span>

// GetRebuildCount returns the number of rebuilds performed (for debugging)
func (fct *FrequencyComputationThread) GetRebuildCount() int <span class="cov0" title="0">{
        fct.rebuildCountMutex.Lock()
        defer fct.rebuildCountMutex.Unlock()
        return fct.rebuildCount
}</span>

// consumeAllAccumulatedTokens processes tokens from both queues using queue size snapshots
func (fct *FrequencyComputationThread) consumeAllAccumulatedTokens() <span class="cov8" title="1">{
        // Get current queue sizes (snapshot to prevent infinite catch-up)
        inboundQueueSize := fct.inboundTokenQueue.Len()
        oldQueueSize := fct.oldTokenQueue.Len()

        slog.Info("FCT: Starting token consumption with queue snapshot",
                "inbound_queue_size", inboundQueueSize,
                "old_queue_size", oldQueueSize)

        inboundProcessed := 0
        oldProcessed := 0

        // Process exactly inboundQueueSize tokens from inbound queue
        for i := 0; i &lt; inboundQueueSize; i++ </span><span class="cov0" title="0">{
                tokens := fct.inboundTokenQueue.Dequeue()
                if tokens == nil </span><span class="cov0" title="0">{
                        break</span> // Queue is empty (shouldn't happen given our size check)
                }
                <span class="cov0" title="0">fct.tokenCounter.IncrementTokens(tokens)
                inboundProcessed += len(tokens)</span>
        }

        // Process exactly oldQueueSize tokens from old queue
        <span class="cov8" title="1">for i := 0; i &lt; oldQueueSize; i++ </span><span class="cov0" title="0">{
                tokens := fct.oldTokenQueue.Dequeue()
                if tokens == nil </span><span class="cov0" title="0">{
                        break</span> // Queue is empty (shouldn't happen given our size check)
                }
                <span class="cov0" title="0">fct.tokenCounter.DecrementTokens(tokens)
                oldProcessed += len(tokens)</span>
        }

        <span class="cov8" title="1">slog.Info("FCT: Consumed tokens using queue snapshot",
                "inbound_processed", inboundProcessed,
                "old_processed", oldProcessed,
                "inbound_queue_size_after", fct.inboundTokenQueue.Len(),
                "old_queue_size_after", fct.oldTokenQueue.Len())</span>
}

// savePersistedState saves the data structures to files
func savePersistedState(result FreqClassResult, tokenCounts map[string]int) <span class="cov8" title="1">{
        // Set persistence flag
        atomic.StoreInt32(&amp;persistenceInProgress, 1)
        defer atomic.StoreInt32(&amp;persistenceInProgress, 0)

        slog.Info("Starting to save persisted state")
        fmt.Printf("*** SAVING PERSISTED STATE ***\n")
        saveStartTime := time.Now()

        // Get the state directory from config (hardcoded for now, could be made configurable)
        stateDir := "../data/state"

        // Save TokenCounter
        tokenCounter := NewTokenCounter()
        for token, count := range tokenCounts </span><span class="cov8" title="1">{
                for i := 0; i &lt; count; i++ </span><span class="cov8" title="1">{
                        tokenCounter.IncrementTokens([]string{token})
                }</span>
        }
        <span class="cov8" title="1">tokenCounterPath := filepath.Join(stateDir, "token_counter.json")
        if err := tokenCounter.SaveToFile(tokenCounterPath); err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to save TokenCounter", "error", err, "path", tokenCounterPath)
        }</span> else<span class="cov8" title="1"> {
                fmt.Printf("TokenCounter saved: %d total tokens (%d distinct tokens)\n", len(tokenCounts), len(tokenCounts))
        }</span>

        // Save FrequencyClassResult
        <span class="cov8" title="1">freqClassPath := filepath.Join(stateDir, "frequency_classes.json")
        if err := result.SaveToFile(freqClassPath); err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to save FrequencyClassResult", "error", err, "path", freqClassPath)
        }</span> else<span class="cov8" title="1"> {
                fmt.Printf("FrequencyClassResult saved: %d classes\n", len(result.Filters))
        }</span>

        // Save ThreePartKey mappings
        <span class="cov8" title="1">threePKPath := filepath.Join(stateDir, "threepartkey_mappings.json")
        if err := saveThreePartKeyMappingsToFile(threePKPath, TokenTo3PK); err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to save ThreePartKey mappings", "error", err, "path", threePKPath)
        }</span> else<span class="cov8" title="1"> {
                fmt.Printf("ThreePartKey mappings saved: %d mappings\n", len(TokenTo3PK))
        }</span>

        <span class="cov8" title="1">saveDuration := time.Since(saveStartTime)
        slog.Info("Persisted state saving completed", "duration", saveDuration.String())
        fmt.Printf("*** PERSISTED STATE SAVED in %v ***\n", saveDuration)

        fmt.Println("=== PERSISTED STATE SAVED ===")</span>
}

// IsPersistenceInProgress returns true if persistence operations are currently running
func IsPersistenceInProgress() bool <span class="cov0" title="0">{
        return atomic.LoadInt32(&amp;persistenceInProgress) == 1
}</span>

// saveThreePartKeyMappingsToFile saves ThreePartKey mappings to a file
func saveThreePartKeyMappingsToFile(filename string, mapping map[string]tweets.ThreePartKey) error <span class="cov8" title="1">{
        token3PKMutex.RLock()
        snapshot := make(map[string]tweets.ThreePartKey, len(mapping))
        for k, v := range mapping </span><span class="cov0" title="0">{
                snapshot[k] = v
        }</span>
        <span class="cov8" title="1">token3PKMutex.RUnlock()
        // Ensure the directory exists
        dir := filepath.Dir(filename)
        if err := os.MkdirAll(dir, 0755); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create directory %s: %v", dir, err)
        }</span>

        // Create the file
        <span class="cov8" title="1">file, err := os.Create(filename)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create file %s: %v", filename, err)
        }</span>
        <span class="cov8" title="1">defer file.Close()

        // Encode and write to file (use the snapshot, not the live map)
        encoder := gob.NewEncoder(file)
        if err := encoder.Encode(snapshot); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to encode mappings to %s: %v", filename, err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}
</pre>
		
		<pre class="file" id="file4" style="display: none">package pipeline

import (
        "sync"
)

// TokenQueue is a thread-safe queue for storing token arrays
type TokenQueue struct {
        items [][]string
        mu    sync.RWMutex
}

// NewTokenQueue creates a new empty TokenQueue
func NewTokenQueue() *TokenQueue <span class="cov8" title="1">{
        return &amp;TokenQueue{
                items: make([][]string, 0),
        }
}</span>

// Enqueue adds a slice of tokens to the end of the queue
func (tq *TokenQueue) Enqueue(tokens []string) <span class="cov8" title="1">{
        tq.mu.Lock()
        defer tq.mu.Unlock()
        tq.items = append(tq.items, tokens)
}</span>

// Dequeue removes and returns the first slice of tokens from the queue
// Returns nil if the queue is empty
func (tq *TokenQueue) Dequeue() []string <span class="cov8" title="1">{
        tq.mu.Lock()
        defer tq.mu.Unlock()

        if len(tq.items) == 0 </span><span class="cov8" title="1">{
                return nil
        }</span>

        // Get the first item
        <span class="cov8" title="1">tokens := tq.items[0]

        // Remove it from the queue
        tq.items = tq.items[1:]

        return tokens</span>
}

// Len returns the number of token arrays in the queue
func (tq *TokenQueue) Len() int <span class="cov8" title="1">{
        tq.mu.RLock()
        defer tq.mu.RUnlock()
        return len(tq.items)
}</span>

// Clear removes all items from the queue
func (tq *TokenQueue) Clear() <span class="cov0" title="0">{
        tq.mu.Lock()
        defer tq.mu.Unlock()
        tq.items = make([][]string, 0)
}</span>
</pre>
		
		<pre class="file" id="file5" style="display: none">package pipeline

import (
        "crypto/md5"
        "cursor-twitter/src/tweets"
        "encoding/binary"
        "sync"
)

var TokenTo3PK = make(map[string]tweets.ThreePartKey)
var ThreePKToToken = make(map[tweets.ThreePartKey]string)
var token3PKMutex sync.RWMutex

// Global array length for 3PK generation (set from main.go)
var GlobalArrayLen int = 1000 // Default, will be set from config

func GenerateThreePartKey(token string) tweets.ThreePartKey <span class="cov0" title="0">{
        a := hashWithSuffix(token, "__0NE__", GlobalArrayLen)
        b := hashWithSuffix(token, "__TW0__", GlobalArrayLen)
        c := hashWithSuffix(token, "__THR33__", GlobalArrayLen)
        key := tweets.ThreePartKey{Part1: a, Part2: b, Part3: c}
        // Store in global maps if not already present
        token3PKMutex.RLock()
        _, exists := TokenTo3PK[token]
        token3PKMutex.RUnlock()
        if !exists </span><span class="cov0" title="0">{
                token3PKMutex.Lock()
                TokenTo3PK[token] = key
                ThreePKToToken[key] = token
                token3PKMutex.Unlock()
        }</span>
        <span class="cov0" title="0">return key</span>
}

func hashWithSuffix(token, suffix string, modulo int) int <span class="cov0" title="0">{
        h := md5.Sum([]byte(token + suffix))
        return int(binary.BigEndian.Uint32(h[:4])) % modulo
}</span>

// SetGlobalArrayLen sets the global array length for 3PK generation
func SetGlobalArrayLen(arrayLen int) <span class="cov0" title="0">{
        GlobalArrayLen = arrayLen
}</span>
</pre>
		
		<pre class="file" id="file6" style="display: none">package pipeline

import (
        "encoding/gob"
        "fmt"
        "os"
        "path/filepath"
        "sync"
)

// TokenCounter keeps track of how many times each token appears in the current window.
// Uses record-level locking for thread safety with minimal contention.
type TokenCounter struct {
        counts map[string]int
        mu     sync.RWMutex
}

// NewTokenCounter creates a new TokenCounter with an empty map.
func NewTokenCounter() *TokenCounter <span class="cov8" title="1">{
        return &amp;TokenCounter{counts: make(map[string]int)}
}</span>

// IncrementTokens increases the count for each token in the list.
// Call this when a new tweet enters the window.
func (tc *TokenCounter) IncrementTokens(tokens []string) <span class="cov8" title="1">{
        tc.mu.Lock()
        defer tc.mu.Unlock()
        for _, token := range tokens </span><span class="cov8" title="1">{
                tc.counts[token]++
        }</span>
}

// DecrementTokens decreases the count for each token in the list.
// Call this when an old tweet leaves the window.
func (tc *TokenCounter) DecrementTokens(tokens []string) <span class="cov8" title="1">{
        tc.mu.Lock()
        defer tc.mu.Unlock()
        for _, token := range tokens </span><span class="cov8" title="1">{
                tc.counts[token]--
                if tc.counts[token] &lt;= 0 </span><span class="cov8" title="1">{
                        delete(tc.counts, token) // Clean up to save memory
                }</span>
        }
}

// GetCount returns the count for a specific token.
func (tc *TokenCounter) GetCount(token string) int <span class="cov8" title="1">{
        tc.mu.RLock()
        defer tc.mu.RUnlock()
        return tc.counts[token]
}</span>

// Counts returns the map of all token counts (for stats reporting).
// This creates a snapshot of the current counts for thread safety.
func (tc *TokenCounter) Counts() map[string]int <span class="cov8" title="1">{
        tc.mu.RLock()
        defer tc.mu.RUnlock()

        // Create a copy to avoid race conditions
        snapshot := make(map[string]int, len(tc.counts))
        for token, count := range tc.counts </span><span class="cov8" title="1">{
                snapshot[token] = count
        }</span>
        <span class="cov8" title="1">return snapshot</span>
}

// CountsSnapshot returns a snapshot of token counts optimized for frequency calculations.
// This method is designed to be called from the background frequency calculation goroutine.
//
// TRADE-OFFS:
// - Creates a copy to avoid concurrent map access errors
// - Slightly slower but thread-safe
// - Suitable for frequency calculations where "pretty good is good enough"
func (tc *TokenCounter) CountsSnapshot() map[string]int <span class="cov8" title="1">{
        tc.mu.RLock()
        defer tc.mu.RUnlock()

        // Create a copy to avoid "concurrent map iteration and map write" errors
        // This is safer than returning a direct reference
        snapshot := make(map[string]int, len(tc.counts))
        for token, count := range tc.counts </span><span class="cov8" title="1">{
                snapshot[token] = count
        }</span>
        <span class="cov8" title="1">return snapshot</span>
}

// Clear resets all token counts to zero.
// Call this after frequency calculations to start fresh for the next window.
func (tc *TokenCounter) Clear() <span class="cov8" title="1">{
        tc.mu.Lock()
        defer tc.mu.Unlock()
        // Clear the map by creating a new one
        tc.counts = make(map[string]int)
}</span>

// SaveToFile saves the current token counts to a file using gob encoding
func (tc *TokenCounter) SaveToFile(filename string) error <span class="cov8" title="1">{
        // Ensure the directory exists
        dir := filepath.Dir(filename)
        if err := os.MkdirAll(dir, 0755); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create directory %s: %v", dir, err)
        }</span>

        // Create the file
        <span class="cov8" title="1">file, err := os.Create(filename)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create file %s: %v", filename, err)
        }</span>
        <span class="cov8" title="1">defer file.Close()

        // Get a snapshot of the counts
        counts := tc.CountsSnapshot()

        // Encode and write to file
        encoder := gob.NewEncoder(file)
        if err := encoder.Encode(counts); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to encode counts to %s: %v", filename, err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// LoadFromFile loads token counts from a file using gob decoding
func (tc *TokenCounter) LoadFromFile(filename string) error <span class="cov8" title="1">{
        // Open the file
        file, err := os.Open(filename)
        if err != nil </span><span class="cov8" title="1">{
                return fmt.Errorf("failed to open file %s: %v", filename, err)
        }</span>
        <span class="cov8" title="1">defer file.Close()

        // Decode the counts
        var counts map[string]int
        decoder := gob.NewDecoder(file)
        if err := decoder.Decode(&amp;counts); err != nil </span><span class="cov8" title="1">{
                return fmt.Errorf("failed to decode counts from %s: %v", filename, err)
        }</span>

        // Replace the current counts with the loaded ones
        <span class="cov8" title="1">tc.mu.Lock()
        defer tc.mu.Unlock()
        tc.counts = counts

        return nil</span>
}
</pre>
		
		</div>
	</body>
	<script>
	(function() {
		var files = document.getElementById('files');
		var visible;
		files.addEventListener('change', onChange, false);
		function select(part) {
			if (visible)
				visible.style.display = 'none';
			visible = document.getElementById(part);
			if (!visible)
				return;
			files.value = part;
			visible.style.display = 'block';
			location.hash = part;
		}
		function onChange() {
			select(files.value);
			window.scrollTo(0, 0);
		}
		if (location.hash != "") {
			select(location.hash.substr(1));
		}
		if (!visible) {
			select("file0");
		}
	})();
	</script>
</html>
