
<!DOCTYPE html>
<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<title>cursor-twitter: Go Coverage Report</title>
		<style>
			body {
				background: black;
				color: rgb(80, 80, 80);
			}
			body, pre, #legend span {
				font-family: Menlo, monospace;
				font-weight: bold;
			}
			#topbar {
				background: black;
				position: fixed;
				top: 0; left: 0; right: 0;
				height: 42px;
				border-bottom: 1px solid rgb(80, 80, 80);
			}
			#content {
				margin-top: 50px;
			}
			#nav, #legend {
				float: left;
				margin-left: 10px;
			}
			#legend {
				margin-top: 12px;
			}
			#nav {
				margin-top: 10px;
			}
			#legend span {
				margin: 0 5px;
			}
			.cov0 { color: rgb(192, 0, 0) }
.cov1 { color: rgb(128, 128, 128) }
.cov2 { color: rgb(116, 140, 131) }
.cov3 { color: rgb(104, 152, 134) }
.cov4 { color: rgb(92, 164, 137) }
.cov5 { color: rgb(80, 176, 140) }
.cov6 { color: rgb(68, 188, 143) }
.cov7 { color: rgb(56, 200, 146) }
.cov8 { color: rgb(44, 212, 149) }
.cov9 { color: rgb(32, 224, 152) }
.cov10 { color: rgb(20, 236, 155) }

		</style>
	</head>
	<body>
		<div id="topbar">
			<div id="nav">
				<select id="files">
				
				<option value="file0">cursor-twitter/analyze_tokens.go (0.0%)</option>
				
				<option value="file1">cursor-twitter/parser/parser.go (0.0%)</option>
				
				<option value="file2">cursor-twitter/src/filter/word_filter.go (97.1%)</option>
				
				<option value="file3">cursor-twitter/src/main.go (17.1%)</option>
				
				<option value="file4">cursor-twitter/src/pipeline/busy_word_processors.go (0.0%)</option>
				
				<option value="file5">cursor-twitter/src/pipeline/frequency_classes.go (54.5%)</option>
				
				<option value="file6">cursor-twitter/src/pipeline/frequency_computation_thread.go (80.2%)</option>
				
				<option value="file7">cursor-twitter/src/pipeline/queues.go (82.4%)</option>
				
				<option value="file8">cursor-twitter/src/pipeline/threepartkey.go (0.0%)</option>
				
				<option value="file9">cursor-twitter/src/pipeline/tokencounter.go (94.3%)</option>
				
				<option value="file10">cursor-twitter/src/rabbitmq.go (0.0%)</option>
				
				</select>
			</div>
			<div id="legend">
				<span>not tracked</span>
			
				<span class="cov0">not covered</span>
				<span class="cov8">covered</span>
			
			</div>
		</div>
		<div id="content">
		
		<pre class="file" id="file0" style="display: none">package main

import (
        "bufio"
        "encoding/csv"
        "flag"
        "fmt"
        "io"
        "os"
        "path/filepath"
        "regexp"
        "sort"
        "strings"
        "time"
)

// Simple tokenizer: splits on non-word characters, lowercases, removes empty tokens
func simpleTokenize(text string) []string <span class="cov0" title="0">{
        // Remove punctuation, split on whitespace
        re := regexp.MustCompile(`\W+`)
        tokens := re.Split(strings.ToLower(text), -1)
        var out []string
        for _, t := range tokens </span><span class="cov0" title="0">{
                t = strings.TrimSpace(t)
                if t != "" </span><span class="cov0" title="0">{
                        out = append(out, t)
                }</span>
        }
        <span class="cov0" title="0">return out</span>
}

// Reads all CSV files in a directory (non-recursive)
func getCSVFiles(dir string) ([]string, error) <span class="cov0" title="0">{
        var files []string
        entries, err := os.ReadDir(dir)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">for _, entry := range entries </span><span class="cov0" title="0">{
                if !entry.IsDir() &amp;&amp; strings.HasSuffix(entry.Name(), ".csv") </span><span class="cov0" title="0">{
                        files = append(files, filepath.Join(dir, entry.Name()))
                }</span>
        }
        // Sort for reproducibility
        <span class="cov0" title="0">sort.Strings(files)
        return files, nil</span>
}

func main() <span class="cov0" title="0">{
        inputDir := flag.String("input", "data", "Directory containing tweet CSV files")
        interval := flag.Int("interval", 10000, "Interval for reporting stats (default 10000)")
        filterTokens := flag.Bool("filter-tokens", true, "Filter out URLs, mentions, hashtags, and short tokens (default true)")
        flag.Parse()

        files, err := getCSVFiles(*inputDir)
        if err != nil </span><span class="cov0" title="0">{
                fmt.Fprintf(os.Stderr, "Error reading input directory: %v\n", err)
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if len(files) == 0 </span><span class="cov0" title="0">{
                fmt.Fprintf(os.Stderr, "No CSV files found in directory: %s\n", *inputDir)
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">tokenSet := make(map[string]struct{})
        tweetsRead := 0
        startTime := time.Now()
        fmt.Printf("TweetsRead\tDistinctTokens\n")

        // For graphing
        var xVals []int
        var yVals []int

        for _, file := range files </span><span class="cov0" title="0">{
                f, err := os.Open(file)
                if err != nil </span><span class="cov0" title="0">{
                        fmt.Fprintf(os.Stderr, "Error opening file %s: %v\n", file, err)
                        continue</span>
                }
                <span class="cov0" title="0">reader := csv.NewReader(bufio.NewReader(f))
                reader.FieldsPerRecord = -1 // allow variable columns
                reader.LazyQuotes = true    // handle bare quotes in tweet text
                firstRow := true
                textCol := -1
                for </span><span class="cov0" title="0">{
                        record, err := reader.Read()
                        if err == io.EOF </span><span class="cov0" title="0">{
                                break</span>
                        }
                        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                                fmt.Fprintf(os.Stderr, "Error reading CSV: %v\n", err)
                                break</span>
                        }
                        <span class="cov0" title="0">if firstRow </span><span class="cov0" title="0">{
                                // Find the text column (case-insensitive match for "text")
                                for i, col := range record </span><span class="cov0" title="0">{
                                        if strings.ToLower(col) == "text" </span><span class="cov0" title="0">{
                                                textCol = i
                                                break</span>
                                        }
                                }
                                <span class="cov0" title="0">firstRow = false
                                continue</span>
                        }
                        <span class="cov0" title="0">if textCol == -1 || textCol &gt;= len(record) </span><span class="cov0" title="0">{
                                continue</span> // skip if no text column
                        }
                        <span class="cov0" title="0">text := record[textCol]
                        tokens := simpleTokenize(text)
                        for _, tok := range tokens </span><span class="cov0" title="0">{
                                if *filterTokens </span><span class="cov0" title="0">{
                                        if len(tok) &lt; 2 </span><span class="cov0" title="0">{
                                                continue</span>
                                        }
                                        <span class="cov0" title="0">if strings.HasPrefix(tok, "http") </span><span class="cov0" title="0">{
                                                continue</span>
                                        }
                                        <span class="cov0" title="0">if strings.HasPrefix(tok, "@") </span><span class="cov0" title="0">{
                                                continue</span>
                                        }
                                        <span class="cov0" title="0">if strings.HasPrefix(tok, "#") </span><span class="cov0" title="0">{
                                                continue</span>
                                        }
                                }
                                <span class="cov0" title="0">tokenSet[tok] = struct{}{}</span>
                        }
                        <span class="cov0" title="0">tweetsRead++
                        if tweetsRead%(*interval) == 0 </span><span class="cov0" title="0">{
                                elapsed := time.Since(startTime).Seconds()
                                tps := float64(tweetsRead) / elapsed
                                progress := fmt.Sprintf("Processed %d tweets (distinct: %d) [%.0f tweets/sec]", tweetsRead, len(tokenSet), tps)
                                fmt.Printf("\r%-80s", progress)
                                xVals = append(xVals, tweetsRead)
                                yVals = append(yVals, len(tokenSet))
                        }</span>
                }
                <span class="cov0" title="0">f.Close()</span>
        }
        // Final output
        <span class="cov0" title="0">fmt.Printf("\rProcessed %d tweets (distinct: %d)\n", tweetsRead, len(tokenSet))
        xVals = append(xVals, tweetsRead)
        yVals = append(yVals, len(tokenSet))

        // ASCII Art Graph
        printASCIIGraph(xVals, yVals, 60, 20)</span>
}

// printASCIIGraph prints a simple ASCII line graph for the data
func printASCIIGraph(xVals, yVals []int, width, height int) <span class="cov0" title="0">{
        if len(xVals) &lt; 2 </span><span class="cov0" title="0">{
                fmt.Println("Not enough data for graph.")
                return
        }</span>
        // Find min/max
        <span class="cov0" title="0">xMin, xMax := xVals[0], xVals[len(xVals)-1]
        yMin, yMax := yVals[0], yVals[0]
        for _, y := range yVals </span><span class="cov0" title="0">{
                if y &lt; yMin </span><span class="cov0" title="0">{
                        yMin = y
                }</span>
                <span class="cov0" title="0">if y &gt; yMax </span><span class="cov0" title="0">{
                        yMax = y
                }</span>
        }
        <span class="cov0" title="0">if yMax == yMin </span><span class="cov0" title="0">{
                yMax = yMin + 1 // avoid div by zero
        }</span>
        // Prepare grid
        <span class="cov0" title="0">grid := make([][]rune, height)
        for i := range grid </span><span class="cov0" title="0">{
                grid[i] = make([]rune, width)
                for j := range grid[i] </span><span class="cov0" title="0">{
                        grid[i][j] = ' '
                }</span>
        }
        // Map data points to grid
        <span class="cov0" title="0">for i := 0; i &lt; len(xVals); i++ </span><span class="cov0" title="0">{
                col := int(float64(i) / float64(len(xVals)-1) * float64(width-1))
                row := int(float64(yVals[i]-yMin) / float64(yMax-yMin) * float64(height-1))
                row = height - 1 - row // invert Y axis
                if col &gt;= 0 &amp;&amp; col &lt; width &amp;&amp; row &gt;= 0 &amp;&amp; row &lt; height </span><span class="cov0" title="0">{
                        grid[row][col] = '*'
                }</span>
        }
        // Prepare Y axis labels
        <span class="cov0" title="0">yLabels := make([]string, height)
        yLabels[0] = fmt.Sprintf("%d", yMax)
        yLabels[height/2] = fmt.Sprintf("%d", (yMax+yMin)/2)
        yLabels[height-1] = fmt.Sprintf("%d", yMin)
        for i := 1; i &lt; height-1; i++ </span><span class="cov0" title="0">{
                if yLabels[i] == "" </span><span class="cov0" title="0">{
                        yLabels[i] = " "
                }</span>
        }
        // Print graph with Y axis labels
        <span class="cov0" title="0">fmt.Println("\nASCII Graph: Distinct Tokens vs. Tweets Read")
        for i := 0; i &lt; height; i++ </span><span class="cov0" title="0">{
                fmt.Printf("%8s |", yLabels[i])
                for j := 0; j &lt; width; j++ </span><span class="cov0" title="0">{
                        fmt.Print(string(grid[i][j]))
                }</span>
                <span class="cov0" title="0">fmt.Println()</span>
        }
        // X axis
        <span class="cov0" title="0">fmt.Printf("%8s +%s\n", "", strings.Repeat("-", width))
        // X axis labels: min, mid, max
        xMid := (xMin + xMax) / 2
        label := fmt.Sprintf("%d", xMin)
        labelMid := fmt.Sprintf("%d", xMid)
        labelMax := fmt.Sprintf("%d", xMax)
        // Place min at start, mid at center, max at end
        labelLine := make([]rune, width)
        for i := range labelLine </span><span class="cov0" title="0">{
                labelLine[i] = ' '
        }</span>
        <span class="cov0" title="0">copy(labelLine[0:], []rune(label))
        copy(labelLine[width/2-len(labelMid)/2:], []rune(labelMid))
        copy(labelLine[width-len(labelMax):], []rune(labelMax))
        fmt.Printf("         %s\n", string(labelLine))
        fmt.Printf("Y: %d to %d\n", yMin, yMax)</span>
}
</pre>
		
		<pre class="file" id="file1" style="display: none">package main

import (
        "bufio"
        "compress/gzip"
        "encoding/csv"
        "encoding/json"
        "fmt"
        "log"
        "os"
        "path/filepath"
        "strings"
)

// StringOrNumber handles JSON fields that may be a string or a number
type StringOrNumber string

func (s *StringOrNumber) UnmarshalJSON(b []byte) error <span class="cov0" title="0">{
        // Try as string
        var str string
        if err := json.Unmarshal(b, &amp;str); err == nil </span><span class="cov0" title="0">{
                *s = StringOrNumber(str)
                return nil
        }</span>
        // Try as number
        <span class="cov0" title="0">var num int
        if err := json.Unmarshal(b, &amp;num); err == nil </span><span class="cov0" title="0">{
                *s = StringOrNumber(fmt.Sprintf("%d", num))
                return nil
        }</span>
        <span class="cov0" title="0">return fmt.Errorf("StringOrNumber: could not unmarshal %s", string(b))</span>
}

type Tweet struct {
        IDStr        string         `json:"id_str"`
        Text         string         `json:"text"`
        CreatedAt    string         `json:"created_at"`
        RetweetCount StringOrNumber `json:"retweet_count"`
        Retweeted    bool           `json:"retweeted"`
        User         struct {
                IDStr string `json:"id_str"`
                Name  string `json:"name"`
        } `json:"user"`
}

func processJSONFile(inputPath, outputPath string) (int, int, error) <span class="cov0" title="0">{
        fmt.Printf("Processing %s -&gt; %s\n", inputPath, outputPath)

        // Remove existing output file if it exists
        if _, err := os.Stat(outputPath); err == nil </span><span class="cov0" title="0">{
                os.Remove(outputPath)
        }</span>

        // Open gzipped file
        <span class="cov0" title="0">file, err := os.Open(inputPath)
        if err != nil </span><span class="cov0" title="0">{
                return 0, 0, fmt.Errorf("failed to open file: %v", err)
        }</span>
        <span class="cov0" title="0">defer file.Close()

        gzReader, err := gzip.NewReader(file)
        if err != nil </span><span class="cov0" title="0">{
                return 0, 0, fmt.Errorf("failed to create gzip reader: %v", err)
        }</span>
        <span class="cov0" title="0">defer gzReader.Close()

        // Create output CSV file
        outFile, err := os.Create(outputPath)
        if err != nil </span><span class="cov0" title="0">{
                return 0, 0, fmt.Errorf("failed to create output file: %v", err)
        }</span>
        <span class="cov0" title="0">defer outFile.Close()

        writer := csv.NewWriter(outFile)
        defer writer.Flush()

        // Write CSV header
        header := []string{"id_str", "created_at", "user_id_str", "retweet_count", "text", "retweeted", "at", "http", "hashtag", "words"}
        if err := writer.Write(header); err != nil </span><span class="cov0" title="0">{
                return 0, 0, fmt.Errorf("failed to write header: %v", err)
        }</span>

        <span class="cov0" title="0">scanner := bufio.NewScanner(gzReader)
        tweetCount := 0
        skipCount := 0

        for lineNum := 1; scanner.Scan(); lineNum++ </span><span class="cov0" title="0">{
                line := strings.TrimSpace(scanner.Text())

                // Skip empty lines
                if line == "" </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Skip opening and closing brackets (like GPT code)
                <span class="cov0" title="0">if line == "[" || line == "]" </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Remove trailing comma (like GPT code)
                <span class="cov0" title="0">line = strings.TrimRight(line, ",")

                var tweet Tweet
                if err := json.Unmarshal([]byte(line), &amp;tweet); err != nil </span><span class="cov0" title="0">{
                        fmt.Printf("Failed to decode JSON at line %d: %v\n", lineNum, err)
                        skipCount++
                        continue</span>
                }

                // Check if we have the required fields
                <span class="cov0" title="0">if tweet.IDStr == "" || tweet.Text == "" || tweet.User.IDStr == "" </span><span class="cov0" title="0">{
                        skipCount++
                        continue</span>
                }

                // Count patterns
                <span class="cov0" title="0">atCount := strings.Count(tweet.Text, "@")
                httpCount := strings.Count(tweet.Text, "http")
                hashtagCount := strings.Count(tweet.Text, "#")

                // Extract words (simple approach)
                words := extractWords(tweet.Text)

                // Write CSV row
                row := []string{
                        tweet.IDStr,
                        tweet.CreatedAt,
                        tweet.User.IDStr,
                        string(tweet.RetweetCount),
                        tweet.Text,
                        fmt.Sprintf("%t", tweet.Retweeted),
                        fmt.Sprintf("%d", atCount),
                        fmt.Sprintf("%d", httpCount),
                        fmt.Sprintf("%d", hashtagCount),
                        words,
                }

                if err := writer.Write(row); err != nil </span><span class="cov0" title="0">{
                        fmt.Printf("Failed to write row at line %d: %v\n", lineNum, err)
                        skipCount++
                        continue</span>
                }

                <span class="cov0" title="0">tweetCount++
                if tweetCount%1000 == 0 </span><span class="cov0" title="0">{
                        fmt.Printf("Processed %d tweets so far...\n", tweetCount)
                }</span>
        }

        <span class="cov0" title="0">if err := scanner.Err(); err != nil </span><span class="cov0" title="0">{
                return tweetCount, skipCount, fmt.Errorf("scanner error: %v", err)
        }</span>

        <span class="cov0" title="0">fmt.Printf("Processed %d tweets, skipped %d objects\n", tweetCount, skipCount)
        return tweetCount, skipCount, nil</span>
}

func extractWords(text string) string <span class="cov0" title="0">{
        words := strings.Fields(text)
        var cleanWords []string
        for _, word := range words </span><span class="cov0" title="0">{
                // Remove punctuation and convert to lowercase
                word = strings.ToLower(strings.Trim(word, ".,!?;:\"()[]{}"))
                if len(word) &gt; 1 &amp;&amp; isAlpha(word) </span><span class="cov0" title="0">{
                        cleanWords = append(cleanWords, word)
                }</span>
        }
        <span class="cov0" title="0">return strings.Join(cleanWords, " ")</span>
}

func isAlpha(s string) bool <span class="cov0" title="0">{
        for _, r := range s </span><span class="cov0" title="0">{
                if !((r &gt;= 'a' &amp;&amp; r &lt;= 'z') || (r &gt;= 'A' &amp;&amp; r &lt;= 'Z')) </span><span class="cov0" title="0">{
                        return false
                }</span>
        }
        <span class="cov0" title="0">return true</span>
}

func main() <span class="cov0" title="0">{
        if len(os.Args) != 3 </span><span class="cov0" title="0">{
                fmt.Println("Usage: go run parser.go &lt;input_dir&gt; &lt;output_dir&gt;")
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">inputDir := os.Args[1]
        outputDir := os.Args[2]

        // Create output directory if it doesn't exist
        if err := os.MkdirAll(outputDir, 0755); err != nil </span><span class="cov0" title="0">{
                log.Fatalf("Failed to create output directory: %v", err)
        }</span>

        // Find all .json.gz files
        <span class="cov0" title="0">pattern := filepath.Join(inputDir, "*.json.gz")
        files, err := filepath.Glob(pattern)
        if err != nil </span><span class="cov0" title="0">{
                log.Fatalf("Failed to find files: %v", err)
        }</span>

        <span class="cov0" title="0">if len(files) == 0 </span><span class="cov0" title="0">{
                fmt.Printf("No .json.gz files found in %s\n", inputDir)
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">totalTweets := 0
        totalSkipped := 0

        for _, gzFile := range files </span><span class="cov0" title="0">{
                baseName := filepath.Base(gzFile)
                csvFile := filepath.Join(outputDir, strings.Replace(baseName, ".json.gz", ".csv", 1))

                tweets, skipped, err := processJSONFile(gzFile, csvFile)
                if err != nil </span><span class="cov0" title="0">{
                        fmt.Printf("Failed to process %s: %v\n", gzFile, err)
                        continue</span>
                }

                <span class="cov0" title="0">totalTweets += tweets
                totalSkipped += skipped</span>
        }

        <span class="cov0" title="0">fmt.Printf("Total: %d tweets, %d skipped\n", totalTweets, totalSkipped)</span>
}
</pre>
		
		<pre class="file" id="file2" style="display: none">package filter

import (
        "bufio"
        "fmt"
        "os"
        "strings"
        "sync"
)

// WordFilter holds a set of words to filter out
type WordFilter struct {
        filteredWords map[string]bool
        mu            sync.RWMutex
}

// NewWordFilter creates a new empty WordFilter
func NewWordFilter() *WordFilter <span class="cov8" title="1">{
        return &amp;WordFilter{
                filteredWords: make(map[string]bool),
        }
}</span>

// LoadFromFile loads filtered words from a file
// Each line should contain one word, lines starting with # are comments
func (wf *WordFilter) LoadFromFile(filename string) error <span class="cov8" title="1">{
        file, err := os.Open(filename)
        if err != nil </span><span class="cov8" title="1">{
                return fmt.Errorf("failed to open filter file %s: %v", filename, err)
        }</span>
        <span class="cov8" title="1">defer file.Close()

        wf.mu.Lock()
        defer wf.mu.Unlock()

        scanner := bufio.NewScanner(file)
        lineNum := 0
        loadedCount := 0

        for scanner.Scan() </span><span class="cov8" title="1">{
                lineNum++
                line := strings.TrimSpace(scanner.Text())

                // Skip empty lines and comments
                if line == "" || strings.HasPrefix(line, "#") </span><span class="cov8" title="1">{
                        continue</span>
                }

                // Convert to lowercase for case-insensitive matching
                <span class="cov8" title="1">word := strings.ToLower(line)
                wf.filteredWords[word] = true
                loadedCount++</span>
        }

        <span class="cov8" title="1">if err := scanner.Err(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("error reading filter file %s at line %d: %v", filename, lineNum, err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// IsFiltered checks if a token should be filtered out
func (wf *WordFilter) IsFiltered(token string) bool <span class="cov8" title="1">{
        wf.mu.RLock()
        defer wf.mu.RUnlock()

        // Convert token to lowercase for case-insensitive matching
        token = strings.ToLower(token)
        return wf.filteredWords[token]
}</span>

// GetFilteredCount returns the number of words in the filter
func (wf *WordFilter) GetFilteredCount() int <span class="cov8" title="1">{
        wf.mu.RLock()
        defer wf.mu.RUnlock()
        return len(wf.filteredWords)
}</span>

// AddWord adds a single word to the filter
func (wf *WordFilter) AddWord(word string) <span class="cov8" title="1">{
        wf.mu.Lock()
        defer wf.mu.Unlock()
        wf.filteredWords[strings.ToLower(word)] = true
}</span>

// RemoveWord removes a word from the filter
func (wf *WordFilter) RemoveWord(word string) <span class="cov8" title="1">{
        wf.mu.Lock()
        defer wf.mu.Unlock()
        delete(wf.filteredWords, strings.ToLower(word))
}</span>
</pre>
		
		<pre class="file" id="file3" style="display: none">package main

import (
        "encoding/csv"
        "flag"
        "fmt"
        "log"
        "math"
        "os"
        "path/filepath"
        "regexp"
        "strings"
        "sync"
        "time"

        "cursor-twitter/src/filter"
        "cursor-twitter/src/pipeline"
        "cursor-twitter/src/tweets"
        "log/slog"

        amqp "github.com/rabbitmq/amqp091-go"
        "gopkg.in/yaml.v3"
)

// Config struct for YAML config file (add log_dir)
type Config struct {
        Mode       string `yaml:"mode"`
        InputDir   string `yaml:"input"`
        MQHost     string `yaml:"mq_host"`
        MQPort     int    `yaml:"mq_port"`
        MQQueue    string `yaml:"mq_queue"`
        WindowSize int    `yaml:"window"`
        BatchSize  int    `yaml:"batch"`

        Verbose     bool    `yaml:"verbose"`
        LogDir      string  `yaml:"log_dir"`
        FreqClasses int     `yaml:"freq_classes"`
        BWArrayLen  int     `yaml:"bw_array_len"`
        ZScore      float64 `yaml:"z_score"`

        Filter struct {
                Enabled    bool   `yaml:"enabled"`
                FilterFile string `yaml:"filter_file"`
        } `yaml:"filter"`

        Persistence struct {
                StateDir string `yaml:"state_dir"`
        } `yaml:"persistence"`

        Sender struct {
                StatusFile string `yaml:"status_file"`
        } `yaml:"sender"`
}

// GlobalTokenCounter keeps track of token counts in the current window.
var GlobalTokenCounter = pipeline.NewTokenCounter()

// Global stats counters
var (
        TotalTweetsRead    int
        TotalTokensCounted int
        lastStatsTime      time.Time
        lastTweetCount     int
        freqClasses        int // Number of frequency classes from config

)

// Global mappings for token &lt;-&gt; ThreePartKey relationships
var (
        tokenToThreePK  map[string]tweets.ThreePartKey
        threePKToToken  map[tweets.ThreePartKey]string
        tokenMappingsMu sync.RWMutex
)

// Sliding window management
var (
        tweetQueue   []*tweets.Tweet // Queue of tweets in the current window
        tweetQueueMu sync.RWMutex    // Mutex for thread-safe access to tweet queue
)

// Add a global variable to hold the stats CSV file path
var statsCSVPath string

// Global Bloom filters
var (
        GlobalFilters []pipeline.FreqClassFilter
)

// Global FCT and queues
var (
        inboundTokenQueue  *pipeline.TokenQueue
        oldTokenQueue      *pipeline.TokenQueue
        fct                *pipeline.FrequencyComputationThread
        freqClassProcessor *pipeline.FrequencyClassProcessor
)

// Global word filter
var globalWordFilter *filter.WordFilter

func main() <span class="cov0" title="0">{
        // Add a command line flag to control printing of tweets
        printTweets := flag.Bool("print-tweets", true, "Print each parsed tweet to the console")
        configPath := flag.String("config", "../config/config.yaml", "Path to YAML config file")
        flag.Parse()

        // Load config from YAML file.

        cfg, err := loadConfig(*configPath)
        if err != nil </span><span class="cov0" title="0">{
                log.Fatalf("Failed to load config: %v", err)
        }</span>

        // Require log_dir to be present and non-empty
        <span class="cov0" title="0">if cfg.LogDir == "" </span><span class="cov0" title="0">{
                fmt.Fprintln(os.Stderr, "ERROR: 'log_dir' must be defined in the config file and cannot be empty.")
                os.Exit(1)
        }</span>

        // Set up slog logger to write to a file in the specified log_dir
        <span class="cov0" title="0">logger, logFile, err := setupLogger(cfg.LogDir)
        if err != nil </span><span class="cov0" title="0">{
                log.Fatalf("Failed to set up logger: %v", err)
        }</span>
        <span class="cov0" title="0">defer logFile.Close()
        slog.SetDefault(logger)

        // Set up stats CSV file path
        statsCSVPath = filepath.Join(cfg.LogDir, "stats.csv")
        ensureStatsCSVHeader(statsCSVPath)

        slog.Info("Starting simple RabbitMQ consumer")

        // Start periodic stats printer (prints every 30 seconds)
        startStatsPrinter()

        // Initialize global token mappings
        tokenToThreePK = make(map[string]tweets.ThreePartKey)
        threePKToToken = make(map[tweets.ThreePartKey]string)

        // Initialize word filter if enabled
        if cfg.Filter.Enabled </span><span class="cov0" title="0">{
                globalWordFilter = filter.NewWordFilter()
                if err := globalWordFilter.LoadFromFile(cfg.Filter.FilterFile); err != nil </span><span class="cov0" title="0">{
                        slog.Error("Failed to load word filter", "error", err, "file", cfg.Filter.FilterFile)
                        return
                }</span>
                <span class="cov0" title="0">slog.Info("Word filter initialized", "filtered_words_count", globalWordFilter.GetFilteredCount(), "file", cfg.Filter.FilterFile)</span>
        } else<span class="cov0" title="0"> {
                slog.Info("Word filtering disabled")
        }</span>

        // Set global array length for 3PK generation
        <span class="cov0" title="0">pipeline.SetGlobalArrayLen(cfg.BWArrayLen)

        // Create the token queues and FCT
        inboundTokenQueue = pipeline.NewTokenQueue()
        oldTokenQueue = pipeline.NewTokenQueue()

        // Create FCT with configuration
        freqClasses = cfg.FreqClasses
        if freqClasses &lt;= 0 </span><span class="cov0" title="0">{
                slog.Error("Main: freq_classes must be &gt; 0 in config, got", "value", freqClasses)
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">fct = pipeline.NewFrequencyComputationThread(
                GlobalTokenCounter,
                inboundTokenQueue,
                oldTokenQueue,
                0, // Not used - frequency rebuilds happen based on window size
                freqClasses,
        )

        // Start the FCT
        fct.Start()
        defer fct.Stop()

        slog.Info("FCT created and started",
                "freq_classes", freqClasses)

        // Create and start the frequency class processor
        freqClassProcessor = pipeline.NewFrequencyClassProcessor(freqClasses, cfg.BWArrayLen, float64(cfg.ZScore))
        freqClassProcessor.SetGlobalTokenMappingForAll(threePKToToken, &amp;tokenMappingsMu)
        freqClassProcessor.Start()
        defer freqClassProcessor.Stop()

        slog.Info("FrequencyClassProcessor created and started",
                "num_classes", freqClasses,
                "bw_array_len", cfg.BWArrayLen,
                "z_score_threshold", cfg.ZScore)

        // Connect to RabbitMQ
        conn, err := amqp.Dial("amqp://guest:guest@localhost:5672/")
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to connect to RabbitMQ", "error", err)
                return
        }</span>
        <span class="cov0" title="0">defer conn.Close()

        // Create channel
        ch, err := conn.Channel()
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to open channel", "error", err)
                return
        }</span>
        <span class="cov0" title="0">defer ch.Close()

        // Declare queue
        q, err := ch.QueueDeclare(
                "tweet_in", // name
                true,       // durable
                false,      // delete when unused
                false,      // exclusive
                false,      // no-wait
                nil,        // arguments
        )
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to declare queue", "error", err)
                return
        }</span>

        <span class="cov0" title="0">slog.Info("Connected to RabbitMQ. Waiting for messages...", "queue", q.Name)

        // Start blocking consumer
        msgs, err := ch.Consume(
                q.Name, // queue
                "",     // consumer
                true,   // auto-ack
                false,  // exclusive
                false,  // no-local
                false,  // no-wait
                nil,    // args
        )
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to register a consumer", "error", err)
                return
        }</span>
        // TODO:Add Global stats including tweet count, token count, distinct token count
        //     (available from map size),
        //    number of W window cycles, number of pipeline cycles, etc.
        //
        // TODO: Nothing like maxRebuildTime should exist. Check that this does not exist.

        // TODO: Create the TweetWindowQueue      This will not be allowed to grow beyond WindowSize
        // TODO: Create the InboundTokenQueue
        // TODO: Create the OldTokenQueue
        // TODO: Create the InboundTweetQueue

        // TODO: Create a FrequencyComputationThread
        //       THE FCT take tokens from the InboundTokenQueue and register them in
        //       the CountMap.
        //       It also takes tokens from the OldTokenQueue and decrements the counts in the CountMap.
        //       It also checks a flag to see if it should stop taking tokens and
        //       compute the frequency class filters.  If so,
        //             it copies the CountMap to a new array
        //             clears the existing CountMap.
        //       It also sets the flag to resume taking tokens.
        //       It also copies the CountMap to a new array and clears the CountMap.
        //       It also sets the flag to resume taking tokens.
        //       It also sets the flag to resume taking tokens.
        //       It also sets the flag to resume taking tokens.

        // Main loop runs forever
        <span class="cov0" title="0">for msg := range msgs </span><span class="cov0" title="0">{

                tweet, err := parseCSVToTweet(string(msg.Body))
                if err != nil </span><span class="cov0" title="0">{
                        //slog.Warn("Failed to parse tweet", "error", err, "raw_row", string(msg.Body))
                        //fmt.Printf("[PARSE ERROR] %v\nRaw: %s\n", err, string(msg.Body))
                        continue</span>
                }
                // Only print the tweet if the flag is set
                <span class="cov0" title="0">if *printTweets </span><span class="cov0" title="0">{
                        fmt.Printf("Parsed Tweet: %+v\n", tweet)
                }</span>

                // Always add new tweet tokens to the inbound queue for FCT to build frequency filters
                <span class="cov0" title="0">if len(tweet.Tokens) &gt; 0 </span><span class="cov0" title="0">{
                        inboundTokenQueue.Enqueue(tweet.Tokens)
                        slog.Info("Added tokens to InboundTokenQueue",
                                "tweet_id", tweet.IDStr,
                                "token_count", len(tweet.Tokens),
                                "queue_size_after", inboundTokenQueue.Len())

                        // Route each token to its appropriate frequency class (only if filters are available)
                        filters := pipeline.GetGlobalFilters()
                        if len(filters) &gt; 0 </span><span class="cov0" title="0">{
                                // Debug: Log when filters are available
                                if TotalTweetsRead%10000 == 0 </span><span class="cov0" title="0">{
                                        slog.Info("Filters are available for token routing",
                                                "tweet_count", TotalTweetsRead,
                                                "num_filters", len(filters))
                                        fmt.Printf("*** TOKEN ROUTING ACTIVE: %d filters available ***\n", len(filters))
                                }</span>

                                // Route tokens to frequency classes
                                <span class="cov0" title="0">for _, token := range tweet.Tokens </span><span class="cov0" title="0">{
                                        // Find which frequency class this token belongs to
                                        freqClass := -1
                                        for i, filter := range filters </span><span class="cov0" title="0">{
                                                if filter.Contains(token) </span><span class="cov0" title="0">{
                                                        freqClass = i
                                                        break</span>
                                                }
                                        }

                                        <span class="cov0" title="0">if freqClass &gt;= 0 </span><span class="cov0" title="0">{
                                                // Generate or get the 3pk for this token
                                                tokenMappingsMu.RLock()
                                                threePK, exists := tokenToThreePK[token]
                                                tokenMappingsMu.RUnlock()

                                                if !exists </span><span class="cov0" title="0">{
                                                        // Generate new ThreePartKey and store in mappings
                                                        threePK = pipeline.GenerateThreePartKey(token)
                                                        tokenMappingsMu.Lock()
                                                        tokenToThreePK[token] = threePK
                                                        threePKToToken[threePK] = token
                                                        tokenMappingsMu.Unlock()
                                                }</span>

                                                // Enqueue to appropriate frequency class
                                                <span class="cov0" title="0">freqClassProcessor.EnqueueToFrequencyClass(freqClass, threePK)</span>
                                        } else<span class="cov0" title="0"> {
                                                // Token not in any frequency class (shouldn't happen with proper filters)
                                                slog.Warn("Token not found in any frequency class filter", "token", token)
                                        }</span>
                                }
                        } else<span class="cov0" title="0"> {
                                // No filters available yet - log occasionally
                                if TotalTweetsRead%10000 == 0 </span><span class="cov0" title="0">{
                                        slog.Info("No frequency class filters available yet",
                                                "tweet_count", TotalTweetsRead)
                                        fmt.Printf("*** NO FILTERS AVAILABLE: waiting for first rebuild ***\n")
                                }</span>
                        }
                }

                // Manage the sliding window - add new tweet and remove old ones
                // TODO: This is wrong. WindowSize is a constant set in configuration. A queue called
                // Inbound Tweet structs are stored on a Queue called TweetWindowQueue.
                // The new inbound tweet's tokens are placed on an InboundTokenQueue.
                // if the TweetWindowQueue reaches WindowSize, the oldest tweet is removed and
                // it's tokens are placed on an OldTokenQueue.

                <span class="cov0" title="0">if cfg.WindowSize &lt;= 0 </span><span class="cov0" title="0">{
                        slog.Error("Main: window must be &gt; 0 in config, got", "value", cfg.WindowSize)
                        os.Exit(1)
                }</span>
                <span class="cov0" title="0">manageSlidingWindow(tweet, cfg.WindowSize)

                // Frequency class rebuilding - happens every time we cross the window boundary
                // When we've processed window-size tweets, we rebuild the frequency classes
                // NOTE: TotalTweetsRead is incremented in parseCSVToTweet, so we check after parsing

                // Check if we've crossed a window boundary
                currentWindow := TotalTweetsRead / cfg.WindowSize

                // Debug: Log every 1000 tweets to see what's happening
                if TotalTweetsRead%1000 == 0 </span><span class="cov0" title="0">{
                        slog.Info("Main: Window boundary debug",
                                "tweet_count", TotalTweetsRead,
                                "window_size", cfg.WindowSize,
                                "current_window", currentWindow,
                                "modulo_check", TotalTweetsRead%cfg.WindowSize)
                }</span>

                // Debug: Always log the window boundary check
                <span class="cov0" title="0">if TotalTweetsRead%10000 == 0 </span><span class="cov0" title="0">{
                        slog.Info("Main: Window boundary check",
                                "tweet_count", TotalTweetsRead,
                                "window_size", cfg.WindowSize,
                                "current_window", currentWindow,
                                "modulo_result", TotalTweetsRead%cfg.WindowSize,
                                "should_trigger", TotalTweetsRead%cfg.WindowSize == 0 &amp;&amp; TotalTweetsRead &gt; 0)
                }</span>

                // Check if we should trigger a rebuild (window boundary crossed)
                <span class="cov0" title="0">if TotalTweetsRead%cfg.WindowSize == 0 &amp;&amp; TotalTweetsRead &gt; 0 </span><span class="cov0" title="0">{
                        // We've crossed into a new window, give FCT permission to rebuild
                        rebuildStartTime := time.Now()
                        fmt.Printf("*** WINDOW BOUNDARY CROSSED: Tweet %d, Window %d at %s ***\n",
                                TotalTweetsRead, currentWindow, rebuildStartTime.Format("15:04:05"))
                        slog.Info("Main: Window boundary crossed, giving FCT permission to rebuild",
                                "tweet_count", TotalTweetsRead,
                                "window_size", cfg.WindowSize,
                                "current_window", currentWindow,
                                "rebuild_start_time", rebuildStartTime.Format("15:04:05"))

                        if fct == nil </span><span class="cov0" title="0">{
                                slog.Error("Main: FCT is nil! Cannot trigger rebuild")
                        }</span> else<span class="cov0" title="0"> {
                                slog.Info("Main: About to call fct.TriggerRebuild()")
                                fct.TriggerRebuild()
                                slog.Info("Main: fct.TriggerRebuild() completed")
                        }</span>
                        <span class="cov0" title="0">fmt.Printf("*** REBUILD FLAG SET at %s ***\n", rebuildStartTime.Format("15:04:05"))
                        slog.Info("Main: Rebuild flag set for FCT",
                                "tweet_count", TotalTweetsRead,
                                "window_size", cfg.WindowSize,
                                "current_window", currentWindow,
                                "rebuild_start_time", rebuildStartTime.Format("15:04:05"))</span>
                }

                // Send termination signals to busy word processors every batch number of tweets
                // Only send if frequency class filters are available
                <span class="cov0" title="0">if TotalTweetsRead%cfg.BatchSize == 0 &amp;&amp; TotalTweetsRead &gt; 0 </span><span class="cov0" title="0">{
                        filters := pipeline.GetGlobalFilters()
                        if len(filters) &gt; 0 </span><span class="cov0" title="0">{
                                terminationSignal := tweets.ThreePartKey{Part1: -1, Part2: -1, Part3: -1}

                                // Send termination signal to all frequency class processors
                                for i := 0; i &lt; freqClasses; i++ </span><span class="cov0" title="0">{
                                        freqClassProcessor.EnqueueToFrequencyClass(i, terminationSignal)
                                }</span>

                                <span class="cov0" title="0">fmt.Printf("*** BATCH BOUNDARY: Sent termination signals to all %d busy word processors at tweet %d ***\n",
                                        freqClasses, TotalTweetsRead)
                                slog.Info("Main: Sent termination signals to busy word processors",
                                        "tweet_count", TotalTweetsRead,
                                        "batch_size", cfg.BatchSize,
                                        "num_freq_classes", freqClasses)</span>
                        } else<span class="cov0" title="0"> {
                                // No filters available yet - log occasionally
                                if TotalTweetsRead%10000 == 0 </span><span class="cov0" title="0">{
                                        slog.Info("Skipping batch termination - no frequency class filters available yet",
                                                "tweet_count", TotalTweetsRead,
                                                "batch_size", cfg.BatchSize)
                                }</span>
                        }
                }
        }
}

// loadConfig loads the YAML config file into a Config struct.
func loadConfig(path string) (*Config, error) <span class="cov8" title="1">{
        data, err := os.ReadFile(path)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">var cfg Config
        if err := yaml.Unmarshal(data, &amp;cfg); err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return &amp;cfg, nil</span>
}

// setupLogger creates the log directory if needed and returns a slog.Logger that writes to a file.
func setupLogger(logDir string) (*slog.Logger, *os.File, error) <span class="cov0" title="0">{
        // No default! logDir must be set by config and checked in main()
        if logDir == "" </span><span class="cov0" title="0">{
                return nil, nil, fmt.Errorf("logDir must be set in config; refusing to use a default")
        }</span>
        <span class="cov0" title="0">if err := os.MkdirAll(logDir, 0755); err != nil </span><span class="cov0" title="0">{
                return nil, nil, err
        }</span>
        <span class="cov0" title="0">logPath := filepath.Join(logDir, "pipeline.log")
        logFile, err := os.OpenFile(logPath, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, err
        }</span>
        <span class="cov0" title="0">logger := slog.New(slog.NewTextHandler(logFile, nil))
        return logger, logFile, nil</span>
}

// startStatsPrinter launches a goroutine that prints stats every 30 seconds.
func startStatsPrinter() <span class="cov0" title="0">{
        lastStatsTime = time.Now()
        lastTweetCount = 0
        ticker := time.NewTicker(30 * time.Second)
        go func() </span><span class="cov0" title="0">{
                for range ticker.C </span><span class="cov0" title="0">{
                        printStats()
                }</span>
        }()
}

// ensureStatsCSVHeader creates the stats CSV file and writes the header if it doesn't exist.
func ensureStatsCSVHeader(path string) <span class="cov0" title="0">{
        if _, err := os.Stat(path); os.IsNotExist(err) </span><span class="cov0" title="0">{
                f, err := os.OpenFile(path, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)
                if err != nil </span><span class="cov0" title="0">{
                        log.Printf("Failed to create stats CSV: %v", err)
                        return
                }</span>
                <span class="cov0" title="0">defer f.Close()
                writer := csv.NewWriter(f)
                writer.Write([]string{"timestamp", "total_tweets", "total_tokens", "distinct_tokens"})
                writer.Flush()</span>
        }
}

// printStats prints the current pipeline statistics and logs them as CSV.
func printStats() <span class="cov0" title="0">{
        now := time.Now()
        timestamp := now.Format(time.RFC3339)
        totalTweets := TotalTweetsRead
        totalTokens := TotalTokensCounted
        distinctTokens := len(GlobalTokenCounter.Counts())

        // Calculate processing rate
        timeDiff := now.Sub(lastStatsTime).Seconds()
        tweetDiff := totalTweets - lastTweetCount
        processingRate := float64(tweetDiff) / timeDiff

        // Get sliding window stats
        tweetQueueMu.RLock()
        windowSize := len(tweetQueue)
        tweetQueueMu.RUnlock()

        // Get queue lengths
        inboundQueueSize := inboundTokenQueue.Len()
        oldQueueSize := oldTokenQueue.Len()

        // Get frequency class stats
        freqClassQueueStats := freqClassProcessor.GetQueueStats()
        freqClassProcessorStats := freqClassProcessor.GetProcessorStats()

        fmt.Printf("\n--- Pipeline Stats ---\n")
        fmt.Printf("Total tweets read: %d\n", totalTweets)
        fmt.Printf("Total tokens counted: %d\n", totalTokens)
        fmt.Printf("Distinct tokens: %d\n", distinctTokens)
        fmt.Printf("Tweets in current window: %d\n", windowSize)
        fmt.Printf("Inbound token queue size: %d\n", inboundQueueSize)
        fmt.Printf("Old token queue size: %d\n", oldQueueSize)
        fmt.Printf("Processing rate: %.2f tweets/sec\n", processingRate)

        // Print frequency class stats
        fmt.Printf("--- Frequency Class Stats ---\n")
        for i := 0; i &lt; freqClasses; i++ </span><span class="cov0" title="0">{
                queueKey := fmt.Sprintf("freq_class_%d_queue_size", i)
                processorKey := fmt.Sprintf("freq_class_%d_tokens_processed", i)
                queueSize := freqClassQueueStats[queueKey]
                tokensProcessed := freqClassProcessorStats[processorKey]
                fmt.Printf("Class %d: Queue=%d, Processed=%d\n", i, queueSize, tokensProcessed)
        }</span>
        <span class="cov0" title="0">fmt.Printf("----------------------\n")
        // Also log to slog
        slog.Info("Pipeline stats",
                "tweets", totalTweets,
                "tokens", totalTokens,
                "distinct", distinctTokens,
                "window_size", windowSize,
                "inbound_queue_size", inboundQueueSize,
                "old_queue_size", oldQueueSize,
                "processing_rate_tweets_per_sec", processingRate)

        // Update for next calculation
        lastStatsTime = now
        lastTweetCount = totalTweets

        // Log as CSV for machine consumption
        f, err := os.OpenFile(statsCSVPath, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)
        if err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to open stats CSV: %v", err)
                return
        }</span>
        <span class="cov0" title="0">defer f.Close()
        writer := csv.NewWriter(f)
        writer.Write([]string{
                timestamp,
                fmt.Sprintf("%d", totalTweets),
                fmt.Sprintf("%d", totalTokens),
                fmt.Sprintf("%d", distinctTokens),
        })
        writer.Flush()</span>
}

// parseCSVToTweet parses a CSV row string into a Tweet struct,
// tokenizes the text, generates ThreePartKeys, and updates the global
// token counter.
func parseCSVToTweet(row string) (*tweets.Tweet, error) <span class="cov8" title="1">{
        reader := csv.NewReader(strings.NewReader(row))
        reader.FieldsPerRecord = -1
        record, err := reader.Read()
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">if len(record) &lt; 10 </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("expected at least 10 fields, got %d", len(record))
        }</span>
        // Skip header rows
        <span class="cov8" title="1">if record[0] == "id_str" || record[1] == "created_at" </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("header row detected, skipping")
        }</span>

        // Normalize all whitespace to a single space
        <span class="cov8" title="1">cleanTime := normalizeWhitespace(record[1])

        createdAt, err := time.Parse("Mon Jan 2 15:04:05 -0700 2006", cleanTime)
        if err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("failed to parse CreatedAt: %v", err)
        }</span>

        // Create the Tweet struct and fill in the basic fields from the CSV
        <span class="cov8" title="1">tweet := &amp;tweets.Tweet{
                IDStr:        record[0],
                Unix:         createdAt.Unix(),
                UserIDStr:    record[2],
                Text:         record[4],
                Retweeted:    record[5] == "True",
                RetweetCount: 0,   // TODO: parse record[3] as int
                Tokens:       nil, // We'll fill this in below
        }

        // --- BEGINNER-FRIENDLY COMMENTS BELOW ---

        // Step 1: Tokenize the tweet text.
        // - Convert to lowercase
        // - Remove punctuation
        // - Remove apostrophes and what follows
        // - Split on whitespace
        tokens := simpleTokenize(tweet.Text)
        tweet.Tokens = tokens // Store tokens in the Tweet struct

        // Generate ThreePartKeys and store in global mappings
        var threePKs []tweets.ThreePartKey
        for _, token := range tokens </span><span class="cov8" title="1">{
                // Check if we already have a mapping for this token
                tokenMappingsMu.RLock()
                threePK, exists := tokenToThreePK[token]
                tokenMappingsMu.RUnlock()

                if !exists </span><span class="cov8" title="1">{
                        // Generate new ThreePartKey and store in mappings
                        threePK = pipeline.GenerateThreePartKey(token)
                        tokenMappingsMu.Lock()
                        tokenToThreePK[token] = threePK
                        threePKToToken[threePK] = token
                        tokenMappingsMu.Unlock()
                }</span>

                <span class="cov8" title="1">threePKs = append(threePKs, threePK)</span>
        }
        // Note: ThreePKs not stored in Tweet struct but still generated for other uses

        // Step 3: Update global stats counters (token counting is now handled by FCT)
        <span class="cov8" title="1">TotalTweetsRead++
        TotalTokensCounted += len(tokens)

        // Step 5: Manage the sliding window (remove old tweets and decrement their tokens)
        // Note: We'll call this after parsing, but we need to pass the window size
        // For now, we'll use a default of 15 minutes if not configured

        return tweet, nil</span>
}

// simpleTokenize splits text into tokens for this project.
// - Converts to lowercase
// - Removes punctuation
// - Removes apostrophes and what follows
// - Splits on whitespace
// - Filters out offensive words if word filtering is enabled
func simpleTokenize(text string) []string <span class="cov8" title="1">{
        // Convert to lowercase
        text = strings.ToLower(text)

        // Remove apostrophes and what follows (e.g., "don't" -&gt; "don")
        apostropheRe := regexp.MustCompile(`'\w*`)
        text = apostropheRe.ReplaceAllString(text, "")

        // Remove all punctuation (except spaces)
        punctRe := regexp.MustCompile(`[^a-z0-9 ]`)
        text = punctRe.ReplaceAllString(text, "")

        // Split on whitespace
        tokens := strings.Fields(text)

        // Filter out offensive words if word filtering is enabled
        if globalWordFilter != nil </span><span class="cov0" title="0">{
                var filteredTokens []string
                for _, token := range tokens </span><span class="cov0" title="0">{
                        if !globalWordFilter.IsFiltered(token) </span><span class="cov0" title="0">{
                                filteredTokens = append(filteredTokens, token)
                        }</span>
                }
                <span class="cov0" title="0">return filteredTokens</span>
        }

        <span class="cov8" title="1">return tokens</span>
}

// Normalize all whitespace to a single space
func normalizeWhitespace(s string) string <span class="cov8" title="1">{
        return strings.Join(strings.Fields(s), " ")
}</span>

// manageSlidingWindow adds a new tweet to the queue and removes old tweets that fall outside the window
func manageSlidingWindow(tweet *tweets.Tweet, windowSize int) <span class="cov0" title="0">{
        tweetQueueMu.Lock()
        defer tweetQueueMu.Unlock()

        // Add the new tweet to the queue
        tweetQueue = append(tweetQueue, tweet)

        // Keep only the most recent windowSize tweets
        if len(tweetQueue) &gt; windowSize </span><span class="cov0" title="0">{
                removedCount := len(tweetQueue) - windowSize
                oldTweets := tweetQueue[:removedCount]
                tweetQueue = tweetQueue[removedCount:]

                // Add old tweet tokens to the old token queue for FCT to process
                for _, oldTweet := range oldTweets </span><span class="cov0" title="0">{
                        if len(oldTweet.Tokens) &gt; 0 </span><span class="cov0" title="0">{
                                oldTokenQueue.Enqueue(oldTweet.Tokens)
                                slog.Info("Added old tokens to OldTokenQueue",
                                        "tweet_id", oldTweet.IDStr,
                                        "token_count", len(oldTweet.Tokens),
                                        "queue_size_after", oldTokenQueue.Len())
                        }</span>
                }

                // Log window management stats
                <span class="cov0" title="0">if removedCount &gt; 0 </span><span class="cov0" title="0">{
                        slog.Info("Sliding window management",
                                "tweets_removed", removedCount,
                                "queue_size", len(tweetQueue),
                                "window_size", windowSize)
                }</span>
        }
}

// setupBloomFilterParams returns the expected number of tokens and number of hashes for each frequency class.
// This allows for different Bloom filter sizes based on the expected number of tokens in each class.
func setupBloomFilterParams(numClasses int) ([]int, []uint) <span class="cov0" title="0">{
        // Expected number of tokens in each frequency class (from most frequent to least frequent)
        // Based on actual data showing exponential growth: 15, 90, 576, 6076, 60373 for 5 classes
        expectedTokens := make([]int, numClasses)
        hashCounts := make([]uint, numClasses)

        // Use exponential growth based on actual data pattern
        // For 5 classes: 15, 90, 576, 6076, 60373
        // Growth factor is approximately 6x per class
        baseTokens := 15
        growthFactor := 6.0

        for i := 0; i &lt; numClasses; i++ </span><span class="cov0" title="0">{
                expectedTokens[i] = int(float64(baseTokens) * math.Pow(growthFactor, float64(i)))

                // Number of hash functions - higher counts for larger filters to maintain low false positive rate
                if expectedTokens[i] &lt; 100 </span><span class="cov0" title="0">{
                        hashCounts[i] = 7
                }</span> else<span class="cov0" title="0"> if expectedTokens[i] &lt; 1000 </span><span class="cov0" title="0">{
                        hashCounts[i] = 8
                }</span> else<span class="cov0" title="0"> if expectedTokens[i] &lt; 10000 </span><span class="cov0" title="0">{
                        hashCounts[i] = 10
                }</span> else<span class="cov0" title="0"> if expectedTokens[i] &lt; 100000 </span><span class="cov0" title="0">{
                        hashCounts[i] = 12
                }</span> else<span class="cov0" title="0"> {
                        hashCounts[i] = 14
                }</span>
        }

        <span class="cov0" title="0">return expectedTokens, hashCounts</span>
}
</pre>
		
		<pre class="file" id="file4" style="display: none">package pipeline

import (
        "fmt"
        "math"
        "strings"
        "sync"
        "time"

        "cursor-twitter/src/tweets"
        "log/slog"
)

// ThreePartKeyQueue is a thread-safe queue for ThreePartKeys
type ThreePartKeyQueue struct {
        items []tweets.ThreePartKey
        mu    sync.Mutex
}

// NewThreePartKeyQueue creates a new ThreePartKeyQueue
func NewThreePartKeyQueue() *ThreePartKeyQueue <span class="cov0" title="0">{
        return &amp;ThreePartKeyQueue{
                items: make([]tweets.ThreePartKey, 0),
        }
}</span>

// Enqueue adds ThreePartKeys to the queue
func (q *ThreePartKeyQueue) Enqueue(keys []tweets.ThreePartKey) <span class="cov0" title="0">{
        q.mu.Lock()
        defer q.mu.Unlock()
        q.items = append(q.items, keys...)
}</span>

// Dequeue removes and returns ThreePartKeys from the queue
func (q *ThreePartKeyQueue) Dequeue() []tweets.ThreePartKey <span class="cov0" title="0">{
        q.mu.Lock()
        defer q.mu.Unlock()

        if len(q.items) == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>

        // Return up to 100 keys at a time
        <span class="cov0" title="0">batchSize := 100
        if len(q.items) &lt; batchSize </span><span class="cov0" title="0">{
                batchSize = len(q.items)
        }</span>

        <span class="cov0" title="0">result := q.items[:batchSize]
        q.items = q.items[batchSize:]
        return result</span>
}

// Len returns the number of items in the queue
func (q *ThreePartKeyQueue) Len() int <span class="cov0" title="0">{
        q.mu.Lock()
        defer q.mu.Unlock()
        return len(q.items)
}</span>

// BatchResult holds the busy words found by a processor in one batch
type BatchResult struct {
        ClassIndex int
        BusyWords  []tweets.ThreePartKey
        WordCount  int
        Error      error
        Timestamp  time.Time
}

// BatchSummary holds the complete results from all frequency classes
type BatchSummary struct {
        BatchNumber    int
        TotalBusyWords int
        ClassResults   map[int][]string // class index -&gt; list of busy words
        Timestamp      time.Time
}

// FrequencyClassProcessor manages queues and processors for each frequency class
type FrequencyClassProcessor struct {
        queues     []*ThreePartKeyQueue
        processors []*BusyWordProcessor
        numClasses int
        stopChan   chan struct{}
        wg         sync.WaitGroup

        // Batch coordination
        batchResults chan BatchResult
        batchBarrier *Barrier
        batchMutex   sync.Mutex
        batchActive  bool
        batchNumber  int

        // Global token mapping reference (set from main.go)
        globalTokenMapping map[tweets.ThreePartKey]string
        globalMappingMutex *sync.RWMutex
}

// Barrier implements thread coordination barrier pattern
type Barrier struct {
        mu      sync.Mutex
        count   int
        waiting int
        cond    *sync.Cond
}

// NewBarrier creates a new barrier for N threads
func NewBarrier(count int) *Barrier <span class="cov0" title="0">{
        b := &amp;Barrier{count: count}
        b.cond = sync.NewCond(&amp;b.mu)
        return b
}</span>

// Wait blocks until all N threads have called Wait()
func (b *Barrier) Wait() <span class="cov0" title="0">{
        b.mu.Lock()
        b.waiting++

        if b.waiting &lt; b.count </span><span class="cov0" title="0">{
                // Not all threads have reached the barrier yet
                b.cond.Wait()
        }</span> else<span class="cov0" title="0"> {
                // All threads have reached the barrier, wake everyone up
                b.cond.Broadcast()
        }</span>

        <span class="cov0" title="0">b.mu.Unlock()</span>
}

// Reset resets the barrier for the next cycle
func (b *Barrier) Reset() <span class="cov0" title="0">{
        b.mu.Lock()
        b.waiting = 0
        b.mu.Unlock()
}</span>

// IsComplete returns true if all threads have reached the barrier
func (b *Barrier) IsComplete() bool <span class="cov0" title="0">{
        b.mu.Lock()
        defer b.mu.Unlock()
        return b.waiting == b.count
}</span>

// BusyWordProcessor processes ThreePartKeys for a specific frequency class
type BusyWordProcessor struct {
        classIndex int
        queue      *ThreePartKeyQueue
        stopChan   chan struct{}
        wg         sync.WaitGroup
        tokenCount int
        mutex      sync.Mutex

        // Counter arrays for the three parts of 3PK
        part1Counters []int
        part2Counters []int
        part3Counters []int
        arrayLen      int

        // Configuration
        zScoreThreshold float64

        // Global token mapping reference (set from main.go)
        globalTokenMapping map[tweets.ThreePartKey]string
        globalMappingMutex *sync.RWMutex

        // Batch coordination
        freqClassProcessor *FrequencyClassProcessor
}

// NewFrequencyClassProcessor creates a new processor with the specified number of classes
func NewFrequencyClassProcessor(numClasses int, arrayLen int, zScoreThreshold float64) *FrequencyClassProcessor <span class="cov0" title="0">{
        queues := make([]*ThreePartKeyQueue, numClasses)
        processors := make([]*BusyWordProcessor, numClasses)

        fcp := &amp;FrequencyClassProcessor{
                queues:       queues,
                processors:   processors,
                numClasses:   numClasses,
                stopChan:     make(chan struct{}),
                batchResults: make(chan BatchResult, numClasses), // Buffer for all processors
                batchBarrier: NewBarrier(numClasses),
        }

        for i := 0; i &lt; numClasses; i++ </span><span class="cov0" title="0">{
                queues[i] = NewThreePartKeyQueue()
                processors[i] = NewBusyWordProcessor(i, queues[i], arrayLen, zScoreThreshold, fcp)
        }</span>

        <span class="cov0" title="0">return fcp</span>
}

// NewBusyWordProcessor creates a new busy word processor for a specific class
func NewBusyWordProcessor(classIndex int, queue *ThreePartKeyQueue, arrayLen int, zScoreThreshold float64, fcp *FrequencyClassProcessor) *BusyWordProcessor <span class="cov0" title="0">{
        // Initialize counter arrays to zero
        part1Counters := make([]int, arrayLen)
        part2Counters := make([]int, arrayLen)
        part3Counters := make([]int, arrayLen)

        return &amp;BusyWordProcessor{
                classIndex:         classIndex,
                queue:              queue,
                stopChan:           make(chan struct{}),
                tokenCount:         0,
                part1Counters:      part1Counters,
                part2Counters:      part2Counters,
                part3Counters:      part3Counters,
                arrayLen:           arrayLen,
                zScoreThreshold:    zScoreThreshold,
                freqClassProcessor: fcp,
        }
}</span>

// Start begins all the busy word processors
func (fcp *FrequencyClassProcessor) Start() <span class="cov0" title="0">{
        slog.Info("Starting FrequencyClassProcessor", "num_classes", fcp.numClasses)

        for i, processor := range fcp.processors </span><span class="cov0" title="0">{
                fcp.wg.Add(1)
                go func(p *BusyWordProcessor, classIdx int) </span><span class="cov0" title="0">{
                        defer fcp.wg.Done()
                        p.run()
                }</span>(processor, i)
                <span class="cov0" title="0">slog.Info("Started BusyWordProcessor", "class_index", i)</span>
        }

        // Start the batch result collector
        <span class="cov0" title="0">go fcp.collectBatchResults()</span>
}

// Stop gracefully stops all processors
func (fcp *FrequencyClassProcessor) Stop() <span class="cov0" title="0">{
        close(fcp.stopChan)
        fcp.wg.Wait()
        slog.Info("FrequencyClassProcessor stopped")
}</span>

// collectBatchResults collects and merges results from all processors
func (fcp *FrequencyClassProcessor) collectBatchResults() <span class="cov0" title="0">{
        // Track results for current batch
        currentBatch := make(map[int][]string)
        resultsReceived := 0

        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-fcp.stopChan:<span class="cov0" title="0">
                        return</span>
                case result := &lt;-fcp.batchResults:<span class="cov0" title="0">
                        if result.Error != nil </span><span class="cov0" title="0">{
                                slog.Error("Busy word processor error",
                                        "class_index", result.ClassIndex,
                                        "error", result.Error)
                                continue</span>
                        }

                        // Convert 3PKs to actual words
                        <span class="cov0" title="0">busyWords := fcp.convert3PKsToWords(result.BusyWords)

                        // Store results for this class
                        currentBatch[result.ClassIndex] = busyWords
                        resultsReceived++

                        // Immediate feedback for this class (simplified)
                        fmt.Printf("Class %d: %d busy words\n", result.ClassIndex, len(busyWords))

                        // Check if all classes have reported
                        if resultsReceived == fcp.numClasses </span><span class="cov0" title="0">{
                                // Print batch summary
                                fcp.printBatchSummary(currentBatch)

                                // Reset for next batch
                                currentBatch = make(map[int][]string)
                                resultsReceived = 0
                                fcp.batchNumber++
                        }</span>
                }
        }
}

// printBatchSummary prints a summary of all busy words found in this batch
func (fcp *FrequencyClassProcessor) printBatchSummary(classResults map[int][]string) <span class="cov0" title="0">{
        fmt.Printf("\n" + strings.Repeat("=", 60) + "\n")
        fmt.Printf("BATCH %d SUMMARY: %d frequency classes completed\n",
                fcp.batchNumber, fcp.numClasses)

        totalBusyWords := 0
        for classIndex, words := range classResults </span><span class="cov0" title="0">{
                totalBusyWords += len(words)
                fmt.Printf("Class %d: %d busy words\n", classIndex, len(words))
        }</span>

        <span class="cov0" title="0">fmt.Printf("TOTAL: %d busy words\n", totalBusyWords)

        // Print busy words by class (only if there are any)
        for classIndex, words := range classResults </span><span class="cov0" title="0">{
                if len(words) &gt; 0 </span><span class="cov0" title="0">{
                        fmt.Printf("\nClass %d busy words:\n", classIndex)
                        for i, word := range words </span><span class="cov0" title="0">{
                                fmt.Printf("  %d. %s\n", i+1, word)
                        }</span>
                }
        }

        <span class="cov0" title="0">fmt.Printf(strings.Repeat("=", 60) + "\n\n")</span>
}

// convert3PKsToWords converts ThreePartKeys back to actual word strings
func (fcp *FrequencyClassProcessor) convert3PKsToWords(threePKs []tweets.ThreePartKey) []string <span class="cov0" title="0">{
        words := make([]string, 0, len(threePKs))

        for _, threePK := range threePKs </span><span class="cov0" title="0">{
                // Get the word from the global token mapping
                if word, exists := fcp.getWordFrom3PK(threePK); exists </span><span class="cov0" title="0">{
                        words = append(words, word)
                }</span>
        }

        <span class="cov0" title="0">return words</span>
}

// getWordFrom3PK safely retrieves a word from the global token mapping
func (fcp *FrequencyClassProcessor) getWordFrom3PK(threePK tweets.ThreePartKey) (string, bool) <span class="cov0" title="0">{
        if fcp.globalMappingMutex == nil || fcp.globalTokenMapping == nil </span><span class="cov0" title="0">{
                // Fallback to placeholder if mapping not available
                return fmt.Sprintf("word_%d_%d_%d", threePK.Part1, threePK.Part2, threePK.Part3), true
        }</span>

        <span class="cov0" title="0">fcp.globalMappingMutex.RLock()
        defer fcp.globalMappingMutex.RUnlock()

        word, exists := fcp.globalTokenMapping[threePK]
        return word, exists</span>
}

// EnqueueToFrequencyClass routes a ThreePartKey to the appropriate frequency class queue
func (fcp *FrequencyClassProcessor) EnqueueToFrequencyClass(classIndex int, key tweets.ThreePartKey) <span class="cov0" title="0">{
        if classIndex &lt; 0 || classIndex &gt;= fcp.numClasses </span><span class="cov0" title="0">{
                slog.Warn("Invalid frequency class index", "class_index", classIndex, "num_classes", fcp.numClasses)
                return
        }</span>
        <span class="cov0" title="0">fcp.queues[classIndex].Enqueue([]tweets.ThreePartKey{key})

        // Debug: Log enqueuing occasionally
        queueSize := fcp.queues[classIndex].Len()
        if queueSize%1000 == 0 &amp;&amp; queueSize &gt; 0 </span><span class="cov0" title="0">{
                slog.Info("3pk enqueued to frequency class",
                        "class_index", classIndex,
                        "queue_size", queueSize,
                        "three_pk", key)
        }</span>
}

// EnqueueKeysToFrequencyClass routes multiple ThreePartKeys to a frequency class queue
func (fcp *FrequencyClassProcessor) EnqueueKeysToFrequencyClass(classIndex int, keys []tweets.ThreePartKey) <span class="cov0" title="0">{
        if classIndex &lt; 0 || classIndex &gt;= fcp.numClasses </span><span class="cov0" title="0">{
                slog.Warn("Invalid frequency class index", "class_index", classIndex, "num_classes", fcp.numClasses)
                return
        }</span>
        <span class="cov0" title="0">fcp.queues[classIndex].Enqueue(keys)</span>
}

// GetQueueStats returns statistics about all frequency class queues
func (fcp *FrequencyClassProcessor) GetQueueStats() map[string]int <span class="cov0" title="0">{
        stats := make(map[string]int)
        for i, queue := range fcp.queues </span><span class="cov0" title="0">{
                stats[fmt.Sprintf("freq_class_%d_queue_size", i)] = queue.Len()
        }</span>
        <span class="cov0" title="0">return stats</span>
}

// GetProcessorStats returns statistics about all busy word processors
func (fcp *FrequencyClassProcessor) GetProcessorStats() map[string]int <span class="cov0" title="0">{
        stats := make(map[string]int)
        for i, processor := range fcp.processors </span><span class="cov0" title="0">{
                stats[fmt.Sprintf("freq_class_%d_tokens_processed", i)] = processor.GetTokenCount()
        }</span>
        <span class="cov0" title="0">return stats</span>
}

// run is the main loop for a busy word processor
func (bwp *BusyWordProcessor) run() <span class="cov0" title="0">{
        defer bwp.wg.Done()

        slog.Info("BusyWordProcessor started", "class_index", bwp.classIndex, "array_len", bwp.arrayLen)

        loopCount := 0
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-bwp.stopChan:<span class="cov0" title="0">
                        slog.Info("BusyWordProcessor stopping", "class_index", bwp.classIndex)
                        return</span>
                default:<span class="cov0" title="0">
                        loopCount++

                        // Try to get ThreePartKeys from the queue
                        keys := bwp.queue.Dequeue()
                        if keys == nil </span><span class="cov0" title="0">{
                                // No keys available, wait a bit
                                time.Sleep(1 * time.Millisecond)
                                continue</span>
                        }

                        // Process the ThreePartKeys
                        <span class="cov0" title="0">for _, key := range keys </span><span class="cov0" title="0">{
                                // Check for termination signal: (-1, -1, -1)
                                if key.Part1 == -1 &amp;&amp; key.Part2 == -1 &amp;&amp; key.Part3 == -1 </span><span class="cov0" title="0">{
                                        // Perform coordinated z-computation
                                        bwp.performCoordinatedZComputation()
                                        continue</span>
                                }

                                // Increment counters for each part of the 3PK
                                <span class="cov0" title="0">index1 := key.Part1
                                index2 := key.Part2
                                index3 := key.Part3

                                bwp.part1Counters[index1]++
                                bwp.part2Counters[index2]++
                                bwp.part3Counters[index3]++

                                bwp.mutex.Lock()
                                bwp.tokenCount++
                                bwp.mutex.Unlock()</span>
                        }
                }
        }
}

// performCoordinatedZComputation performs z-computation and reports results to coordinator
func (bwp *BusyWordProcessor) performCoordinatedZComputation() <span class="cov0" title="0">{
        // fmt.Printf("*** BusyWordProcessor-%d: COORDINATED Z-COMPUTATION STARTED ***\n", bwp.classIndex)

        // Calculate statistics for each array
        part1Stats := bwp.CalculateArrayStats(bwp.part1Counters)
        part2Stats := bwp.CalculateArrayStats(bwp.part2Counters)
        part3Stats := bwp.CalculateArrayStats(bwp.part3Counters)

        // Calculate z-scores and find high-scoring positions
        part1HighZScores := bwp.CalculateZScores(bwp.part1Counters, part1Stats, bwp.zScoreThreshold)
        part2HighZScores := bwp.CalculateZScores(bwp.part2Counters, part2Stats, bwp.zScoreThreshold)
        part3HighZScores := bwp.CalculateZScores(bwp.part3Counters, part3Stats, bwp.zScoreThreshold)

        // Find busy words
        busyWords := bwp.FindBusyWords(part1HighZScores, part2HighZScores, part3HighZScores)

        // Report results to coordinator
        result := BatchResult{
                ClassIndex: bwp.classIndex,
                BusyWords:  busyWords,
                WordCount:  len(busyWords),
                Error:      nil,
                Timestamp:  time.Now(),
        }

        bwp.freqClassProcessor.batchResults &lt;- result

        // fmt.Printf("*** BusyWordProcessor-%d: COORDINATED Z-COMPUTATION COMPLETED ***\n", bwp.classIndex)
        // fmt.Printf("*** BusyWordProcessor-%d: Array totals - Part1: %d, Part2: %d, Part3: %d ***\n",
        //         bwp.classIndex, part1Stats.total, part2Stats.total, part3Stats.total)
        // fmt.Printf("*** BusyWordProcessor-%d: Part1 stats - Mean: %.2f, StdDev: %.2f ***\n",
        //         bwp.classIndex, part1Stats.mean, part1Stats.stdDev)
        // fmt.Printf("*** BusyWordProcessor-%d: Part2 stats - Mean: %.2f, StdDev: %.2f ***\n",
        //         bwp.classIndex, part2Stats.mean, part2Stats.stdDev)
        // fmt.Printf("*** BusyWordProcessor-%d: Part3 stats - Mean: %.2f, StdDev: %.2f ***\n",
        //         bwp.classIndex, part3Stats.mean, part3Stats.stdDev)
        // fmt.Printf("*** BusyWordProcessor-%d: High Z-scores (&gt;=%.1f) - Part1: %d, Part2: %d, Part3: %d ***\n",
        //         bwp.classIndex, bwp.zScoreThreshold, len(part1HighZScores), len(part2HighZScores), len(part3HighZScores))
        // fmt.Printf("*** BusyWordProcessor-%d: Busy words found: %d ***\n", bwp.classIndex, len(busyWords))

        // Wipe all counter arrays to zero
        for i := 0; i &lt; bwp.arrayLen; i++ </span><span class="cov0" title="0">{
                bwp.part1Counters[i] = 0
                bwp.part2Counters[i] = 0
                bwp.part3Counters[i] = 0
        }</span>

        // fmt.Printf("*** BusyWordProcessor-%d: Arrays reset, waiting at barrier ***\n", bwp.classIndex)

        // Wait at barrier until all processors have completed
        <span class="cov0" title="0">bwp.freqClassProcessor.batchBarrier.Wait()

        // Reset barrier for next cycle (only the last processor to reach barrier does this)
        bwp.freqClassProcessor.batchMutex.Lock()
        if bwp.freqClassProcessor.batchBarrier.IsComplete() </span><span class="cov0" title="0">{
                bwp.freqClassProcessor.batchBarrier.Reset()
                fmt.Printf("*** BARRIER RESET: All %d processors synchronized, starting next cycle ***\n",
                        bwp.freqClassProcessor.numClasses)
        }</span>
        <span class="cov0" title="0">bwp.freqClassProcessor.batchMutex.Unlock()</span>

        // fmt.Printf("*** BusyWordProcessor-%d: Barrier cleared, starting next cycle ***\n", bwp.classIndex)

        // slog.Info("Coordinated z-computation completed and arrays reset",
        //         "class_index", bwp.classIndex,
        //         "array_len", bwp.arrayLen,
        //         "part1_total", part1Stats.total,
        //         "part2_total", part2Stats.total,
        //         "part3_total", part3Stats.total,
        //         "part1_mean", part1Stats.mean,
        //         "part1_stddev", part1Stats.stdDev,
        //         "part2_mean", part2Stats.mean,
        //         "part2_stddev", part2Stats.stdDev,
        //         "part3_mean", part3Stats.mean,
        //         "part3_stddev", part3Stats.stdDev,
        //         "z_score_threshold", bwp.zScoreThreshold,
        //         "part1_high_z_scores", len(part1HighZScores),
        //         "part2_high_z_scores", len(part2HighZScores),
        //         "part3_high_z_scores", len(part3HighZScores))
}

// GetTokenCount returns the number of tokens processed by this processor
func (bwp *BusyWordProcessor) GetTokenCount() int <span class="cov0" title="0">{
        bwp.mutex.Lock()
        defer bwp.mutex.Unlock()
        return bwp.tokenCount
}</span>

// performZComputation performs statistical analysis on the counter arrays
// Calculates z-scores using Gaussian statistics for each array position
func (bwp *BusyWordProcessor) performZComputation() <span class="cov0" title="0">{
        fmt.Printf("*** BusyWordProcessor-%d: Z-COMPUTATION STARTED ***\n", bwp.classIndex)

        // Calculate statistics for each array
        part1Stats := bwp.CalculateArrayStats(bwp.part1Counters)
        part2Stats := bwp.CalculateArrayStats(bwp.part2Counters)
        part3Stats := bwp.CalculateArrayStats(bwp.part3Counters)

        // Calculate z-scores and find high-scoring positions
        part1HighZScores := bwp.CalculateZScores(bwp.part1Counters, part1Stats, bwp.zScoreThreshold)
        part2HighZScores := bwp.CalculateZScores(bwp.part2Counters, part2Stats, bwp.zScoreThreshold)
        part3HighZScores := bwp.CalculateZScores(bwp.part3Counters, part3Stats, bwp.zScoreThreshold)

        // Take cartesian product of high z-score positions to generate candidate 3PKs
        // For each combination (pos1, pos2, pos3) where pos1 ∈ part1HighZScores, pos2 ∈ part2HighZScores, pos3 ∈ part3HighZScores
        // Generate 3PK and check if it exists in the global token mapping table
        // This will identify the "busy words" for this frequency class
        busyWords := bwp.FindBusyWords(part1HighZScores, part2HighZScores, part3HighZScores)

        fmt.Printf("*** BusyWordProcessor-%d: Z-COMPUTATION COMPLETED ***\n", bwp.classIndex)
        fmt.Printf("*** BusyWordProcessor-%d: Array totals - Part1: %d, Part2: %d, Part3: %d ***\n",
                bwp.classIndex, part1Stats.Total, part2Stats.Total, part3Stats.Total)
        fmt.Printf("*** BusyWordProcessor-%d: Part1 stats - Mean: %.2f, StdDev: %.2f ***\n",
                bwp.classIndex, part1Stats.Mean, part1Stats.StdDev)
        fmt.Printf("*** BusyWordProcessor-%d: Part2 stats - Mean: %.2f, StdDev: %.2f ***\n",
                bwp.classIndex, part2Stats.Mean, part2Stats.StdDev)
        fmt.Printf("*** BusyWordProcessor-%d: Part3 stats - Mean: %.2f, StdDev: %.2f ***\n",
                bwp.classIndex, part3Stats.Mean, part3Stats.StdDev)
        fmt.Printf("*** BusyWordProcessor-%d: High Z-scores (&gt;=%.1f) - Part1: %d, Part2: %d, Part3: %d ***\n",
                bwp.classIndex, bwp.zScoreThreshold, len(part1HighZScores), len(part2HighZScores), len(part3HighZScores))
        fmt.Printf("*** BusyWordProcessor-%d: Busy words found: %d ***\n", bwp.classIndex, len(busyWords))
        fmt.Printf("*** BusyWordProcessor-%d: Wiping counter arrays to zero ***\n", bwp.classIndex)

        // Wipe all counter arrays to zero
        for i := 0; i &lt; bwp.arrayLen; i++ </span><span class="cov0" title="0">{
                bwp.part1Counters[i] = 0
                bwp.part2Counters[i] = 0
                bwp.part3Counters[i] = 0
        }</span>

        <span class="cov0" title="0">fmt.Printf("*** BusyWordProcessor-%d: Arrays reset, ready for next batch ***\n", bwp.classIndex)

        slog.Info("Z-computation completed and arrays reset",
                "class_index", bwp.classIndex,
                "array_len", bwp.arrayLen,
                "part1_total", part1Stats.Total,
                "part2_total", part2Stats.Total,
                "part3_total", part3Stats.Total,
                "part1_mean", part1Stats.Mean,
                "part1_stddev", part1Stats.StdDev,
                "part2_mean", part2Stats.Mean,
                "part2_stddev", part2Stats.StdDev,
                "part3_mean", part3Stats.Mean,
                "part3_stddev", part3Stats.StdDev,
                "z_score_threshold", bwp.zScoreThreshold,
                "part1_high_z_scores", len(part1HighZScores),
                "part2_high_z_scores", len(part2HighZScores),
                "part3_high_z_scores", len(part3HighZScores))</span>
}

// CalculateZScores calculates z-scores for each position and returns set of high-scoring positions
// Also calculates min, max, and mean z-scores for threshold tuning
func (bwp *BusyWordProcessor) CalculateZScores(counts []int, stats ArrayStats, threshold float64) map[int]float64 <span class="cov0" title="0">{
        highZScores := make(map[int]float64)

        // Avoid division by zero
        if stats.StdDev == 0 </span><span class="cov0" title="0">{
                return highZScores
        }</span>

        // Calculate all z-scores and track statistics
        <span class="cov0" title="0">var allZScores []float64
        for i, count := range counts </span><span class="cov0" title="0">{
                zScore := (float64(count) - stats.Mean) / stats.StdDev
                allZScores = append(allZScores, zScore)
                if zScore &gt;= threshold </span><span class="cov0" title="0">{
                        highZScores[i] = zScore
                }</span>
        }

        // Calculate z-score statistics
        <span class="cov0" title="0">if len(allZScores) &gt; 0 </span><span class="cov0" title="0">{
                minZ := allZScores[0]
                maxZ := allZScores[0]
                sumZ := 0.0

                for _, z := range allZScores </span><span class="cov0" title="0">{
                        if z &lt; minZ </span><span class="cov0" title="0">{
                                minZ = z
                        }</span>
                        <span class="cov0" title="0">if z &gt; maxZ </span><span class="cov0" title="0">{
                                maxZ = z
                        }</span>
                        <span class="cov0" title="0">sumZ += z</span>
                }
                <span class="cov0" title="0">meanZ := sumZ / float64(len(allZScores))

                fmt.Printf("*** BusyWordProcessor-%d: Z-score stats - Min: %.2f, Max: %.2f, Mean: %.2f ***\n",
                        bwp.classIndex, minZ, maxZ, meanZ)</span>
        }

        <span class="cov0" title="0">return highZScores</span>
}

// ArrayStats holds statistical information about an array
type ArrayStats struct {
        Total  int
        Mean   float64
        StdDev float64
}

// CalculateArrayStats calculates mean, standard deviation, and z-scores for an array
func (bwp *BusyWordProcessor) CalculateArrayStats(counts []int) ArrayStats <span class="cov0" title="0">{
        // Calculate total and mean
        total := 0
        for _, count := range counts </span><span class="cov0" title="0">{
                total += count
        }</span>
        <span class="cov0" title="0">mean := float64(total) / float64(bwp.arrayLen)

        // Calculate variance (sum of squared differences from mean)
        variance := 0.0
        for _, count := range counts </span><span class="cov0" title="0">{
                diff := float64(count) - mean
                variance += diff * diff
        }</span>
        <span class="cov0" title="0">variance = variance / float64(bwp.arrayLen)

        // Calculate standard deviation
        stdDev := math.Sqrt(variance)

        return ArrayStats{
                Total:  total,
                Mean:   mean,
                StdDev: stdDev,
        }</span>
}

// FindBusyWords finds busy words from high z-score positions
func (bwp *BusyWordProcessor) FindBusyWords(part1HighZScores, part2HighZScores, part3HighZScores map[int]float64) []tweets.ThreePartKey <span class="cov0" title="0">{
        busyWords := []tweets.ThreePartKey{}

        // Iterate over all combinations of high z-score positions
        for pos1, _ := range part1HighZScores </span><span class="cov0" title="0">{
                for pos2, _ := range part2HighZScores </span><span class="cov0" title="0">{
                        for pos3, _ := range part3HighZScores </span><span class="cov0" title="0">{
                                // Generate 3PK from high z-score positions
                                key := tweets.ThreePartKey{
                                        Part1: pos1,
                                        Part2: pos2,
                                        Part3: pos3,
                                }

                                // Check if the generated 3PK exists in the global token mapping table
                                if bwp.existsInGlobalTokenMapping(key) </span><span class="cov0" title="0">{
                                        busyWords = append(busyWords, key)
                                }</span>
                        }
                }
        }

        <span class="cov0" title="0">return busyWords</span>
}

// SetGlobalTokenMapping sets the reference to the global token mapping
func (bwp *BusyWordProcessor) SetGlobalTokenMapping(mapping map[tweets.ThreePartKey]string, mutex *sync.RWMutex) <span class="cov0" title="0">{
        bwp.globalTokenMapping = mapping
        bwp.globalMappingMutex = mutex
}</span>

// existsInGlobalTokenMapping checks if a ThreePartKey exists in the global token mapping table
func (bwp *BusyWordProcessor) existsInGlobalTokenMapping(key tweets.ThreePartKey) bool <span class="cov0" title="0">{
        if bwp.globalMappingMutex == nil || bwp.globalTokenMapping == nil </span><span class="cov0" title="0">{
                return false
        }</span>

        <span class="cov0" title="0">bwp.globalMappingMutex.RLock()
        defer bwp.globalMappingMutex.RUnlock()

        _, exists := bwp.globalTokenMapping[key]
        return exists</span>
}

// SetGlobalTokenMappingForAll sets the global token mapping for all busy word processors
func (fcp *FrequencyClassProcessor) SetGlobalTokenMappingForAll(mapping map[tweets.ThreePartKey]string, mutex *sync.RWMutex) <span class="cov0" title="0">{
        // Set the mapping in the FrequencyClassProcessor itself
        fcp.globalTokenMapping = mapping
        fcp.globalMappingMutex = mutex

        // Also set it in all individual processors
        for _, processor := range fcp.processors </span><span class="cov0" title="0">{
                processor.SetGlobalTokenMapping(mapping, mutex)
        }</span>
}
</pre>
		
		<pre class="file" id="file5" style="display: none">package pipeline

import (
        "encoding/gob"
        "fmt"
        "os"
        "path/filepath"
        "sort"
        "sync"

        "github.com/bits-and-blooms/bloom/v3"
)

// TokenCount holds a token and its count.
type TokenCount struct {
        Token string
        Count int
}

// FreqClassFilter interface for both set and Bloom filter implementations
type FreqClassFilter interface {
        Contains(token string) bool
}

// SetFilter implements FreqClassFilter using a simple hash set
type SetFilter struct {
        tokens map[string]bool
}

// NewSetFilter creates a new SetFilter with the given tokens
func NewSetFilter(tokens []string) *SetFilter <span class="cov0" title="0">{
        sf := &amp;SetFilter{tokens: make(map[string]bool, len(tokens))}
        for _, token := range tokens </span><span class="cov0" title="0">{
                sf.tokens[token] = true
        }</span>
        <span class="cov0" title="0">return sf</span>
}

func (sf *SetFilter) Contains(token string) bool <span class="cov8" title="1">{
        return sf.tokens[token]
}</span>

// BloomFilterWrapper implements FreqClassFilter using a Bloom filter
type BloomFilterWrapper struct {
        filter *bloom.BloomFilter
}

func (bf *BloomFilterWrapper) Contains(token string) bool <span class="cov0" title="0">{
        return bf.filter.TestString(token)
}</span>

// SerializableFilter represents a filter that can be saved/loaded
type SerializableFilter struct {
        Type   string   // "set" or "bloom"
        Tokens []string // For SetFilter
        // Note: Bloom filters are not easily serializable, so we'll focus on SetFilter for now
}

// Add a struct to hold the result
type FreqClassResult struct {
        Filters   []FreqClassFilter
        TopTokens []TokenCount
}

// CRITICAL: ONLY the FCT (FrequencyComputationThread) should ever touch token counters or do frequency calculations.
// DO NOT create any other threads, managers, or background processes that access token counters.
// The FCT is the single source of truth for all token counting and frequency computation.

// BuildFrequencyClassBloomFiltersOptimized is an optimized version that doesn't require TokenCounter
func BuildFrequencyClassBloomFiltersOptimized(tokenCounts map[string]int, F int, bloomSizes []uint, hashCounts []uint) FreqClassResult <span class="cov8" title="1">{
        // Step 1: Build a slice of (token, count) pairs (pre-allocate for efficiency)
        tokenCountsSlice := make([]TokenCount, 0, len(tokenCounts))
        for token, count := range tokenCounts </span><span class="cov8" title="1">{
                tokenCountsSlice = append(tokenCountsSlice, TokenCount{Token: token, Count: count})
        }</span>

        // Step 2: Sort by count descending (most frequent first)
        <span class="cov8" title="1">sort.Slice(tokenCountsSlice, func(i, j int) bool </span><span class="cov8" title="1">{
                return tokenCountsSlice[i].Count &gt; tokenCountsSlice[j].Count
        }</span>)

        // Step 3: Calculate total count and class size
        <span class="cov8" title="1">total := 0
        for _, tc := range tokenCountsSlice </span><span class="cov8" title="1">{
                total += tc.Count
        }</span>
        <span class="cov8" title="1">if F &lt;= 0 </span><span class="cov0" title="0">{
                F = 1
        }</span>
        <span class="cov8" title="1">C := total / F

        // Step 4: Assign tokens to F classes (optimized)
        classes := make([][]string, F)
        classIdx := 0
        runningTotal := 0

        for _, pair := range tokenCountsSlice </span><span class="cov8" title="1">{
                if classIdx &lt; F-1 &amp;&amp; runningTotal &gt;= (classIdx+1)*C </span><span class="cov8" title="1">{
                        classIdx++
                }</span>
                <span class="cov8" title="1">classes[classIdx] = append(classes[classIdx], pair.Token)
                runningTotal += pair.Count</span>
        }

        // Step 5: Create F filters and insert tokens (parallel processing)
        <span class="cov8" title="1">filters := make([]FreqClassFilter, F)
        var wg sync.WaitGroup

        for i := 0; i &lt; F; i++ </span><span class="cov8" title="1">{
                wg.Add(1)
                go func(classIndex int) </span><span class="cov8" title="1">{
                        defer wg.Done()
                        tokenCount := len(classes[classIndex])

                        // Use hash set for small classes (threshold: 1000 tokens)
                        if tokenCount &lt; 1000 </span><span class="cov8" title="1">{
                                setFilter := &amp;SetFilter{tokens: make(map[string]bool, tokenCount)}
                                for _, token := range classes[classIndex] </span><span class="cov8" title="1">{
                                        setFilter.tokens[token] = true
                                }</span>
                                <span class="cov8" title="1">filters[classIndex] = setFilter</span>
                        } else<span class="cov0" title="0"> {
                                // Use Bloom filter for large classes
                                bloomSize := uint(tokenCount * 10) // Simple sizing
                                numHashes := uint(10)              // Simple hash count
                                if bloomSizes != nil &amp;&amp; classIndex &lt; len(bloomSizes) </span><span class="cov0" title="0">{
                                        bloomSize = bloomSizes[classIndex]
                                }</span>
                                <span class="cov0" title="0">if hashCounts != nil &amp;&amp; classIndex &lt; len(hashCounts) </span><span class="cov0" title="0">{
                                        numHashes = hashCounts[classIndex]
                                }</span>

                                <span class="cov0" title="0">bf := bloom.New(bloomSize, numHashes)
                                for _, token := range classes[classIndex] </span><span class="cov0" title="0">{
                                        bf.AddString(token)
                                }</span>
                                <span class="cov0" title="0">filters[classIndex] = &amp;BloomFilterWrapper{filter: bf}</span>
                        }
                }(i)
        }

        <span class="cov8" title="1">wg.Wait()

        // Log final class distribution
        for i := 0; i &lt; F; i++ </span><span class="cov8" title="1">{
                fmt.Printf("[AsyncFreqClass] Class %d assigned %d tokens\n", i+1, len(classes[i]))
        }</span>

        <span class="cov8" title="1">return FreqClassResult{
                Filters:   filters,
                TopTokens: tokenCountsSlice[:min(10, len(tokenCountsSlice))],
        }</span>
}

// min helper function
func min(a, b int) int <span class="cov8" title="1">{
        if a &lt; b </span><span class="cov8" title="1">{
                return a
        }</span>
        <span class="cov8" title="1">return b</span>
}

// BuildFrequencyClassHashSets divides tokens into F frequency classes and returns F hash set filters.
// Each class accounts for roughly the same number of token occurrences (not unique tokens).
func BuildFrequencyClassHashSets(tokenCounts map[string]int, F int, bloomSizes []uint, hashCounts []uint) FreqClassResult <span class="cov8" title="1">{
        // Step 1: Build a slice of (token, count) pairs
        tokenCountsSlice := make([]TokenCount, 0, len(tokenCounts))
        for token, count := range tokenCounts </span><span class="cov8" title="1">{
                tokenCountsSlice = append(tokenCountsSlice, TokenCount{Token: token, Count: count})
        }</span>

        // Step 2: Sort by count descending (most frequent first)
        <span class="cov8" title="1">sort.Slice(tokenCountsSlice, func(i, j int) bool </span><span class="cov8" title="1">{
                return tokenCountsSlice[i].Count &gt; tokenCountsSlice[j].Count
        }</span>)

        // Step 3: Calculate total count and class size
        <span class="cov8" title="1">total := 0
        for _, tc := range tokenCountsSlice </span><span class="cov8" title="1">{
                total += tc.Count
        }</span>
        <span class="cov8" title="1">if F &lt;= 0 </span><span class="cov0" title="0">{
                F = 1
        }</span>
        <span class="cov8" title="1">C := total / F

        // Step 4: Assign tokens to F classes
        classes := make([][]string, F)
        classIdx := 0
        runningTotal := 0

        fmt.Printf("*** DEBUG: Starting token distribution to %d classes ***\n", F)
        for _, pair := range tokenCountsSlice </span><span class="cov8" title="1">{
                if classIdx &lt; F-1 &amp;&amp; runningTotal &gt;= (classIdx+1)*C </span><span class="cov8" title="1">{
                        fmt.Printf("*** DEBUG: Advancing from class %d to class %d at running total %d (threshold: %d) ***\n",
                                classIdx+1, classIdx+2, runningTotal, (classIdx+1)*C)
                        classIdx++
                }</span>
                <span class="cov8" title="1">classes[classIdx] = append(classes[classIdx], pair.Token)
                runningTotal += pair.Count</span>
        }
        <span class="cov8" title="1">fmt.Printf("*** DEBUG: Token distribution complete. Final running total: %d ***\n", runningTotal)

        // Step 5: Create F hash set filters and insert tokens
        filters := make([]FreqClassFilter, F)
        for i := 0; i &lt; F; i++ </span><span class="cov8" title="1">{
                setFilter := &amp;SetFilter{tokens: make(map[string]bool, len(classes[i]))}
                for _, token := range classes[i] </span><span class="cov8" title="1">{
                        setFilter.tokens[token] = true
                }</span>
                <span class="cov8" title="1">filters[i] = setFilter</span>
        }

        // Log final class distribution with usage counts
        <span class="cov8" title="1">fmt.Printf("*** FREQUENCY CLASS REBUILD: Built %d classes ***\n", F)
        fmt.Printf("*** DEBUG: Total tokens to distribute: %d, Target per class: %d ***\n", total, C)
        for i := 0; i &lt; F; i++ </span><span class="cov8" title="1">{
                // Calculate total usage for this class
                classUsage := 0
                for _, token := range classes[i] </span><span class="cov8" title="1">{
                        for _, tc := range tokenCountsSlice </span><span class="cov8" title="1">{
                                if tc.Token == token </span><span class="cov8" title="1">{
                                        classUsage += tc.Count
                                        break</span>
                                }
                        }
                }
                <span class="cov8" title="1">fmt.Printf("  Class %d: %d distinct tokens, %d total usages\n", i+1, len(classes[i]), classUsage)
                if len(classes[i]) == 0 </span><span class="cov0" title="0">{
                        fmt.Printf("  *** WARNING: Class %d is empty! ***\n", i+1)
                }</span>
        }
        <span class="cov8" title="1">fmt.Printf("*** FREQUENCY CLASS REBUILD COMPLETE ***\n")

        return FreqClassResult{
                Filters:   filters,
                TopTokens: tokenCountsSlice[:min(10, len(tokenCountsSlice))],
        }</span>
}

var globalFiltersMutex sync.RWMutex
var globalFilters []FreqClassFilter

// SetGlobalFilters sets the global frequency class filters
func SetGlobalFilters(filters []FreqClassFilter) <span class="cov8" title="1">{
        globalFiltersMutex.Lock()
        defer globalFiltersMutex.Unlock()
        globalFilters = filters
        fmt.Printf("*** SetGlobalFilters called with %d filters ***\n", len(filters))
}</span>

// GetGlobalFilters returns the current global frequency class filters
func GetGlobalFilters() []FreqClassFilter <span class="cov0" title="0">{
        globalFiltersMutex.RLock()
        defer globalFiltersMutex.RUnlock()
        result := make([]FreqClassFilter, len(globalFilters))
        copy(result, globalFilters)
        //fmt.Printf("*** GetGlobalFilters called, returning %d filters ***\n", len(result))
        return result
}</span>

// SaveToFile saves the frequency class filters to a file
// Note: This only saves SetFilter types, not BloomFilterWrapper
func (fcr *FreqClassResult) SaveToFile(filename string) error <span class="cov8" title="1">{
        // Ensure the directory exists
        dir := filepath.Dir(filename)
        if err := os.MkdirAll(dir, 0755); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create directory %s: %v", dir, err)
        }</span>

        // Create the file
        <span class="cov8" title="1">file, err := os.Create(filename)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create file %s: %v", filename, err)
        }</span>
        <span class="cov8" title="1">defer file.Close()

        // Convert filters to serializable format
        serializableFilters := make([]SerializableFilter, len(fcr.Filters))
        for i, filter := range fcr.Filters </span><span class="cov8" title="1">{
                if setFilter, ok := filter.(*SetFilter); ok </span><span class="cov8" title="1">{
                        // Convert SetFilter to SerializableFilter
                        tokens := make([]string, 0, len(setFilter.tokens))
                        for token := range setFilter.tokens </span><span class="cov8" title="1">{
                                tokens = append(tokens, token)
                        }</span>
                        <span class="cov8" title="1">serializableFilters[i] = SerializableFilter{
                                Type:   "set",
                                Tokens: tokens,
                        }</span>
                } else<span class="cov0" title="0"> {
                        // Skip BloomFilterWrapper for now
                        serializableFilters[i] = SerializableFilter{
                                Type:   "bloom",
                                Tokens: []string{}, // Bloom filters not serialized
                        }
                }</span>
        }

        // Create serializable result
        <span class="cov8" title="1">serializableResult := struct {
                Filters   []SerializableFilter
                TopTokens []TokenCount
        }{
                Filters:   serializableFilters,
                TopTokens: fcr.TopTokens,
        }

        // Encode and write to file
        encoder := gob.NewEncoder(file)
        if err := encoder.Encode(serializableResult); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to encode filters to %s: %v", filename, err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// LoadFromFile loads frequency class filters from a file
func (fcr *FreqClassResult) LoadFromFile(filename string) error <span class="cov8" title="1">{
        // Open the file
        file, err := os.Open(filename)
        if err != nil </span><span class="cov8" title="1">{
                return fmt.Errorf("failed to open file %s: %v", filename, err)
        }</span>
        <span class="cov8" title="1">defer file.Close()

        // Decode the serializable result
        var serializableResult struct {
                Filters   []SerializableFilter
                TopTokens []TokenCount
        }
        decoder := gob.NewDecoder(file)
        if err := decoder.Decode(&amp;serializableResult); err != nil </span><span class="cov8" title="1">{
                return fmt.Errorf("failed to decode filters from %s: %v", filename, err)
        }</span>

        // Convert back to FreqClassFilter
        <span class="cov8" title="1">filters := make([]FreqClassFilter, len(serializableResult.Filters))
        for i, sf := range serializableResult.Filters </span><span class="cov8" title="1">{
                if sf.Type == "set" </span><span class="cov8" title="1">{
                        // Convert SerializableFilter back to SetFilter
                        setFilter := &amp;SetFilter{tokens: make(map[string]bool, len(sf.Tokens))}
                        for _, token := range sf.Tokens </span><span class="cov8" title="1">{
                                setFilter.tokens[token] = true
                        }</span>
                        <span class="cov8" title="1">filters[i] = setFilter</span>
                } else<span class="cov0" title="0"> {
                        // For bloom filters, create an empty SetFilter (placeholder)
                        filters[i] = &amp;SetFilter{tokens: make(map[string]bool)}
                }</span>
        }

        // Update the FreqClassResult
        <span class="cov8" title="1">fcr.Filters = filters
        fcr.TopTokens = serializableResult.TopTokens

        return nil</span>
}

// BuildFrequencyClassBloomFilters divides tokens into F frequency classes and returns F filters.
// Each class accounts for roughly the same number of token occurrences (not unique tokens).
// Small classes use hash sets, large classes use Bloom filters.
// bloomSizes and hashCounts are arrays of length F, one for each frequency class.
func BuildFrequencyClassBloomFilters(tc *TokenCounter, F int, bloomSizes []uint, hashCounts []uint) FreqClassResult <span class="cov0" title="0">{
        // Step 1: Build a slice of (token, count) pairs
        tokenCounts := make([]TokenCount, 0, len(tc.Counts()))
        for token, count := range tc.Counts() </span><span class="cov0" title="0">{
                tokenCounts = append(tokenCounts, TokenCount{Token: token, Count: count})
        }</span>

        // Step 2: Sort by count descending (most frequent first)
        <span class="cov0" title="0">sort.Slice(tokenCounts, func(i, j int) bool </span><span class="cov0" title="0">{
                return tokenCounts[i].Count &gt; tokenCounts[j].Count
        }</span>)

        // Log the top 10 most frequent tokens
        <span class="cov0" title="0">topN := 10
        if len(tokenCounts) &lt; topN </span><span class="cov0" title="0">{
                topN = len(tokenCounts)
        }</span>
        <span class="cov0" title="0">fmt.Printf("[FreqClass] Top %d tokens: ", topN)
        for i := 0; i &lt; topN; i++ </span><span class="cov0" title="0">{
                fmt.Printf("%s(%d) ", tokenCounts[i].Token, tokenCounts[i].Count)
        }</span>
        <span class="cov0" title="0">fmt.Println()

        // Step 3: Calculate total count and class size
        total := 0
        for _, tc := range tokenCounts </span><span class="cov0" title="0">{
                total += tc.Count
        }</span>
        <span class="cov0" title="0">if F &lt;= 0 </span><span class="cov0" title="0">{
                F = 1
        }</span>
        <span class="cov0" title="0">C := total / F
        fmt.Printf("[FreqClass] Total tokens: %d, Classes: %d, Target per class: %d\n", total, F, C)

        // Step 4: Assign tokens to F classes
        classes := make([][]string, F)
        classIdx := 0
        runningTotal := 0
        for _, pair := range tokenCounts </span><span class="cov0" title="0">{
                if classIdx &lt; F-1 &amp;&amp; runningTotal &gt;= (classIdx+1)*C </span><span class="cov0" title="0">{
                        fmt.Printf("[FreqClass] Advancing to class %d at running total %d\n", classIdx+1, runningTotal)
                        classIdx++
                }</span>
                <span class="cov0" title="0">classes[classIdx] = append(classes[classIdx], pair.Token)
                runningTotal += pair.Count</span>
        }

        // Log final class distribution
        <span class="cov0" title="0">for i := 0; i &lt; F; i++ </span><span class="cov0" title="0">{
                fmt.Printf("[FreqClass] Class %d assigned %d tokens\n", i+1, len(classes[i]))
        }</span>

        // Step 5: Create F filters and insert tokens
        <span class="cov0" title="0">filters := make([]FreqClassFilter, F)
        for i := 0; i &lt; F; i++ </span><span class="cov0" title="0">{
                tokenCount := len(classes[i])

                // Use hash set for small classes (threshold: 1000 tokens)
                if tokenCount &lt; 1000 </span><span class="cov0" title="0">{
                        setFilter := &amp;SetFilter{tokens: make(map[string]bool)}
                        for _, token := range classes[i] </span><span class="cov0" title="0">{
                                setFilter.tokens[token] = true
                        }</span>
                        <span class="cov0" title="0">filters[i] = setFilter

                        // Log the number of tokens and total occurrences in this class
                        totalClassCount := 0
                        for _, token := range classes[i] </span><span class="cov0" title="0">{
                                for _, tc := range tokenCounts </span><span class="cov0" title="0">{
                                        if tc.Token == token </span><span class="cov0" title="0">{
                                                totalClassCount += tc.Count
                                        }</span>
                                }
                        }
                        <span class="cov0" title="0">fmt.Printf("[FreqClass] Class %d: %d tokens, %d total occurrences, using HASH SET\n",
                                i+1, len(classes[i]), totalClassCount)</span>
                } else<span class="cov0" title="0"> {
                        // Use Bloom filter for large classes
                        bloomSize := bloomSizes[i]
                        numHashes := hashCounts[i]
                        bf := bloom.New(bloomSize, numHashes)
                        for _, token := range classes[i] </span><span class="cov0" title="0">{
                                bf.AddString(token)
                        }</span>
                        <span class="cov0" title="0">filters[i] = &amp;BloomFilterWrapper{filter: bf}

                        // Log the number of tokens and total occurrences in this class
                        totalClassCount := 0
                        for _, token := range classes[i] </span><span class="cov0" title="0">{
                                for _, tc := range tokenCounts </span><span class="cov0" title="0">{
                                        if tc.Token == token </span><span class="cov0" title="0">{
                                                totalClassCount += tc.Count
                                        }</span>
                                }
                        }
                        <span class="cov0" title="0">fmt.Printf("[FreqClass] Class %d: %d tokens, %d total occurrences, bloom_size=%d, hash_count=%d\n",
                                i+1, len(classes[i]), totalClassCount, bloomSize, numHashes)</span>
                }
        }

        <span class="cov0" title="0">return FreqClassResult{
                Filters:   filters,
                TopTokens: tokenCounts[:topN],
        }</span>
}

// GetTokenFrequencyClass returns the frequency class index for a token.
// Checks filters in order from most frequent to least frequent.
// If the token is not found in any class, returns the last index (least frequent class).
func GetTokenFrequencyClass(token string) int <span class="cov0" title="0">{
        filters := GetGlobalFilters() // Thread-safe getter
        if len(filters) == 0 </span><span class="cov0" title="0">{
                fmt.Printf("WARNING: No frequency class filters available, assigning token '%s' to class 0\n", token)
                return 0 // Defensive: if no filters, return 0
        }</span>

        // Debug: Log filter status occasionally (but not too often)
        // Note: This is a simple approach - in production you'd want a thread-safe counter
        // For now, we'll just log the first few calls to see what's happening
        <span class="cov0" title="0">if len(filters) &gt; 0 </span><span class="cov0" title="0">{
                // Check if this is a SetFilter and has tokens
                if setFilter, ok := filters[0].(*SetFilter); ok </span><span class="cov0" title="0">{
                        if len(setFilter.tokens) == 0 </span><span class="cov0" title="0">{
                                fmt.Printf("WARNING: Frequency class filter 0 is empty\n")
                        }</span>
                }
        }

        <span class="cov0" title="0">for i, filter := range filters </span><span class="cov0" title="0">{
                if filter.Contains(token) </span><span class="cov0" title="0">{
                        return i
                }</span>
        }
        // Not found: assign to least frequent class
        <span class="cov0" title="0">return len(filters) - 1</span>
}
</pre>
		
		<pre class="file" id="file6" style="display: none">package pipeline

import (
        "fmt"
        "sync"
        "sync/atomic"
        "time"

        "log/slog"
)

// FrequencyComputationThread (FCT) manages token counting and frequency calculations
// in a separate goroutine to avoid blocking the main tweet processing pipeline.
type FrequencyComputationThread struct {
        // Token processing
        tokenCounter      *TokenCounter
        inboundTokenQueue *TokenQueue
        oldTokenQueue     *TokenQueue

        // Frequency calculation control
        shouldRebuild int32 // Atomic boolean (0 = false, 1 = true)

        // Thread control
        stopChan chan struct{}
        wg       sync.WaitGroup

        // Configuration
        freqClassInterval time.Duration
        freqClasses       int

        // Current filters (thread-safe access)
        currentFilters []FreqClassFilter
        filtersMutex   sync.RWMutex

        // Debug: Track rebuild count
        rebuildCount      int
        rebuildCountMutex sync.Mutex
}

// NewFrequencyComputationThread creates a new FCT with the specified configuration
func NewFrequencyComputationThread(
        tokenCounter *TokenCounter,
        inboundTokenQueue *TokenQueue,
        oldTokenQueue *TokenQueue,
        freqClassIntervalTweets int,
        freqClasses int,
) *FrequencyComputationThread <span class="cov8" title="1">{
        return &amp;FrequencyComputationThread{
                tokenCounter:      tokenCounter,
                inboundTokenQueue: inboundTokenQueue,
                oldTokenQueue:     oldTokenQueue,
                stopChan:          make(chan struct{}),
                freqClassInterval: time.Duration(freqClassIntervalTweets) * time.Second, // Not used in current implementation
                freqClasses:       freqClasses,
        }
}</span>

// Start begins the FCT goroutine
func (fct *FrequencyComputationThread) Start() <span class="cov8" title="1">{
        slog.Info("FCT Start method called")
        fct.wg.Add(1)
        go fct.run()
        slog.Info("FCT goroutine launched")
        slog.Info("FrequencyComputationThread started",
                "freq_class_interval_tweets", fct.freqClassInterval.Seconds(),
                "freq_classes", fct.freqClasses)
}</span>

// Stop gracefully stops the FCT goroutine
func (fct *FrequencyComputationThread) Stop() <span class="cov8" title="1">{
        close(fct.stopChan)
        fct.wg.Wait()
        slog.Info("FrequencyComputationThread stopped")
}</span>

// TriggerRebuild signals that a frequency class rebuild is needed
// The FCT will handle the rebuild autonomously when it's ready
func (fct *FrequencyComputationThread) TriggerRebuild() <span class="cov8" title="1">{
        atomic.StoreInt32(&amp;fct.shouldRebuild, 1)
        slog.Info("FCT: Rebuild flag SET - frequency boundary crossed")
}</span>

// run is the main loop of the FCT goroutine
func (fct *FrequencyComputationThread) run() <span class="cov8" title="1">{
        defer fct.wg.Done()

        // Add panic recovery
        defer func() </span><span class="cov8" title="1">{
                if r := recover(); r != nil </span><span class="cov0" title="0">{
                        slog.Error("FCT run loop panicked", "panic", r)
                }</span>
                <span class="cov8" title="1">slog.Info("FCT run method exiting")</span>
        }()

        <span class="cov8" title="1">slog.Info("FCT run method entered")
        slog.Info("FCT run loop starting")

        loopCount := 0
        for </span><span class="cov8" title="1">{
                select </span>{
                case &lt;-fct.stopChan:<span class="cov8" title="1">
                        slog.Info("FCT run loop stopping")
                        return</span>
                default:<span class="cov8" title="1">
                        loopCount++
                        if loopCount%10000 == 0 </span><span class="cov0" title="0">{ // Log every 10,000 iterations
                                slog.Info("FCT loop iteration", "count", loopCount)
                        }</span>
                        <span class="cov8" title="1">if loopCount%100000 == 0 </span><span class="cov0" title="0">{ // Log every 100,000 iterations to confirm it's running
                                slog.Info("FCT: Loop is running, iteration", "count", loopCount)
                        }</span>

                        // Check if rebuild is needed first
                        <span class="cov8" title="1">shouldRebuild := atomic.LoadInt32(&amp;fct.shouldRebuild) == 1

                        // Debug: Log rebuild flag status more frequently
                        if loopCount%1000 == 0 </span><span class="cov0" title="0">{
                                slog.Info("FCT: Rebuild flag check",
                                        "loop_count", loopCount,
                                        "should_rebuild", shouldRebuild)
                        }</span>

                        // ALWAYS log when rebuild flag is true (this should be rare)
                        <span class="cov8" title="1">if shouldRebuild </span><span class="cov8" title="1">{
                                slog.Info("FCT: REBUILD FLAG DETECTED!",
                                        "loop_count", loopCount,
                                        "should_rebuild", shouldRebuild)
                        }</span>

                        // Debug: Log the branch we're taking more frequently
                        <span class="cov8" title="1">if loopCount%1000 == 0 </span><span class="cov0" title="0">{
                                if shouldRebuild </span><span class="cov0" title="0">{
                                        slog.Info("FCT: Taking rebuild branch", "loop_count", loopCount)
                                }</span> else<span class="cov0" title="0"> {
                                        slog.Debug("FCT: Taking token processing branch", "loop_count", loopCount)
                                }</span>
                        }

                        <span class="cov8" title="1">if shouldRebuild </span><span class="cov8" title="1">{
                                // Increment rebuild count
                                fct.rebuildCountMutex.Lock()
                                fct.rebuildCount++
                                currentRebuildCount := fct.rebuildCount
                                fct.rebuildCountMutex.Unlock()

                                // Consume all accumulated tokens before starting computation
                                slog.Info("FCT: Consuming accumulated tokens before rebuild", "rebuild_count", currentRebuildCount)
                                fct.consumeAllAccumulatedTokens()

                                rebuildStartTime := time.Now()
                                slog.Info("FCT: Starting rebuild", "rebuild_count", currentRebuildCount, "start_time", rebuildStartTime.Format("15:04:05"))
                                fmt.Printf("*** FCT REBUILD STARTED at %s ***\n", rebuildStartTime.Format("15:04:05"))
                                // Pause token processing and do rebuild
                                fct.performRebuild()

                                // Debug: Log queue sizes after rebuild
                                inboundSizeAfter := fct.inboundTokenQueue.Len()
                                oldSizeAfter := fct.oldTokenQueue.Len()
                                slog.Info("FCT: Queue sizes after rebuild",
                                        "rebuild_count", currentRebuildCount,
                                        "inbound_queue_size", inboundSizeAfter,
                                        "old_queue_size", oldSizeAfter)

                        }</span>

                        // Process a small amount of tokens (main loop body - always happens)
                        <span class="cov8" title="1">fct.processTokens()

                        // Add a small delay when no tokens are being processed to prevent CPU spinning
                        inboundSize := fct.inboundTokenQueue.Len()
                        oldSize := fct.oldTokenQueue.Len()
                        if inboundSize == 0 &amp;&amp; oldSize == 0 </span><span class="cov8" title="1">{
                                time.Sleep(1 * time.Millisecond)
                        }</span>

                        // Debug: Log when queues are empty
                        <span class="cov8" title="1">if loopCount%1000 == 0 &amp;&amp; inboundSize == 0 &amp;&amp; oldSize == 0 </span><span class="cov0" title="0">{
                                slog.Debug("FCT: No tokens to process, waiting...",
                                        "loop_count", loopCount,
                                        "inbound_queue_size", inboundSize,
                                        "old_queue_size", oldSize)
                        }</span>
                }
        }
}

// processTokens processes tokens from both queues
func (fct *FrequencyComputationThread) processTokens() <span class="cov8" title="1">{
        // Only log when we actually process tokens or when queues have significant backlog
        inboundProcessed := 0
        for </span><span class="cov8" title="1">{
                tokens := fct.inboundTokenQueue.Dequeue()
                if tokens == nil </span><span class="cov8" title="1">{
                        break</span> // Queue is empty
                }
                <span class="cov8" title="1">fct.tokenCounter.IncrementTokens(tokens)
                inboundProcessed += len(tokens)</span>
        }

        // Process old tokens (decrement counts)
        <span class="cov8" title="1">oldProcessed := 0
        for </span><span class="cov8" title="1">{
                tokens := fct.oldTokenQueue.Dequeue()
                if tokens == nil </span><span class="cov8" title="1">{
                        break</span> // Queue is empty
                }
                <span class="cov8" title="1">fct.tokenCounter.DecrementTokens(tokens)
                oldProcessed += len(tokens)</span>
        }

        // Only log if we processed tokens or if queues are getting backed up
        <span class="cov8" title="1">if inboundProcessed &gt; 0 || oldProcessed &gt; 0 </span><span class="cov8" title="1">{
                slog.Info("FCT processed tokens",
                        "inbound_processed", inboundProcessed,
                        "old_processed", oldProcessed,
                        "inbound_queue_size_after", fct.inboundTokenQueue.Len(),
                        "old_queue_size_after", fct.oldTokenQueue.Len())
        }</span> else<span class="cov8" title="1"> {
                // Check if queues are getting backed up but we didn't process anything
                currentInboundSize := fct.inboundTokenQueue.Len()
                currentOldSize := fct.oldTokenQueue.Len()
                if currentInboundSize &gt; 100 || currentOldSize &gt; 100 </span><span class="cov0" title="0">{
                        slog.Warn("FCT queues have backlog but processed no tokens",
                                "inbound_queue_size", currentInboundSize,
                                "old_queue_size", currentOldSize)
                }</span>
        }

        // Debug: Log every 1000 calls to processTokens to confirm it's being called
        // Note: This is a simple counter for debugging - in production this would be removed
        // or made thread-safe if needed
}

// checkForRebuild method removed - rebuild logic now integrated into main loop

// performRebuild performs the actual frequency class calculation and filter building
func (fct *FrequencyComputationThread) performRebuild() <span class="cov8" title="1">{
        // Reset the rebuild flag immediately so loop can detect new rebuild requests
        atomic.StoreInt32(&amp;fct.shouldRebuild, 0)
        slog.Info("FCT: Rebuild flag RESET at start of performRebuild")

        startTime := time.Now()
        slog.Info("Starting frequency class rebuild")

        // Get a snapshot of current token counts for frequency calculations
        tokenCounts := fct.tokenCounter.CountsSnapshot()

        // Perform the frequency class calculation
        slog.Info("FCT: About to call BuildFrequencyClassHashSets", "token_count", len(tokenCounts), "freq_classes", fct.freqClasses)
        result := BuildFrequencyClassHashSets(tokenCounts, fct.freqClasses, nil, nil)
        slog.Info("FCT: BuildFrequencyClassHashSets returned", "filters_built", len(result.Filters))

        // Clear the token counter after frequency calculation
        // This ensures each rebuild is based only on the current window's tokens
        fct.tokenCounter.Clear()

        // Store the filters for the main thread to access
        fct.filtersMutex.Lock()
        fct.currentFilters = result.Filters
        fct.filtersMutex.Unlock()

        // Also install globally for main thread
        fmt.Printf("*** ABOUT TO INSTALL FILTERS GLOBALLY ***\n")
        SetGlobalFilters(result.Filters)
        fmt.Printf("*** FILTERS INSTALLED GLOBALLY ***\n")

        duration := time.Since(startTime)
        completionTime := time.Now()
        slog.Info("Frequency class rebuild completed",
                "duration", duration,
                "completion_time", completionTime.Format("15:04:05"),
                "token_count", len(tokenCounts),
                "filters_built", len(result.Filters))

        // Also print to stdout for immediate visibility
        fmt.Printf("*** FREQUENCY REBUILD COMPLETED at %s (duration: %v) ***\n",
                completionTime.Format("15:04:05"), duration)

        // Add diagnostic line to show filters are installed
        slog.Info("INSTALLED: frequency class filters are now active",
                "num_filters", len(result.Filters))

        // Print to stdout for immediate visibility
        fmt.Printf("*** FREQUENCY FILTERS INSTALLED: %d filters now active ***\n", len(result.Filters))

        // Log top tokens for debugging
        if len(result.TopTokens) &gt; 0 </span><span class="cov8" title="1">{
                slog.Debug("Top tokens after rebuild",
                        "top_token", result.TopTokens[0].Token,
                        "top_count", result.TopTokens[0].Count)
        }</span>
}

// GetQueueStats returns statistics about the current queue states
func (fct *FrequencyComputationThread) GetQueueStats() map[string]int <span class="cov8" title="1">{
        return map[string]int{
                "inbound_token_queue_size": fct.inboundTokenQueue.Len(),
                "old_token_queue_size":     fct.oldTokenQueue.Len(),
                "distinct_tokens":          len(fct.tokenCounter.Counts()),
        }
}</span>

// GetCurrentFilters returns the current frequency class filters (thread-safe)
func (fct *FrequencyComputationThread) GetCurrentFilters() []FreqClassFilter <span class="cov0" title="0">{
        fct.filtersMutex.RLock()
        defer fct.filtersMutex.RUnlock()
        return fct.currentFilters
}</span>

// GetRebuildCount returns the number of rebuilds performed (for debugging)
func (fct *FrequencyComputationThread) GetRebuildCount() int <span class="cov0" title="0">{
        fct.rebuildCountMutex.Lock()
        defer fct.rebuildCountMutex.Unlock()
        return fct.rebuildCount
}</span>

// consumeAllAccumulatedTokens processes tokens from both queues using queue size snapshots
func (fct *FrequencyComputationThread) consumeAllAccumulatedTokens() <span class="cov8" title="1">{
        // Get current queue sizes (snapshot to prevent infinite catch-up)
        inboundQueueSize := fct.inboundTokenQueue.Len()
        oldQueueSize := fct.oldTokenQueue.Len()

        slog.Info("FCT: Starting token consumption with queue snapshot",
                "inbound_queue_size", inboundQueueSize,
                "old_queue_size", oldQueueSize)

        inboundProcessed := 0
        oldProcessed := 0

        // Process exactly inboundQueueSize tokens from inbound queue
        for i := 0; i &lt; inboundQueueSize; i++ </span><span class="cov0" title="0">{
                tokens := fct.inboundTokenQueue.Dequeue()
                if tokens == nil </span><span class="cov0" title="0">{
                        break</span> // Queue is empty (shouldn't happen given our size check)
                }
                <span class="cov0" title="0">fct.tokenCounter.IncrementTokens(tokens)
                inboundProcessed += len(tokens)</span>
        }

        // Process exactly oldQueueSize tokens from old queue
        <span class="cov8" title="1">for i := 0; i &lt; oldQueueSize; i++ </span><span class="cov0" title="0">{
                tokens := fct.oldTokenQueue.Dequeue()
                if tokens == nil </span><span class="cov0" title="0">{
                        break</span> // Queue is empty (shouldn't happen given our size check)
                }
                <span class="cov0" title="0">fct.tokenCounter.DecrementTokens(tokens)
                oldProcessed += len(tokens)</span>
        }

        <span class="cov8" title="1">slog.Info("FCT: Consumed tokens using queue snapshot",
                "inbound_processed", inboundProcessed,
                "old_processed", oldProcessed,
                "inbound_queue_size_after", fct.inboundTokenQueue.Len(),
                "old_queue_size_after", fct.oldTokenQueue.Len())</span>
}
</pre>
		
		<pre class="file" id="file7" style="display: none">package pipeline

import (
        "sync"
)

// TokenQueue is a thread-safe queue for storing token arrays
type TokenQueue struct {
        items [][]string
        mu    sync.RWMutex
}

// NewTokenQueue creates a new empty TokenQueue
func NewTokenQueue() *TokenQueue <span class="cov8" title="1">{
        return &amp;TokenQueue{
                items: make([][]string, 0),
        }
}</span>

// Enqueue adds a slice of tokens to the end of the queue
func (tq *TokenQueue) Enqueue(tokens []string) <span class="cov8" title="1">{
        tq.mu.Lock()
        defer tq.mu.Unlock()
        tq.items = append(tq.items, tokens)
}</span>

// Dequeue removes and returns the first slice of tokens from the queue
// Returns nil if the queue is empty
func (tq *TokenQueue) Dequeue() []string <span class="cov8" title="1">{
        tq.mu.Lock()
        defer tq.mu.Unlock()

        if len(tq.items) == 0 </span><span class="cov8" title="1">{
                return nil
        }</span>

        // Get the first item
        <span class="cov8" title="1">tokens := tq.items[0]

        // Remove it from the queue
        tq.items = tq.items[1:]

        return tokens</span>
}

// Len returns the number of token arrays in the queue
func (tq *TokenQueue) Len() int <span class="cov8" title="1">{
        tq.mu.RLock()
        defer tq.mu.RUnlock()
        return len(tq.items)
}</span>

// Clear removes all items from the queue
func (tq *TokenQueue) Clear() <span class="cov0" title="0">{
        tq.mu.Lock()
        defer tq.mu.Unlock()
        tq.items = make([][]string, 0)
}</span>
</pre>
		
		<pre class="file" id="file8" style="display: none">package pipeline

import (
        "crypto/md5"
        "cursor-twitter/src/tweets"
        "encoding/binary"
)

var TokenTo3PK = make(map[string]tweets.ThreePartKey)
var ThreePKToToken = make(map[tweets.ThreePartKey]string)

// Global array length for 3PK generation (set from main.go)
var GlobalArrayLen int = 1000 // Default, will be set from config

func GenerateThreePartKey(token string) tweets.ThreePartKey <span class="cov0" title="0">{
        a := hashWithSuffix(token, "__0NE__", GlobalArrayLen)
        b := hashWithSuffix(token, "__TW0__", GlobalArrayLen)
        c := hashWithSuffix(token, "__THR33__", GlobalArrayLen)
        key := tweets.ThreePartKey{Part1: a, Part2: b, Part3: c}
        // Store in global maps if not already present
        if _, exists := TokenTo3PK[token]; !exists </span><span class="cov0" title="0">{
                TokenTo3PK[token] = key
                ThreePKToToken[key] = token
        }</span>
        <span class="cov0" title="0">return key</span>
}

func hashWithSuffix(token, suffix string, modulo int) int <span class="cov0" title="0">{
        h := md5.Sum([]byte(token + suffix))
        return int(binary.BigEndian.Uint32(h[:4])) % modulo
}</span>

// SetGlobalArrayLen sets the global array length for 3PK generation
func SetGlobalArrayLen(arrayLen int) <span class="cov0" title="0">{
        GlobalArrayLen = arrayLen
}</span>
</pre>
		
		<pre class="file" id="file9" style="display: none">package pipeline

import (
        "encoding/gob"
        "fmt"
        "os"
        "path/filepath"
        "sync"
)

// TokenCounter keeps track of how many times each token appears in the current window.
// Uses record-level locking for thread safety with minimal contention.
type TokenCounter struct {
        counts map[string]int
        mu     sync.RWMutex
}

// NewTokenCounter creates a new TokenCounter with an empty map.
func NewTokenCounter() *TokenCounter <span class="cov8" title="1">{
        return &amp;TokenCounter{counts: make(map[string]int)}
}</span>

// IncrementTokens increases the count for each token in the list.
// Call this when a new tweet enters the window.
func (tc *TokenCounter) IncrementTokens(tokens []string) <span class="cov8" title="1">{
        tc.mu.Lock()
        defer tc.mu.Unlock()
        for _, token := range tokens </span><span class="cov8" title="1">{
                tc.counts[token]++
        }</span>
}

// DecrementTokens decreases the count for each token in the list.
// Call this when an old tweet leaves the window.
func (tc *TokenCounter) DecrementTokens(tokens []string) <span class="cov8" title="1">{
        tc.mu.Lock()
        defer tc.mu.Unlock()
        for _, token := range tokens </span><span class="cov8" title="1">{
                tc.counts[token]--
                if tc.counts[token] &lt;= 0 </span><span class="cov8" title="1">{
                        delete(tc.counts, token) // Clean up to save memory
                }</span>
        }
}

// GetCount returns the count for a specific token.
func (tc *TokenCounter) GetCount(token string) int <span class="cov8" title="1">{
        tc.mu.RLock()
        defer tc.mu.RUnlock()
        return tc.counts[token]
}</span>

// Counts returns the map of all token counts (for stats reporting).
// This creates a snapshot of the current counts for thread safety.
func (tc *TokenCounter) Counts() map[string]int <span class="cov8" title="1">{
        tc.mu.RLock()
        defer tc.mu.RUnlock()

        // Create a copy to avoid race conditions
        snapshot := make(map[string]int, len(tc.counts))
        for token, count := range tc.counts </span><span class="cov8" title="1">{
                snapshot[token] = count
        }</span>
        <span class="cov8" title="1">return snapshot</span>
}

// CountsSnapshot returns a snapshot of token counts optimized for frequency calculations.
// This method is designed to be called from the background frequency calculation goroutine.
//
// TRADE-OFFS:
// - Creates a copy to avoid concurrent map access errors
// - Slightly slower but thread-safe
// - Suitable for frequency calculations where "pretty good is good enough"
func (tc *TokenCounter) CountsSnapshot() map[string]int <span class="cov8" title="1">{
        tc.mu.RLock()
        defer tc.mu.RUnlock()

        // Create a copy to avoid "concurrent map iteration and map write" errors
        // This is safer than returning a direct reference
        snapshot := make(map[string]int, len(tc.counts))
        for token, count := range tc.counts </span><span class="cov8" title="1">{
                snapshot[token] = count
        }</span>
        <span class="cov8" title="1">return snapshot</span>
}

// Clear resets all token counts to zero.
// Call this after frequency calculations to start fresh for the next window.
func (tc *TokenCounter) Clear() <span class="cov8" title="1">{
        tc.mu.Lock()
        defer tc.mu.Unlock()
        // Clear the map by creating a new one
        tc.counts = make(map[string]int)
}</span>

// SaveToFile saves the current token counts to a file using gob encoding
func (tc *TokenCounter) SaveToFile(filename string) error <span class="cov8" title="1">{
        // Ensure the directory exists
        dir := filepath.Dir(filename)
        if err := os.MkdirAll(dir, 0755); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create directory %s: %v", dir, err)
        }</span>

        // Create the file
        <span class="cov8" title="1">file, err := os.Create(filename)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create file %s: %v", filename, err)
        }</span>
        <span class="cov8" title="1">defer file.Close()

        // Get a snapshot of the counts
        counts := tc.CountsSnapshot()

        // Encode and write to file
        encoder := gob.NewEncoder(file)
        if err := encoder.Encode(counts); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to encode counts to %s: %v", filename, err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// LoadFromFile loads token counts from a file using gob decoding
func (tc *TokenCounter) LoadFromFile(filename string) error <span class="cov8" title="1">{
        // Open the file
        file, err := os.Open(filename)
        if err != nil </span><span class="cov8" title="1">{
                return fmt.Errorf("failed to open file %s: %v", filename, err)
        }</span>
        <span class="cov8" title="1">defer file.Close()

        // Decode the counts
        var counts map[string]int
        decoder := gob.NewDecoder(file)
        if err := decoder.Decode(&amp;counts); err != nil </span><span class="cov8" title="1">{
                return fmt.Errorf("failed to decode counts from %s: %v", filename, err)
        }</span>

        // Replace the current counts with the loaded ones
        <span class="cov8" title="1">tc.mu.Lock()
        defer tc.mu.Unlock()
        tc.counts = counts

        return nil</span>
}
</pre>
		
		<pre class="file" id="file10" style="display: none">package main

import (
        "fmt"

        amqp "github.com/rabbitmq/amqp091-go"
)

// RabbitMQConfig holds RabbitMQ connection configuration
type RabbitMQConfig struct {
        Host     string
        Port     int
        Username string
        Password string
        Queue    string
        Exchange string
}

// RabbitMQ implements the MessageQueue interface using RabbitMQ
type RabbitMQ struct {
        conn    *amqp.Connection
        channel *amqp.Channel
        queue   amqp.Queue
        config  RabbitMQConfig
}

// NewRabbitMQ creates a new RabbitMQ connection
func NewRabbitMQ(config RabbitMQConfig) (*RabbitMQ, error) <span class="cov0" title="0">{
        // Build connection URL
        url := fmt.Sprintf("amqp://%s:%s@%s:%d/", config.Username, config.Password, config.Host, config.Port)

        // Connect to RabbitMQ
        conn, err := amqp.Dial(url)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to connect to RabbitMQ: %w", err)
        }</span>

        // Create channel
        <span class="cov0" title="0">ch, err := conn.Channel()
        if err != nil </span><span class="cov0" title="0">{
                conn.Close()
                return nil, fmt.Errorf("failed to open channel: %w", err)
        }</span>

        // Declare queue
        <span class="cov0" title="0">q, err := ch.QueueDeclare(
                config.Queue, // name
                true,         // durable
                false,        // delete when unused
                false,        // exclusive
                false,        // no-wait
                nil,          // arguments
        )
        if err != nil </span><span class="cov0" title="0">{
                ch.Close()
                conn.Close()
                return nil, fmt.Errorf("failed to declare queue: %w", err)
        }</span>

        // Set QoS for fair dispatch
        <span class="cov0" title="0">err = ch.Qos(
                1,     // prefetch count
                0,     // prefetch size
                false, // global
        )
        if err != nil </span><span class="cov0" title="0">{
                ch.Close()
                conn.Close()
                return nil, fmt.Errorf("failed to set QoS: %w", err)
        }</span>

        <span class="cov0" title="0">return &amp;RabbitMQ{
                conn:    conn,
                channel: ch,
                queue:   q,
                config:  config,
        }, nil</span>
}

// Close closes the RabbitMQ connection
func (r *RabbitMQ) Close() error <span class="cov0" title="0">{
        if r.channel != nil </span><span class="cov0" title="0">{
                r.channel.Close()
        }</span>
        <span class="cov0" title="0">if r.conn != nil </span><span class="cov0" title="0">{
                return r.conn.Close()
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// GetQueueInfo returns information about the queue
func (r *RabbitMQ) GetQueueInfo() (map[string]interface{}, error) <span class="cov0" title="0">{
        queue, err := r.channel.QueueInspect(r.config.Queue)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to inspect queue: %w", err)
        }</span>

        <span class="cov0" title="0">return map[string]interface{}{
                "name":      queue.Name,
                "messages":  queue.Messages,
                "consumers": queue.Consumers,
        }, nil</span>
}
</pre>
		
		</div>
	</body>
	<script>
	(function() {
		var files = document.getElementById('files');
		var visible;
		files.addEventListener('change', onChange, false);
		function select(part) {
			if (visible)
				visible.style.display = 'none';
			visible = document.getElementById(part);
			if (!visible)
				return;
			files.value = part;
			visible.style.display = 'block';
			location.hash = part;
		}
		function onChange() {
			select(files.value);
			window.scrollTo(0, 0);
		}
		if (location.hash != "") {
			select(location.hash.substr(1));
		}
		if (!visible) {
			select("file0");
		}
	})();
	</script>
</html>
